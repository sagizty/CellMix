{"cells":[{"cell_type":"markdown","metadata":{"id":"-1_HUut4YYm5"},"source":["## This is the official training Demo of CellMix\n","* Use google colab pro+ (high RAM+GPU) for demo\n","* we use the 3090 GPU for the Experiments\n","\n","## The code and Training process along with all record are private\n","* Our github page: https://github.com/sagizty/CellMix\n","* The datasets are publicly aviliable (mostly)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":664,"status":"ok","timestamp":1670905870092,"user":{"displayName":"Rush MSHT","userId":"17678018738220178064"},"user_tz":-480},"id":"ZnbrNSoSXFm5","outputId":"f2faf057-8f3c-4813-b8ce-18a5e27da2fa"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tue Dec 13 04:31:08 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   35C    P0    26W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["# check GPU\n","!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1670905870093,"user":{"displayName":"Rush MSHT","userId":"17678018738220178064"},"user_tz":-480},"id":"n9GPOn5gcykA","outputId":"647f9508-c99f-4bb0-cc8a-1c2450733d2f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tue Dec 13 12:31:08 UTC 2022\n"]}],"source":["!date --date='+8 hour'  # CST time zone"]},{"cell_type":"markdown","metadata":{"id":"fbnpeHYUgsJz"},"source":["## Mount Google Drive"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26836,"status":"ok","timestamp":1670905896925,"user":{"displayName":"Rush MSHT","userId":"17678018738220178064"},"user_tz":-480},"id":"3obRNrIaffjK","outputId":"7931fddf-58d6-4a45-e295-2b5bde5d3d7d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"BYevYeMFYmlx"},"source":["## create file-system enviroment\n","* mount your google drive first\n","* take the zipped dataset from the mounted google drive\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30818,"status":"ok","timestamp":1670906104394,"user":{"displayName":"Rush MSHT","userId":"17678018738220178064"},"user_tz":-480},"id":"ePtQFcQCEPlu","outputId":"97222d5d-8a6b-4f26-d085-959b9850da6a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Folder Tree Creation completed!\n","Cloning into '/home/Pathology_Experiment/code'...\n","remote: Enumerating objects: 119, done.\u001b[K\n","remote: Counting objects: 100% (47/47), done.\u001b[K\n","remote: Compressing objects: 100% (47/47), done.\u001b[K\n","remote: Total 119 (delta 27), reused 0 (delta 0), pack-reused 72\u001b[K\n","Receiving objects: 100% (119/119), 102.55 KiB | 20.51 MiB/s, done.\n","Resolving deltas: 100% (51/51), done.\n","code transfer from github completed!\n","data transfer completed!\n"]}],"source":["# clear colab path\n","!rm -rf /data\n","!rm -rf /home/Pathology_Experiment\n","\n","# create path\n","!mkdir /home/Pathology_Experiment\n","!mkdir /home/Pathology_Experiment/runs\n","!mkdir /home/Pathology_Experiment/code\n","!mkdir /home/Pathology_Experiment/saved_models\n","!mkdir /home/Pathology_Experiment/imaging_results\n","\n","!mkdir /data\n","!mkdir /data/Pathology_Experiment\n","!mkdir /data/Pathology_Experiment/dataset\n","\n","print('Folder Tree Creation completed!')\n","\n","# get latest code from Github pancreatic-cancer-diagnosis-tansformer page\n","!git clone https://github.com/sagizty/CellMix.git /home/Pathology_Experiment/code\n","print('code transfer from github completed!')\n","\n","# copy runs if u want to compare\n","# !cp -r /content/drive/MyDrive/Pathology_Experiment/runs/* /home/Pathology_Experiment/runs\n","# print('tensorboard log transfer completed!')\n","\n","# get the datasets\n","# by its zip\n","!cp /content/drive/MyDrive/dataset/ROSE_CLS.zip /data/Pathology_Experiment/dataset/\n","# !cp /content/drive/MyDrive/dataset/MARS_CLS.zip /data/Pathology_Experiment/dataset/\n","# !cp /content/drive/MyDrive/dataset/warwick_CLS.zip /data/Pathology_Experiment/dataset/\n","# !cp /content/drive/MyDrive/dataset/pRCC_CLS.zip /data/Pathology_Experiment/dataset/\n","# !cp /content/drive/MyDrive/dataset/GS_CLS.zip /data/Pathology_Experiment/dataset/\n","\n","# unzip\n","!unzip -q /data/Pathology_Experiment/dataset/ROSE_CLS.zip -d /data/Pathology_Experiment/dataset/\n","# !unzip -q /data/Pathology_Experiment/dataset/MARS_CLS.zip -d /data/Pathology_Experiment/dataset/\n","# !unzip -q /data/Pathology_Experiment/dataset/warwick_CLS.zip -d /data/Pathology_Experiment/dataset/\n","# !unzip -q /data/Pathology_Experiment/dataset/pRCC_CLS.zip -d /data/Pathology_Experiment/dataset/\n","# !unzip -q /data/Pathology_Experiment/dataset/GS_CLS.zip -d /data/Pathology_Experiment/dataset/\n","\n","# alter the path\n","!rm -rf /data/Pathology_Experiment/dataset/ROSE_CLS.zip\n","# !rm -rf /data/Pathology_Experiment/dataset/MARS_CLS.zip\n","# !rm -rf /data/Pathology_Experiment/dataset/warwick_CLS.zip\n","# !rm -rf /data/Pathology_Experiment/dataset/pRCC_CLS.zip\n","# !rm -rf /data/Pathology_Experiment/dataset/GS_CLS.zip\n","print('data transfer completed!')"]},{"cell_type":"markdown","metadata":{"id":"xLxxHGq_wwwL"},"source":["## Arrange the working enviorment"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":169587,"status":"ok","timestamp":1670906073583,"user":{"displayName":"Rush MSHT","userId":"17678018738220178064"},"user_tz":-480},"id":"Bl0KeDbA645a","outputId":"40530b85-b707-4d7a-d52d-01031b5ef37c"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[K     |████████████▌                   | 834.1 MB 1.2 MB/s eta 0:18:38tcmalloc: large alloc 1147494400 bytes == 0x3a1fc000 @  0x7f06f45ca615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x4fd8b5 0x4997c7 0x4fd8b5 0x49abe4 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x5d8868 0x5da092 0x587116 0x5d8d8c 0x55dc1e 0x55cd91 0x5d8941 0x49abe4 0x55cd91 0x5d8941 0x4990ca 0x5d8868 0x4997a2 0x4fd8b5 0x49abe4\n","\u001b[K     |███████████████▉                | 1055.7 MB 130.8 MB/s eta 0:00:09tcmalloc: large alloc 1434370048 bytes == 0x7e852000 @  0x7f06f45ca615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x4fd8b5 0x4997c7 0x4fd8b5 0x49abe4 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x5d8868 0x5da092 0x587116 0x5d8d8c 0x55dc1e 0x55cd91 0x5d8941 0x49abe4 0x55cd91 0x5d8941 0x4990ca 0x5d8868 0x4997a2 0x4fd8b5 0x49abe4\n","\u001b[K     |████████████████████            | 1336.2 MB 1.2 MB/s eta 0:10:54tcmalloc: large alloc 1792966656 bytes == 0x3684000 @  0x7f06f45ca615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x4fd8b5 0x4997c7 0x4fd8b5 0x49abe4 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x5d8868 0x5da092 0x587116 0x5d8d8c 0x55dc1e 0x55cd91 0x5d8941 0x49abe4 0x55cd91 0x5d8941 0x4990ca 0x5d8868 0x4997a2 0x4fd8b5 0x49abe4\n","\u001b[K     |█████████████████████████▎      | 1691.1 MB 1.1 MB/s eta 0:06:35tcmalloc: large alloc 2241208320 bytes == 0x6e46c000 @  0x7f06f45ca615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x4fd8b5 0x4997c7 0x4fd8b5 0x49abe4 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x4f5fe9 0x55e146 0x5d8868 0x5da092 0x587116 0x5d8d8c 0x55dc1e 0x55cd91 0x5d8941 0x49abe4 0x55cd91 0x5d8941 0x4990ca 0x5d8868 0x4997a2 0x4fd8b5 0x49abe4\n","\u001b[K     |████████████████████████████████| 2137.6 MB 1.1 MB/s eta 0:00:01tcmalloc: large alloc 2137636864 bytes == 0xf3dce000 @  0x7f06f45c91e7 0x4d30a0 0x4d312c 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x5d8868 0x4997a2 0x55cd91 0x5d8941 0x49abe4 0x4fd8b5 0x49abe4 0x55cd91\n","tcmalloc: large alloc 2672050176 bytes == 0x1e7916000 @  0x7f06f45ca615 0x5d6f4c 0x51edd1 0x51ef5b 0x4f750a 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x55cd91 0x5d8941 0x4997a2 0x5d8868 0x4997a2 0x55cd91 0x5d8941 0x49abe4 0x4fd8b5 0x49abe4 0x55cd91 0x5d8941 0x4fe318\n","\u001b[K     |████████████████████████████████| 2137.6 MB 8.5 kB/s \n","\u001b[K     |████████████████████████████████| 24.5 MB 107.2 MB/s \n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtext 0.14.0 requires torch==1.13.0, but you have torch 1.10.0+cu111 which is incompatible.\n","torchaudio 0.13.0+cu116 requires torch==1.13.0, but you have torch 1.10.0+cu111 which is incompatible.\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install -q torch==1.10.0+cu111 torchvision==0.11.1+cu111 -f https://download.pytorch.org/whl/torch_stable.html"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18307,"status":"ok","timestamp":1670906122690,"user":{"displayName":"Rush MSHT","userId":"17678018738220178064"},"user_tz":-480},"id":"K1Yb2b6TGF4r","outputId":"f9005af4-97ef-4219-f3de-1a57b23ef8e8"},"outputs":[{"name":"stdout","output_type":"stream","text":["/home/Pathology_Experiment/code\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorboardX\n","  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n","\u001b[K     |████████████████████████████████| 125 kB 30.6 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from tensorboardX) (1.21.6)\n","Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorboardX) (3.19.6)\n","Installing collected packages: tensorboardX\n","Successfully installed tensorboardX-2.5.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting timm\n","  Downloading timm-0.6.12-py3-none-any.whl (549 kB)\n","\u001b[K     |████████████████████████████████| 549 kB 44.5 MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from timm) (6.0)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (from timm) (0.11.1+cu111)\n","Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.8/dist-packages (from timm) (1.10.0+cu111)\n","Collecting huggingface-hub\n","  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n","\u001b[K     |████████████████████████████████| 182 kB 89.3 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.7->timm) (4.4.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->timm) (2.23.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->timm) (21.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->timm) (3.8.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->timm) (4.64.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.9->huggingface-hub->timm) (3.0.9)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub->timm) (2022.9.24)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub->timm) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub->timm) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub->timm) (2.10)\n","Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision->timm) (7.1.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision->timm) (1.21.6)\n","Installing collected packages: huggingface-hub, timm\n","Successfully installed huggingface-hub-0.11.1 timm-0.6.12\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting notifyemail\n","  Downloading notifyemail-1.0.2-py3-none-any.whl (31 kB)\n","Installing collected packages: notifyemail\n","Successfully installed notifyemail-1.0.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting ttach\n","  Downloading ttach-0.0.3-py3-none-any.whl (9.8 kB)\n","Installing collected packages: ttach\n","Successfully installed ttach-0.0.3\n"]}],"source":["# change working dir\n","import os\n","os.chdir(\"/home/Pathology_Experiment/code\")\n","!pwd\n","\n","# get packages\n","!pip install tensorboardX\n","!pip install timm\n","!pip install notifyemail\n","!pip install ttach\n","\n","!pip freeze>requirements.txt\n","!cp requirements.txt ../runs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1670906122691,"user":{"displayName":"Rush MSHT","userId":"17678018738220178064"},"user_tz":-480},"id":"87Owjg_pN2yD","outputId":"b85d7bbe-b6ab-4a13-ff29-2ed2c6965dc2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Python 3.8.16\n"]}],"source":["!python --version"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":753,"status":"ok","timestamp":1670906123438,"user":{"displayName":"Rush MSHT","userId":"17678018738220178064"},"user_tz":-480},"id":"GpEVUWwqK79D","outputId":"75a9714b-be1c-412a-d30f-aa922a8fc402"},"outputs":[{"name":"stdout","output_type":"stream","text":["Package                       Version\n","----------------------------- ----------------------\n","absl-py                       1.3.0\n","aeppl                         0.0.33\n","aesara                        2.7.9\n","aiohttp                       3.8.3\n","aiosignal                     1.3.1\n","alabaster                     0.7.12\n","albumentations                1.2.1\n","altair                        4.2.0\n","appdirs                       1.4.4\n","arviz                         0.12.1\n","astor                         0.8.1\n","astropy                       4.3.1\n","astunparse                    1.6.3\n","async-timeout                 4.0.2\n","atari-py                      0.2.9\n","atomicwrites                  1.4.1\n","attrs                         22.1.0\n","audioread                     3.0.0\n","autograd                      1.5\n","Babel                         2.11.0\n","backcall                      0.2.0\n","beautifulsoup4                4.6.3\n","bleach                        5.0.1\n","blis                          0.7.9\n","bokeh                         2.3.3\n","branca                        0.6.0\n","bs4                           0.0.1\n","CacheControl                  0.12.11\n","cachetools                    5.2.0\n","catalogue                     2.0.8\n","certifi                       2022.9.24\n","cffi                          1.15.1\n","cftime                        1.6.2\n","chardet                       3.0.4\n","charset-normalizer            2.1.1\n","click                         7.1.2\n","clikit                        0.6.2\n","cloudpickle                   1.5.0\n","cmake                         3.22.6\n","cmdstanpy                     1.0.8\n","colorcet                      3.0.1\n","colorlover                    0.3.0\n","community                     1.0.0b1\n","confection                    0.0.3\n","cons                          0.4.5\n","contextlib2                   0.5.5\n","convertdate                   2.4.0\n","crashtest                     0.3.1\n","crcmod                        1.7\n","cufflinks                     0.17.3\n","cupy-cuda11x                  11.0.0\n","cvxopt                        1.3.0\n","cvxpy                         1.2.2\n","cycler                        0.11.0\n","cymem                         2.0.7\n","Cython                        0.29.32\n","daft                          0.0.4\n","dask                          2022.2.1\n","datascience                   0.17.5\n","db-dtypes                     1.0.4\n","debugpy                       1.0.0\n","decorator                     4.4.2\n","defusedxml                    0.7.1\n","descartes                     1.1.0\n","dill                          0.3.6\n","distributed                   2022.2.1\n","dlib                          19.24.0\n","dm-tree                       0.1.7\n","dnspython                     2.2.1\n","docutils                      0.17.1\n","dopamine-rl                   1.0.5\n","earthengine-api               0.1.334\n","easydict                      1.10\n","ecos                          2.0.10\n","editdistance                  0.5.3\n","en-core-web-sm                3.4.1\n","entrypoints                   0.4\n","ephem                         4.1.3\n","et-xmlfile                    1.1.0\n","etils                         0.9.0\n","etuples                       0.3.8\n","fa2                           0.3.5\n","fastai                        2.7.10\n","fastcore                      1.5.27\n","fastdownload                  0.0.7\n","fastdtw                       0.3.4\n","fastjsonschema                2.16.2\n","fastprogress                  1.0.3\n","fastrlock                     0.8.1\n","feather-format                0.4.1\n","filelock                      3.8.0\n","firebase-admin                5.3.0\n","fix-yahoo-finance             0.0.22\n","Flask                         1.1.4\n","flatbuffers                   1.12\n","folium                        0.12.1.post1\n","frozenlist                    1.3.3\n","fsspec                        2022.11.0\n","future                        0.16.0\n","gast                          0.4.0\n","GDAL                          2.2.2\n","gdown                         4.4.0\n","gensim                        3.6.0\n","geographiclib                 1.52\n","geopy                         1.17.0\n","gin-config                    0.5.0\n","glob2                         0.7\n","google                        2.0.3\n","google-api-core               2.8.2\n","google-api-python-client      1.12.11\n","google-auth                   2.15.0\n","google-auth-httplib2          0.0.4\n","google-auth-oauthlib          0.4.6\n","google-cloud-bigquery         3.3.6\n","google-cloud-bigquery-storage 2.16.2\n","google-cloud-core             2.3.2\n","google-cloud-datastore        2.9.0\n","google-cloud-firestore        2.7.2\n","google-cloud-language         2.6.1\n","google-cloud-storage          2.5.0\n","google-cloud-translate        3.8.4\n","google-colab                  1.0.0\n","google-crc32c                 1.5.0\n","google-pasta                  0.2.0\n","google-resumable-media        2.4.0\n","googleapis-common-protos      1.57.0\n","googledrivedownloader         0.4\n","graphviz                      0.10.1\n","greenlet                      2.0.1\n","grpcio                        1.51.1\n","grpcio-status                 1.48.2\n","gspread                       3.4.2\n","gspread-dataframe             3.0.8\n","gym                           0.25.2\n","gym-notices                   0.0.8\n","h5py                          3.1.0\n","HeapDict                      1.0.1\n","hijri-converter               2.2.4\n","holidays                      0.17.2\n","holoviews                     1.14.9\n","html5lib                      1.0.1\n","httpimport                    0.5.18\n","httplib2                      0.17.4\n","httpstan                      4.6.1\n","huggingface-hub               0.11.1\n","humanize                      0.5.1\n","hyperopt                      0.1.2\n","idna                          2.10\n","imageio                       2.9.0\n","imagesize                     1.4.1\n","imbalanced-learn              0.8.1\n","imblearn                      0.0\n","imgaug                        0.4.0\n","importlib-metadata            4.13.0\n","importlib-resources           5.10.0\n","imutils                       0.5.4\n","inflect                       2.1.0\n","intel-openmp                  2022.2.1\n","intervaltree                  2.1.0\n","ipykernel                     5.3.4\n","ipython                       7.9.0\n","ipython-genutils              0.2.0\n","ipython-sql                   0.3.9\n","ipywidgets                    7.7.1\n","itsdangerous                  1.1.0\n","jax                           0.3.25\n","jaxlib                        0.3.25+cuda11.cudnn805\n","jieba                         0.42.1\n","Jinja2                        2.11.3\n","joblib                        1.2.0\n","jpeg4py                       0.1.4\n","jsonschema                    4.3.3\n","jupyter-client                6.1.12\n","jupyter-console               6.1.0\n","jupyter-core                  5.1.0\n","jupyterlab-widgets            3.0.3\n","kaggle                        1.5.12\n","kapre                         0.3.7\n","keras                         2.9.0\n","Keras-Preprocessing           1.1.2\n","keras-vis                     0.4.1\n","kiwisolver                    1.4.4\n","korean-lunar-calendar         0.3.1\n","langcodes                     3.3.0\n","libclang                      14.0.6\n","librosa                       0.8.1\n","lightgbm                      2.2.3\n","llvmlite                      0.39.1\n","lmdb                          0.99\n","locket                        1.0.0\n","logical-unification           0.4.5\n","LunarCalendar                 0.0.9\n","lxml                          4.9.1\n","Markdown                      3.4.1\n","MarkupSafe                    2.0.1\n","marshmallow                   3.19.0\n","matplotlib                    3.2.2\n","matplotlib-venn               0.11.7\n","miniKanren                    1.0.3\n","missingno                     0.5.1\n","mistune                       0.8.4\n","mizani                        0.7.3\n","mkl                           2019.0\n","mlxtend                       0.14.0\n","more-itertools                9.0.0\n","moviepy                       0.2.3.5\n","mpmath                        1.2.1\n","msgpack                       1.0.4\n","multidict                     6.0.3\n","multipledispatch              0.6.0\n","multitasking                  0.0.11\n","murmurhash                    1.0.9\n","music21                       5.5.0\n","natsort                       5.5.0\n","nbconvert                     5.6.1\n","nbformat                      5.7.0\n","netCDF4                       1.6.2\n","networkx                      2.8.8\n","nibabel                       3.0.2\n","nltk                          3.7\n","notebook                      5.7.16\n","notifyemail                   1.0.2\n","numba                         0.56.4\n","numexpr                       2.8.4\n","numpy                         1.21.6\n","oauth2client                  4.1.3\n","oauthlib                      3.2.2\n","okgrade                       0.4.3\n","opencv-contrib-python         4.6.0.66\n","opencv-python                 4.6.0.66\n","opencv-python-headless        4.6.0.66\n","openpyxl                      3.0.10\n","opt-einsum                    3.3.0\n","osqp                          0.6.2.post0\n","packaging                     21.3\n","palettable                    3.3.0\n","pandas                        1.3.5\n","pandas-datareader             0.9.0\n","pandas-gbq                    0.17.9\n","pandas-profiling              1.4.1\n","pandocfilters                 1.5.0\n","panel                         0.12.1\n","param                         1.12.2\n","parso                         0.8.3\n","partd                         1.3.0\n","pastel                        0.2.1\n","pathlib                       1.0.1\n","pathy                         0.10.0\n","patsy                         0.5.3\n","pep517                        0.13.0\n","pexpect                       4.8.0\n","pickleshare                   0.7.5\n","Pillow                        7.1.2\n","pip                           21.1.3\n","pip-tools                     6.2.0\n","platformdirs                  2.5.4\n","plotly                        5.5.0\n","plotnine                      0.8.0\n","pluggy                        0.7.1\n","pooch                         1.6.0\n","portpicker                    1.3.9\n","prefetch-generator            1.0.3\n","preshed                       3.0.8\n","prettytable                   3.5.0\n","progressbar2                  3.38.0\n","prometheus-client             0.15.0\n","promise                       2.3\n","prompt-toolkit                2.0.10\n","prophet                       1.1.1\n","proto-plus                    1.22.1\n","protobuf                      3.19.6\n","psutil                        5.4.8\n","psycopg2                      2.9.5\n","ptyprocess                    0.7.0\n","py                            1.11.0\n","pyarrow                       9.0.0\n","pyasn1                        0.4.8\n","pyasn1-modules                0.2.8\n","pycocotools                   2.0.6\n","pycparser                     2.21\n","pyct                          0.4.8\n","pydantic                      1.10.2\n","pydata-google-auth            1.4.0\n","pydot                         1.3.0\n","pydot-ng                      2.0.0\n","pydotplus                     2.0.2\n","PyDrive                       1.3.1\n","pyemd                         0.5.1\n","pyerfa                        2.0.0.1\n","Pygments                      2.6.1\n","pygobject                     3.26.1\n","pylev                         1.4.0\n","pymc                          4.1.4\n","PyMeeus                       0.5.11\n","pymongo                       4.3.3\n","pymystem3                     0.2.0\n","PyOpenGL                      3.1.6\n","pyparsing                     3.0.9\n","pyrsistent                    0.19.2\n","pysimdjson                    3.2.0\n","pysndfile                     1.3.8\n","PySocks                       1.7.1\n","pystan                        3.3.0\n","pytest                        3.6.4\n","python-apt                    0.0.0\n","python-dateutil               2.8.2\n","python-louvain                0.16\n","python-slugify                7.0.0\n","python-utils                  3.4.5\n","pytz                          2022.6\n","pyviz-comms                   2.2.1\n","PyWavelets                    1.4.1\n","PyYAML                        6.0\n","pyzmq                         23.2.1\n","qdldl                         0.1.5.post2\n","qudida                        0.0.4\n","regex                         2022.6.2\n","requests                      2.23.0\n","requests-oauthlib             1.3.1\n","resampy                       0.4.2\n","rpy2                          3.5.5\n","rsa                           4.9\n","scikit-image                  0.18.3\n","scikit-learn                  1.0.2\n","scipy                         1.7.3\n","screen-resolution-extra       0.0.0\n","scs                           3.2.2\n","seaborn                       0.11.2\n","Send2Trash                    1.8.0\n","setuptools                    57.4.0\n","setuptools-git                1.2\n","Shapely                       1.8.5.post1\n","six                           1.15.0\n","sklearn-pandas                1.8.0\n","smart-open                    5.2.1\n","snowballstemmer               2.2.0\n","sortedcontainers              2.4.0\n","soundfile                     0.11.0\n","spacy                         3.4.3\n","spacy-legacy                  3.0.10\n","spacy-loggers                 1.0.3\n","Sphinx                        1.8.6\n","sphinxcontrib-serializinghtml 1.1.5\n","sphinxcontrib-websupport      1.2.4\n","SQLAlchemy                    1.4.44\n","sqlparse                      0.4.3\n","srsly                         2.4.5\n","statsmodels                   0.12.2\n","sympy                         1.7.1\n","tables                        3.7.0\n","tabulate                      0.8.10\n","tblib                         1.7.0\n","tenacity                      8.1.0\n","tensorboard                   2.9.1\n","tensorboard-data-server       0.6.1\n","tensorboard-plugin-wit        1.8.1\n","tensorboardX                  2.5.1\n","tensorflow                    2.9.2\n","tensorflow-datasets           4.6.0\n","tensorflow-estimator          2.9.0\n","tensorflow-gcs-config         2.9.1\n","tensorflow-hub                0.12.0\n","tensorflow-io-gcs-filesystem  0.28.0\n","tensorflow-metadata           1.11.0\n","tensorflow-probability        0.17.0\n","termcolor                     2.1.1\n","terminado                     0.13.3\n","testpath                      0.6.0\n","text-unidecode                1.3\n","textblob                      0.15.3\n","thinc                         8.1.5\n","threadpoolctl                 3.1.0\n","tifffile                      2022.10.10\n","timm                          0.6.12\n","toml                          0.10.2\n","tomli                         2.0.1\n","toolz                         0.12.0\n","torch                         1.10.0+cu111\n","torchaudio                    0.13.0+cu116\n","torchsummary                  1.5.1\n","torchtext                     0.14.0\n","torchvision                   0.11.1+cu111\n","tornado                       6.0.4\n","tqdm                          4.64.1\n","traitlets                     5.6.0\n","ttach                         0.0.3\n","tweepy                        3.10.0\n","typeguard                     2.7.1\n","typer                         0.7.0\n","typing-extensions             4.4.0\n","tzlocal                       1.5.1\n","uritemplate                   3.0.1\n","urllib3                       1.24.3\n","vega-datasets                 0.9.0\n","wasabi                        0.10.1\n","wcwidth                       0.2.5\n","webargs                       8.2.0\n","webencodings                  0.5.1\n","Werkzeug                      1.0.1\n","wheel                         0.38.4\n","widgetsnbextension            3.6.1\n","wordcloud                     1.8.2.2\n","wrapt                         1.14.1\n","xarray                        0.20.2\n","xarray-einstats               0.3.0\n","xgboost                       0.90\n","xkit                          0.0.0\n","xlrd                          1.2.0\n","xlwt                          1.3.0\n","yarl                          1.8.2\n","yellowbrick                   1.5\n","zict                          2.2.0\n","zipp                          3.11.0\n"]}],"source":["!pip list"]},{"cell_type":"markdown","metadata":{"id":"h31KAx1ZZEl9"},"source":["## Start Training\n","* by command line\n","* use argparse to set down hyper-parameter\n","\n","* ViT baseline and ViT + CellMix are trained and compared here."]},{"cell_type":"markdown","metadata":{"id":"--aldMsHOZkP"},"source":["# CLS counterparts"]},{"cell_type":"markdown","metadata":{"id":"QqeBMVh6OjTu"},"source":["* Train"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"C8Li1e1Z2XUS","outputId":"08702bdf-e8df-472d-cff1-ee9438d62984"},"outputs":[{"name":"stdout","output_type":"stream","text":["class_names: ['Negative', 'Positive']\n","*********************************setting*************************************\n","Namespace(Pre_Trained_model_path=None, PromptTuning=None, PromptUnFreeze=False, Prompt_Token_num=20, Prompt_state_path=None, att_module='SimAM', attn_drop_rate=0.0, augmentation_name=None, backbone_PT_off=False, batch_size=8, check_minibatch=None, cls_token_off=False, data_augmentation_mode=0, dataroot='/data/Pathology_Experiment/dataset/ROSE_CLS', draw_root='/home/Pathology_Experiment/runs', drop_path_rate=0.0, drop_rate=0.0, edge_size=384, enable_attention_check=False, enable_notify=False, enable_sam=False, enable_tensorboard=True, enable_visualize_check=False, fix_patch_size=None, fix_position_ratio=None, gpu_idx=-1, intake_epochs=0, linearprobing=False, loss_drive_threshold=4.0, lr=1e-05, lrf=0.25, model_idx='ViT_384_401_PT_lf25_b8_ROSE_CLS', model_path='/home/Pathology_Experiment/saved_models', num_classes=0, num_epochs=50, num_workers=2, opt_name='Adam', paint=True, patch_size_jump=None, patch_strategy='loss_hold', pos_embedding_off=False, ratio_strategy='loss_hold')\n","we dont have more GPU idx here, try to use gpu_idx=0\n","['convit_base',\n"," 'convit_small',\n"," 'convit_tiny',\n"," 'crossvit_9_240',\n"," 'crossvit_9_dagger_240',\n"," 'crossvit_15_240',\n"," 'crossvit_15_dagger_240',\n"," 'crossvit_15_dagger_408',\n"," 'crossvit_18_240',\n"," 'crossvit_18_dagger_240',\n"," 'crossvit_18_dagger_408',\n"," 'crossvit_base_240',\n"," 'crossvit_small_240',\n"," 'crossvit_tiny_240',\n"," 'gcvit_base',\n"," 'gcvit_small',\n"," 'gcvit_tiny',\n"," 'gcvit_xtiny',\n"," 'gcvit_xxtiny',\n"," 'levit_128',\n"," 'levit_128s',\n"," 'levit_192',\n"," 'levit_256',\n"," 'levit_256d',\n"," 'levit_384',\n"," 'maxvit_base_224',\n"," 'maxvit_large_224',\n"," 'maxvit_nano_rw_256',\n"," 'maxvit_pico_rw_256',\n"," 'maxvit_rmlp_nano_rw_256',\n"," 'maxvit_rmlp_pico_rw_256',\n"," 'maxvit_rmlp_small_rw_224',\n"," 'maxvit_rmlp_small_rw_256',\n"," 'maxvit_rmlp_tiny_rw_256',\n"," 'maxvit_small_224',\n"," 'maxvit_tiny_224',\n"," 'maxvit_tiny_pm_256',\n"," 'maxvit_tiny_rw_224',\n"," 'maxvit_tiny_rw_256',\n"," 'maxvit_xlarge_224',\n"," 'maxxvit_rmlp_nano_rw_256',\n"," 'maxxvit_rmlp_small_rw_256',\n"," 'maxxvit_rmlp_tiny_rw_256',\n"," 'mobilevit_s',\n"," 'mobilevit_xs',\n"," 'mobilevit_xxs',\n"," 'mobilevitv2_050',\n"," 'mobilevitv2_075',\n"," 'mobilevitv2_100',\n"," 'mobilevitv2_125',\n"," 'mobilevitv2_150',\n"," 'mobilevitv2_150_384_in22ft1k',\n"," 'mobilevitv2_150_in22ft1k',\n"," 'mobilevitv2_175',\n"," 'mobilevitv2_175_384_in22ft1k',\n"," 'mobilevitv2_175_in22ft1k',\n"," 'mobilevitv2_200',\n"," 'mobilevitv2_200_384_in22ft1k',\n"," 'mobilevitv2_200_in22ft1k',\n"," 'mvitv2_base',\n"," 'mvitv2_large',\n"," 'mvitv2_small',\n"," 'mvitv2_small_cls',\n"," 'mvitv2_tiny',\n"," 'semobilevit_s',\n"," 'vit_base_patch8_224',\n"," 'vit_base_patch8_224_dino',\n"," 'vit_base_patch8_224_in21k',\n"," 'vit_base_patch16_18x2_224',\n"," 'vit_base_patch16_224',\n"," 'vit_base_patch16_224_dino',\n"," 'vit_base_patch16_224_in21k',\n"," 'vit_base_patch16_224_miil',\n"," 'vit_base_patch16_224_miil_in21k',\n"," 'vit_base_patch16_224_sam',\n"," 'vit_base_patch16_384',\n"," 'vit_base_patch16_plus_240',\n"," 'vit_base_patch16_rpn_224',\n"," 'vit_base_patch32_224',\n"," 'vit_base_patch32_224_clip_laion2b',\n"," 'vit_base_patch32_224_in21k',\n"," 'vit_base_patch32_224_sam',\n"," 'vit_base_patch32_384',\n"," 'vit_base_patch32_plus_256',\n"," 'vit_base_r26_s32_224',\n"," 'vit_base_r50_s16_224',\n"," 'vit_base_r50_s16_224_in21k',\n"," 'vit_base_r50_s16_384',\n"," 'vit_base_resnet26d_224',\n"," 'vit_base_resnet50_224_in21k',\n"," 'vit_base_resnet50_384',\n"," 'vit_base_resnet50d_224',\n"," 'vit_giant_patch14_224',\n"," 'vit_giant_patch14_224_clip_laion2b',\n"," 'vit_gigantic_patch14_224',\n"," 'vit_huge_patch14_224',\n"," 'vit_huge_patch14_224_clip_laion2b',\n"," 'vit_huge_patch14_224_in21k',\n"," 'vit_large_patch14_224',\n"," 'vit_large_patch14_224_clip_laion2b',\n"," 'vit_large_patch16_224',\n"," 'vit_large_patch16_224_in21k',\n"," 'vit_large_patch16_384',\n"," 'vit_large_patch32_224',\n"," 'vit_large_patch32_224_in21k',\n"," 'vit_large_patch32_384',\n"," 'vit_large_r50_s32_224',\n"," 'vit_large_r50_s32_224_in21k',\n"," 'vit_large_r50_s32_384',\n"," 'vit_relpos_base_patch16_224',\n"," 'vit_relpos_base_patch16_cls_224',\n"," 'vit_relpos_base_patch16_clsgap_224',\n"," 'vit_relpos_base_patch16_plus_240',\n"," 'vit_relpos_base_patch16_rpn_224',\n"," 'vit_relpos_base_patch32_plus_rpn_256',\n"," 'vit_relpos_medium_patch16_224',\n"," 'vit_relpos_medium_patch16_cls_224',\n"," 'vit_relpos_medium_patch16_rpn_224',\n"," 'vit_relpos_small_patch16_224',\n"," 'vit_relpos_small_patch16_rpn_224',\n"," 'vit_small_patch8_224_dino',\n"," 'vit_small_patch16_18x2_224',\n"," 'vit_small_patch16_36x1_224',\n"," 'vit_small_patch16_224',\n"," 'vit_small_patch16_224_dino',\n"," 'vit_small_patch16_224_in21k',\n"," 'vit_small_patch16_384',\n"," 'vit_small_patch32_224',\n"," 'vit_small_patch32_224_in21k',\n"," 'vit_small_patch32_384',\n"," 'vit_small_r26_s32_224',\n"," 'vit_small_r26_s32_224_in21k',\n"," 'vit_small_r26_s32_384',\n"," 'vit_small_resnet26d_224',\n"," 'vit_small_resnet50d_s16_224',\n"," 'vit_srelpos_medium_patch16_224',\n"," 'vit_srelpos_small_patch16_224',\n"," 'vit_tiny_patch16_224',\n"," 'vit_tiny_patch16_224_in21k',\n"," 'vit_tiny_patch16_384',\n"," 'vit_tiny_r_s16_p8_224',\n"," 'vit_tiny_r_s16_p8_224_in21k',\n"," 'vit_tiny_r_s16_p8_384']\n","test model output： tensor([[ 0.9823, -1.2481]], grad_fn=<AddmmBackward0>)\n","model is ready now!\n","GPU: 0\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1          [-1, 768, 24, 24]         590,592\n","          Identity-2             [-1, 576, 768]               0\n","        PatchEmbed-3             [-1, 576, 768]               0\n","           Dropout-4             [-1, 577, 768]               0\n","          Identity-5             [-1, 577, 768]               0\n","         LayerNorm-6             [-1, 577, 768]           1,536\n","            Linear-7            [-1, 577, 2304]       1,771,776\n","           Dropout-8         [-1, 12, 577, 577]               0\n","            Linear-9             [-1, 577, 768]         590,592\n","          Dropout-10             [-1, 577, 768]               0\n","        Attention-11             [-1, 577, 768]               0\n","         Identity-12             [-1, 577, 768]               0\n","         Identity-13             [-1, 577, 768]               0\n","        LayerNorm-14             [-1, 577, 768]           1,536\n","           Linear-15            [-1, 577, 3072]       2,362,368\n","             GELU-16            [-1, 577, 3072]               0\n","          Dropout-17            [-1, 577, 3072]               0\n","           Linear-18             [-1, 577, 768]       2,360,064\n","          Dropout-19             [-1, 577, 768]               0\n","              Mlp-20             [-1, 577, 768]               0\n","         Identity-21             [-1, 577, 768]               0\n","         Identity-22             [-1, 577, 768]               0\n","            Block-23             [-1, 577, 768]               0\n","        LayerNorm-24             [-1, 577, 768]           1,536\n","           Linear-25            [-1, 577, 2304]       1,771,776\n","          Dropout-26         [-1, 12, 577, 577]               0\n","           Linear-27             [-1, 577, 768]         590,592\n","          Dropout-28             [-1, 577, 768]               0\n","        Attention-29             [-1, 577, 768]               0\n","         Identity-30             [-1, 577, 768]               0\n","         Identity-31             [-1, 577, 768]               0\n","        LayerNorm-32             [-1, 577, 768]           1,536\n","           Linear-33            [-1, 577, 3072]       2,362,368\n","             GELU-34            [-1, 577, 3072]               0\n","          Dropout-35            [-1, 577, 3072]               0\n","           Linear-36             [-1, 577, 768]       2,360,064\n","          Dropout-37             [-1, 577, 768]               0\n","              Mlp-38             [-1, 577, 768]               0\n","         Identity-39             [-1, 577, 768]               0\n","         Identity-40             [-1, 577, 768]               0\n","            Block-41             [-1, 577, 768]               0\n","        LayerNorm-42             [-1, 577, 768]           1,536\n","           Linear-43            [-1, 577, 2304]       1,771,776\n","          Dropout-44         [-1, 12, 577, 577]               0\n","           Linear-45             [-1, 577, 768]         590,592\n","          Dropout-46             [-1, 577, 768]               0\n","        Attention-47             [-1, 577, 768]               0\n","         Identity-48             [-1, 577, 768]               0\n","         Identity-49             [-1, 577, 768]               0\n","        LayerNorm-50             [-1, 577, 768]           1,536\n","           Linear-51            [-1, 577, 3072]       2,362,368\n","             GELU-52            [-1, 577, 3072]               0\n","          Dropout-53            [-1, 577, 3072]               0\n","           Linear-54             [-1, 577, 768]       2,360,064\n","          Dropout-55             [-1, 577, 768]               0\n","              Mlp-56             [-1, 577, 768]               0\n","         Identity-57             [-1, 577, 768]               0\n","         Identity-58             [-1, 577, 768]               0\n","            Block-59             [-1, 577, 768]               0\n","        LayerNorm-60             [-1, 577, 768]           1,536\n","           Linear-61            [-1, 577, 2304]       1,771,776\n","          Dropout-62         [-1, 12, 577, 577]               0\n","           Linear-63             [-1, 577, 768]         590,592\n","          Dropout-64             [-1, 577, 768]               0\n","        Attention-65             [-1, 577, 768]               0\n","         Identity-66             [-1, 577, 768]               0\n","         Identity-67             [-1, 577, 768]               0\n","        LayerNorm-68             [-1, 577, 768]           1,536\n","           Linear-69            [-1, 577, 3072]       2,362,368\n","             GELU-70            [-1, 577, 3072]               0\n","          Dropout-71            [-1, 577, 3072]               0\n","           Linear-72             [-1, 577, 768]       2,360,064\n","          Dropout-73             [-1, 577, 768]               0\n","              Mlp-74             [-1, 577, 768]               0\n","         Identity-75             [-1, 577, 768]               0\n","         Identity-76             [-1, 577, 768]               0\n","            Block-77             [-1, 577, 768]               0\n","        LayerNorm-78             [-1, 577, 768]           1,536\n","           Linear-79            [-1, 577, 2304]       1,771,776\n","          Dropout-80         [-1, 12, 577, 577]               0\n","           Linear-81             [-1, 577, 768]         590,592\n","          Dropout-82             [-1, 577, 768]               0\n","        Attention-83             [-1, 577, 768]               0\n","         Identity-84             [-1, 577, 768]               0\n","         Identity-85             [-1, 577, 768]               0\n","        LayerNorm-86             [-1, 577, 768]           1,536\n","           Linear-87            [-1, 577, 3072]       2,362,368\n","             GELU-88            [-1, 577, 3072]               0\n","          Dropout-89            [-1, 577, 3072]               0\n","           Linear-90             [-1, 577, 768]       2,360,064\n","          Dropout-91             [-1, 577, 768]               0\n","              Mlp-92             [-1, 577, 768]               0\n","         Identity-93             [-1, 577, 768]               0\n","         Identity-94             [-1, 577, 768]               0\n","            Block-95             [-1, 577, 768]               0\n","        LayerNorm-96             [-1, 577, 768]           1,536\n","           Linear-97            [-1, 577, 2304]       1,771,776\n","          Dropout-98         [-1, 12, 577, 577]               0\n","           Linear-99             [-1, 577, 768]         590,592\n","         Dropout-100             [-1, 577, 768]               0\n","       Attention-101             [-1, 577, 768]               0\n","        Identity-102             [-1, 577, 768]               0\n","        Identity-103             [-1, 577, 768]               0\n","       LayerNorm-104             [-1, 577, 768]           1,536\n","          Linear-105            [-1, 577, 3072]       2,362,368\n","            GELU-106            [-1, 577, 3072]               0\n","         Dropout-107            [-1, 577, 3072]               0\n","          Linear-108             [-1, 577, 768]       2,360,064\n","         Dropout-109             [-1, 577, 768]               0\n","             Mlp-110             [-1, 577, 768]               0\n","        Identity-111             [-1, 577, 768]               0\n","        Identity-112             [-1, 577, 768]               0\n","           Block-113             [-1, 577, 768]               0\n","       LayerNorm-114             [-1, 577, 768]           1,536\n","          Linear-115            [-1, 577, 2304]       1,771,776\n","         Dropout-116         [-1, 12, 577, 577]               0\n","          Linear-117             [-1, 577, 768]         590,592\n","         Dropout-118             [-1, 577, 768]               0\n","       Attention-119             [-1, 577, 768]               0\n","        Identity-120             [-1, 577, 768]               0\n","        Identity-121             [-1, 577, 768]               0\n","       LayerNorm-122             [-1, 577, 768]           1,536\n","          Linear-123            [-1, 577, 3072]       2,362,368\n","            GELU-124            [-1, 577, 3072]               0\n","         Dropout-125            [-1, 577, 3072]               0\n","          Linear-126             [-1, 577, 768]       2,360,064\n","         Dropout-127             [-1, 577, 768]               0\n","             Mlp-128             [-1, 577, 768]               0\n","        Identity-129             [-1, 577, 768]               0\n","        Identity-130             [-1, 577, 768]               0\n","           Block-131             [-1, 577, 768]               0\n","       LayerNorm-132             [-1, 577, 768]           1,536\n","          Linear-133            [-1, 577, 2304]       1,771,776\n","         Dropout-134         [-1, 12, 577, 577]               0\n","          Linear-135             [-1, 577, 768]         590,592\n","         Dropout-136             [-1, 577, 768]               0\n","       Attention-137             [-1, 577, 768]               0\n","        Identity-138             [-1, 577, 768]               0\n","        Identity-139             [-1, 577, 768]               0\n","       LayerNorm-140             [-1, 577, 768]           1,536\n","          Linear-141            [-1, 577, 3072]       2,362,368\n","            GELU-142            [-1, 577, 3072]               0\n","         Dropout-143            [-1, 577, 3072]               0\n","          Linear-144             [-1, 577, 768]       2,360,064\n","         Dropout-145             [-1, 577, 768]               0\n","             Mlp-146             [-1, 577, 768]               0\n","        Identity-147             [-1, 577, 768]               0\n","        Identity-148             [-1, 577, 768]               0\n","           Block-149             [-1, 577, 768]               0\n","       LayerNorm-150             [-1, 577, 768]           1,536\n","          Linear-151            [-1, 577, 2304]       1,771,776\n","         Dropout-152         [-1, 12, 577, 577]               0\n","          Linear-153             [-1, 577, 768]         590,592\n","         Dropout-154             [-1, 577, 768]               0\n","       Attention-155             [-1, 577, 768]               0\n","        Identity-156             [-1, 577, 768]               0\n","        Identity-157             [-1, 577, 768]               0\n","       LayerNorm-158             [-1, 577, 768]           1,536\n","          Linear-159            [-1, 577, 3072]       2,362,368\n","            GELU-160            [-1, 577, 3072]               0\n","         Dropout-161            [-1, 577, 3072]               0\n","          Linear-162             [-1, 577, 768]       2,360,064\n","         Dropout-163             [-1, 577, 768]               0\n","             Mlp-164             [-1, 577, 768]               0\n","        Identity-165             [-1, 577, 768]               0\n","        Identity-166             [-1, 577, 768]               0\n","           Block-167             [-1, 577, 768]               0\n","       LayerNorm-168             [-1, 577, 768]           1,536\n","          Linear-169            [-1, 577, 2304]       1,771,776\n","         Dropout-170         [-1, 12, 577, 577]               0\n","          Linear-171             [-1, 577, 768]         590,592\n","         Dropout-172             [-1, 577, 768]               0\n","       Attention-173             [-1, 577, 768]               0\n","        Identity-174             [-1, 577, 768]               0\n","        Identity-175             [-1, 577, 768]               0\n","       LayerNorm-176             [-1, 577, 768]           1,536\n","          Linear-177            [-1, 577, 3072]       2,362,368\n","            GELU-178            [-1, 577, 3072]               0\n","         Dropout-179            [-1, 577, 3072]               0\n","          Linear-180             [-1, 577, 768]       2,360,064\n","         Dropout-181             [-1, 577, 768]               0\n","             Mlp-182             [-1, 577, 768]               0\n","        Identity-183             [-1, 577, 768]               0\n","        Identity-184             [-1, 577, 768]               0\n","           Block-185             [-1, 577, 768]               0\n","       LayerNorm-186             [-1, 577, 768]           1,536\n","          Linear-187            [-1, 577, 2304]       1,771,776\n","         Dropout-188         [-1, 12, 577, 577]               0\n","          Linear-189             [-1, 577, 768]         590,592\n","         Dropout-190             [-1, 577, 768]               0\n","       Attention-191             [-1, 577, 768]               0\n","        Identity-192             [-1, 577, 768]               0\n","        Identity-193             [-1, 577, 768]               0\n","       LayerNorm-194             [-1, 577, 768]           1,536\n","          Linear-195            [-1, 577, 3072]       2,362,368\n","            GELU-196            [-1, 577, 3072]               0\n","         Dropout-197            [-1, 577, 3072]               0\n","          Linear-198             [-1, 577, 768]       2,360,064\n","         Dropout-199             [-1, 577, 768]               0\n","             Mlp-200             [-1, 577, 768]               0\n","        Identity-201             [-1, 577, 768]               0\n","        Identity-202             [-1, 577, 768]               0\n","           Block-203             [-1, 577, 768]               0\n","       LayerNorm-204             [-1, 577, 768]           1,536\n","          Linear-205            [-1, 577, 2304]       1,771,776\n","         Dropout-206         [-1, 12, 577, 577]               0\n","          Linear-207             [-1, 577, 768]         590,592\n","         Dropout-208             [-1, 577, 768]               0\n","       Attention-209             [-1, 577, 768]               0\n","        Identity-210             [-1, 577, 768]               0\n","        Identity-211             [-1, 577, 768]               0\n","       LayerNorm-212             [-1, 577, 768]           1,536\n","          Linear-213            [-1, 577, 3072]       2,362,368\n","            GELU-214            [-1, 577, 3072]               0\n","         Dropout-215            [-1, 577, 3072]               0\n","          Linear-216             [-1, 577, 768]       2,360,064\n","         Dropout-217             [-1, 577, 768]               0\n","             Mlp-218             [-1, 577, 768]               0\n","        Identity-219             [-1, 577, 768]               0\n","        Identity-220             [-1, 577, 768]               0\n","           Block-221             [-1, 577, 768]               0\n","       LayerNorm-222             [-1, 577, 768]           1,536\n","        Identity-223                  [-1, 768]               0\n","          Linear-224                    [-1, 2]           1,538\n","================================================================\n","Total params: 85,648,130\n","Trainable params: 85,648,130\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 1.69\n","Forward/backward pass size (MB): 1522.01\n","Params size (MB): 326.72\n","Estimated Total Size (MB): 1850.42\n","----------------------------------------------------------------\n","model : ViT_384_401_PT_lf25_b8_ROSE_CLS\n","no valid counterparts augmentation selected\n","Epoch 1/50\n","----------\n","Epoch: 1     train index of 50 minibatch: 1      time used: 47.4305682182312\n","minibatch AVG loss: 0.7099431040138007\n","Epoch: 1     train index of 50 minibatch: 2      time used: 51.39685344696045\n","minibatch AVG loss: 0.5171096692979336\n","Epoch: 1     train index of 50 minibatch: 3      time used: 50.20023274421692\n","minibatch AVG loss: 0.3304007609374821\n","Epoch: 1     train index of 50 minibatch: 4      time used: 50.59788990020752\n","minibatch AVG loss: 0.3714101116359234\n","Epoch: 1     train index of 50 minibatch: 5      time used: 50.462116956710815\n","minibatch AVG loss: 0.27695039320737125\n","Epoch: 1     train index of 50 minibatch: 6      time used: 50.699535846710205\n","minibatch AVG loss: 0.39560961730778216\n","Epoch: 1     train index of 50 minibatch: 7      time used: 50.388394594192505\n","minibatch AVG loss: 0.27876874469220636\n","Epoch: 1     train index of 50 minibatch: 8      time used: 50.51951718330383\n","minibatch AVG loss: 0.25389480479061605\n","\n","Epoch: 1  train \n","Loss: 0.3809  Acc: 83.7216\n","Negative precision: 86.2313  recall: 89.3920\n","Negative sensitivity: 89.3920  specificity: 73.3280\n","Negative FPR: 26.6720  NPV: 78.7197\n","Negative TP: 2073.0\n","Negative TN: 910.0\n","Negative FP: 331.0\n","Negative FN: 246.0\n","Positive precision: 78.7197  recall: 73.3280\n","Positive sensitivity: 73.3280  specificity: 89.3920\n","Positive FPR: 10.6080  NPV: 86.2313\n","Positive TP: 910.0\n","Positive TN: 2073.0\n","Positive FP: 246.0\n","Positive FN: 331.0\n","\n","\n","Epoch: 1     val index of 50 minibatch: 1      time used: 19.355077028274536\n","minibatch AVG loss: 0.12964691115543248\n","\n","Epoch: 1  val \n","Loss: 0.2598  Acc: 87.2299\n","Negative precision: 86.1702  recall: 97.5904\n","Negative sensitivity: 97.5904  specificity: 69.7674\n","Negative FPR: 30.2326  NPV: 93.7500\n","Negative TP: 324.0\n","Negative TN: 120.0\n","Negative FP: 52.0\n","Negative FN: 8.0\n","Positive precision: 93.7500  recall: 69.7674\n","Positive sensitivity: 69.7674  specificity: 97.5904\n","Positive FPR: 2.4096  NPV: 86.1702\n","Positive TP: 120.0\n","Positive TN: 324.0\n","Positive FP: 8.0\n","Positive FN: 52.0\n","\n","\n","\n","Epoch 2/50\n","----------\n","Epoch: 2     train index of 50 minibatch: 1      time used: 51.00884532928467\n","minibatch AVG loss: 0.23799644239246845\n","Epoch: 2     train index of 50 minibatch: 2      time used: 50.629327058792114\n","minibatch AVG loss: 0.4403261686861515\n","Epoch: 2     train index of 50 minibatch: 3      time used: 50.657262086868286\n","minibatch AVG loss: 0.17029704275541008\n","Epoch: 2     train index of 50 minibatch: 4      time used: 50.437034130096436\n","minibatch AVG loss: 0.2719058238714933\n","Epoch: 2     train index of 50 minibatch: 5      time used: 50.53132462501526\n","minibatch AVG loss: 0.20919235890731216\n","Epoch: 2     train index of 50 minibatch: 6      time used: 50.658440828323364\n","minibatch AVG loss: 0.1719825871195644\n","Epoch: 2     train index of 50 minibatch: 7      time used: 50.60081505775452\n","minibatch AVG loss: 0.20945179587230087\n","Epoch: 2     train index of 50 minibatch: 8      time used: 50.577232360839844\n","minibatch AVG loss: 0.23061588138341904\n","\n","Epoch: 2  train \n","Loss: 0.2391  Acc: 90.1488\n","Negative precision: 91.4947  recall: 93.7042\n","Negative sensitivity: 93.7042  specificity: 83.7228\n","Negative FPR: 16.2772  NPV: 87.6793\n","Negative TP: 2173.0\n","Negative TN: 1039.0\n","Negative FP: 202.0\n","Negative FN: 146.0\n","Positive precision: 87.6793  recall: 83.7228\n","Positive sensitivity: 83.7228  specificity: 93.7042\n","Positive FPR: 6.2958  NPV: 91.4947\n","Positive TP: 1039.0\n","Positive TN: 2173.0\n","Positive FP: 146.0\n","Positive FN: 202.0\n","\n","\n","Epoch: 2     val index of 50 minibatch: 1      time used: 19.297740697860718\n","minibatch AVG loss: 0.4017246557259932\n","\n","Epoch: 2  val \n","Loss: 0.3300  Acc: 87.2299\n","Negative precision: 99.6350  recall: 82.2289\n","Negative sensitivity: 82.2289  specificity: 99.4186\n","Negative FPR: 0.5814  NPV: 74.3478\n","Negative TP: 273.0\n","Negative TN: 171.0\n","Negative FP: 1.0\n","Negative FN: 59.0\n","Positive precision: 74.3478  recall: 99.4186\n","Positive sensitivity: 99.4186  specificity: 82.2289\n","Positive FPR: 17.7711  NPV: 99.6350\n","Positive TP: 171.0\n","Positive TN: 273.0\n","Positive FP: 59.0\n","Positive FN: 1.0\n","\n","\n","\n","Epoch 3/50\n","----------\n","Epoch: 3     train index of 50 minibatch: 1      time used: 51.15509843826294\n","minibatch AVG loss: 0.24640254320576788\n","Epoch: 3     train index of 50 minibatch: 2      time used: 50.72490358352661\n","minibatch AVG loss: 0.18630095651373269\n","Epoch: 3     train index of 50 minibatch: 3      time used: 50.49765753746033\n","minibatch AVG loss: 0.13530883947270922\n","Epoch: 3     train index of 50 minibatch: 4      time used: 50.71194386482239\n","minibatch AVG loss: 0.23043402316980063\n","Epoch: 3     train index of 50 minibatch: 5      time used: 50.405622720718384\n","minibatch AVG loss: 0.17856334064155818\n","Epoch: 3     train index of 50 minibatch: 6      time used: 50.667065382003784\n","minibatch AVG loss: 0.18922914787195622\n","Epoch: 3     train index of 50 minibatch: 7      time used: 50.58953881263733\n","minibatch AVG loss: 0.25565529718063773\n","Epoch: 3     train index of 50 minibatch: 8      time used: 50.436885833740234\n","minibatch AVG loss: 0.2717774034291506\n","\n","Epoch: 3  train \n","Loss: 0.2093  Acc: 91.0749\n","Negative precision: 92.4249  recall: 94.1379\n","Negative sensitivity: 94.1379  specificity: 85.5645\n","Negative FPR: 14.4355  NPV: 88.6383\n","Negative TP: 2184.0\n","Negative TN: 1061.0\n","Negative FP: 179.0\n","Negative FN: 136.0\n","Positive precision: 88.6383  recall: 85.5645\n","Positive sensitivity: 85.5645  specificity: 94.1379\n","Positive FPR: 5.8621  NPV: 92.4249\n","Positive TP: 1061.0\n","Positive TN: 2184.0\n","Positive FP: 136.0\n","Positive FN: 179.0\n","\n","\n","Epoch: 3     val index of 50 minibatch: 1      time used: 19.383353233337402\n","minibatch AVG loss: 0.26472765041515234\n","\n","Epoch: 3  val \n","Loss: 0.2464  Acc: 88.6051\n","Negative precision: 96.6555  recall: 87.0482\n","Negative sensitivity: 87.0482  specificity: 94.1860\n","Negative FPR: 5.8140  NPV: 79.0244\n","Negative TP: 289.0\n","Negative TN: 162.0\n","Negative FP: 10.0\n","Negative FN: 43.0\n","Positive precision: 79.0244  recall: 94.1860\n","Positive sensitivity: 94.1860  specificity: 87.0482\n","Positive FPR: 12.9518  NPV: 96.6555\n","Positive TP: 162.0\n","Positive TN: 289.0\n","Positive FP: 43.0\n","Positive FN: 10.0\n","\n","\n","\n","Epoch 4/50\n","----------\n","Epoch: 4     train index of 50 minibatch: 1      time used: 51.20478010177612\n","minibatch AVG loss: 0.11080615484155715\n","Epoch: 4     train index of 50 minibatch: 2      time used: 50.6344211101532\n","minibatch AVG loss: 0.1546294077858329\n","Epoch: 4     train index of 50 minibatch: 3      time used: 50.6850483417511\n","minibatch AVG loss: 0.19814532133750618\n","Epoch: 4     train index of 50 minibatch: 4      time used: 50.70363140106201\n","minibatch AVG loss: 0.19987220318987967\n","Epoch: 4     train index of 50 minibatch: 5      time used: 50.647605657577515\n","minibatch AVG loss: 0.16385461053811012\n","Epoch: 4     train index of 50 minibatch: 6      time used: 50.58945560455322\n","minibatch AVG loss: 0.23199577605351807\n","Epoch: 4     train index of 50 minibatch: 7      time used: 50.623023986816406\n","minibatch AVG loss: 0.17732480634003878\n","Epoch: 4     train index of 50 minibatch: 8      time used: 50.54782795906067\n","minibatch AVG loss: 0.19056314595043658\n","\n","Epoch: 4  train \n","Loss: 0.1786  Acc: 92.9273\n","Negative precision: 93.8188  recall: 95.5584\n","Negative sensitivity: 95.5584  specificity: 88.2353\n","Negative FPR: 11.7647  NPV: 91.4023\n","Negative TP: 2216.0\n","Negative TN: 1095.0\n","Negative FP: 146.0\n","Negative FN: 103.0\n","Positive precision: 91.4023  recall: 88.2353\n","Positive sensitivity: 88.2353  specificity: 95.5584\n","Positive FPR: 4.4416  NPV: 93.8188\n","Positive TP: 1095.0\n","Positive TN: 2216.0\n","Positive FP: 103.0\n","Positive FN: 146.0\n","\n","\n","Epoch: 4     val index of 50 minibatch: 1      time used: 19.399455308914185\n","minibatch AVG loss: 0.11896243959461572\n","\n","Epoch: 4  val \n","Loss: 0.2979  Acc: 86.0511\n","Negative precision: 83.5859  recall: 99.6988\n","Negative sensitivity: 99.6988  specificity: 62.2093\n","Negative FPR: 37.7907  NPV: 99.0741\n","Negative TP: 331.0\n","Negative TN: 107.0\n","Negative FP: 65.0\n","Negative FN: 1.0\n","Positive precision: 99.0741  recall: 62.2093\n","Positive sensitivity: 62.2093  specificity: 99.6988\n","Positive FPR: 0.3012  NPV: 83.5859\n","Positive TP: 107.0\n","Positive TN: 331.0\n","Positive FP: 1.0\n","Positive FN: 65.0\n","\n","\n","\n","Epoch 5/50\n","----------\n","Epoch: 5     train index of 50 minibatch: 1      time used: 51.45196056365967\n","minibatch AVG loss: 0.19825805209577083\n","Epoch: 5     train index of 50 minibatch: 2      time used: 50.58428192138672\n","minibatch AVG loss: 0.16639762880280615\n","Epoch: 5     train index of 50 minibatch: 3      time used: 50.87809371948242\n","minibatch AVG loss: 0.18573208626825363\n","Epoch: 5     train index of 50 minibatch: 4      time used: 50.720248222351074\n","minibatch AVG loss: 0.1486703368742019\n","Epoch: 5     train index of 50 minibatch: 5      time used: 50.72796559333801\n","minibatch AVG loss: 0.17252414040267466\n","Epoch: 5     train index of 50 minibatch: 6      time used: 50.56668663024902\n","minibatch AVG loss: 0.18382180294953288\n","Epoch: 5     train index of 50 minibatch: 7      time used: 50.52379488945007\n","minibatch AVG loss: 0.1055268086004071\n","Epoch: 5     train index of 50 minibatch: 8      time used: 50.49205446243286\n","minibatch AVG loss: 0.20555762011557818\n","\n","Epoch: 5  train \n","Loss: 0.1709  Acc: 92.7870\n","Negative precision: 93.7685  recall: 95.3859\n","Negative sensitivity: 95.3859  specificity: 88.1547\n","Negative FPR: 11.8453  NPV: 91.0908\n","Negative TP: 2212.0\n","Negative TN: 1094.0\n","Negative FP: 147.0\n","Negative FN: 107.0\n","Positive precision: 91.0908  recall: 88.1547\n","Positive sensitivity: 88.1547  specificity: 95.3859\n","Positive FPR: 4.6141  NPV: 93.7685\n","Positive TP: 1094.0\n","Positive TN: 2212.0\n","Positive FP: 107.0\n","Positive FN: 147.0\n","\n","\n","Epoch: 5     val index of 50 minibatch: 1      time used: 19.363754987716675\n","minibatch AVG loss: 0.11296507061284501\n","\n","Epoch: 5  val \n","Loss: 0.1998  Acc: 90.7662\n","Negative precision: 91.1932  recall: 96.6867\n","Negative sensitivity: 96.6867  specificity: 81.9767\n","Negative FPR: 18.0233  NPV: 92.7632\n","Negative TP: 321.0\n","Negative TN: 141.0\n","Negative FP: 31.0\n","Negative FN: 11.0\n","Positive precision: 92.7632  recall: 81.9767\n","Positive sensitivity: 81.9767  specificity: 96.6867\n","Positive FPR: 3.3133  NPV: 91.1932\n","Positive TP: 141.0\n","Positive TN: 321.0\n","Positive FP: 11.0\n","Positive FN: 31.0\n","\n","\n","\n","Epoch 6/50\n","----------\n","Epoch: 6     train index of 50 minibatch: 1      time used: 51.285964012145996\n","minibatch AVG loss: 0.12050458118785173\n","Epoch: 6     train index of 50 minibatch: 2      time used: 50.720670223236084\n","minibatch AVG loss: 0.1984137528249994\n","Epoch: 6     train index of 50 minibatch: 3      time used: 50.68362259864807\n","minibatch AVG loss: 0.14586476939730347\n","Epoch: 6     train index of 50 minibatch: 4      time used: 50.778592348098755\n","minibatch AVG loss: 0.17441448137164117\n","Epoch: 6     train index of 50 minibatch: 5      time used: 50.56392550468445\n","minibatch AVG loss: 0.17657214091159404\n","Epoch: 6     train index of 50 minibatch: 6      time used: 50.85328412055969\n","minibatch AVG loss: 0.11614124843850732\n","Epoch: 6     train index of 50 minibatch: 7      time used: 50.5258514881134\n","minibatch AVG loss: 0.16126555471506435\n","Epoch: 6     train index of 50 minibatch: 8      time used: 50.65105390548706\n","minibatch AVG loss: 0.21290772478561848\n","\n","Epoch: 6  train \n","Loss: 0.1730  Acc: 93.2080\n","Negative precision: 93.9189  recall: 95.9034\n","Negative sensitivity: 95.9034  specificity: 88.3965\n","Negative FPR: 11.6035  NPV: 92.0302\n","Negative TP: 2224.0\n","Negative TN: 1097.0\n","Negative FP: 144.0\n","Negative FN: 95.0\n","Positive precision: 92.0302  recall: 88.3965\n","Positive sensitivity: 88.3965  specificity: 95.9034\n","Positive FPR: 4.0966  NPV: 93.9189\n","Positive TP: 1097.0\n","Positive TN: 2224.0\n","Positive FP: 95.0\n","Positive FN: 144.0\n","\n","\n","Epoch: 6     val index of 50 minibatch: 1      time used: 19.388012170791626\n","minibatch AVG loss: 0.17126531893911306\n","\n","Epoch: 6  val \n","Loss: 0.2158  Acc: 90.1768\n","Negative precision: 92.8358  recall: 93.6747\n","Negative sensitivity: 93.6747  specificity: 86.0465\n","Negative FPR: 13.9535  NPV: 87.5740\n","Negative TP: 311.0\n","Negative TN: 148.0\n","Negative FP: 24.0\n","Negative FN: 21.0\n","Positive precision: 87.5740  recall: 86.0465\n","Positive sensitivity: 86.0465  specificity: 93.6747\n","Positive FPR: 6.3253  NPV: 92.8358\n","Positive TP: 148.0\n","Positive TN: 311.0\n","Positive FP: 21.0\n","Positive FN: 24.0\n","\n","\n","\n","Epoch 7/50\n","----------\n","Epoch: 7     train index of 50 minibatch: 1      time used: 51.233046770095825\n","minibatch AVG loss: 0.11251748529728502\n","Epoch: 7     train index of 50 minibatch: 2      time used: 50.728148460388184\n","minibatch AVG loss: 0.14950492684263736\n","Epoch: 7     train index of 50 minibatch: 3      time used: 50.67150926589966\n","minibatch AVG loss: 0.14618009113706648\n","Epoch: 7     train index of 50 minibatch: 4      time used: 50.702229022979736\n","minibatch AVG loss: 0.1539346219599247\n","Epoch: 7     train index of 50 minibatch: 5      time used: 50.70763969421387\n","minibatch AVG loss: 0.18014314584899693\n","Epoch: 7     train index of 50 minibatch: 6      time used: 50.532604694366455\n","minibatch AVG loss: 0.12965292277745902\n","Epoch: 7     train index of 50 minibatch: 7      time used: 50.46546244621277\n","minibatch AVG loss: 0.16345727340551094\n","Epoch: 7     train index of 50 minibatch: 8      time used: 50.53594636917114\n","minibatch AVG loss: 0.2171314222365618\n","\n","Epoch: 7  train \n","Loss: 0.1536  Acc: 93.8816\n","Negative precision: 94.6520  recall: 96.1621\n","Negative sensitivity: 96.1621  specificity: 89.8469\n","Negative FPR: 10.1531  NPV: 92.6080\n","Negative TP: 2230.0\n","Negative TN: 1115.0\n","Negative FP: 126.0\n","Negative FN: 89.0\n","Positive precision: 92.6080  recall: 89.8469\n","Positive sensitivity: 89.8469  specificity: 96.1621\n","Positive FPR: 3.8379  NPV: 94.6520\n","Positive TP: 1115.0\n","Positive TN: 2230.0\n","Positive FP: 89.0\n","Positive FN: 126.0\n","\n","\n","Epoch: 7     val index of 50 minibatch: 1      time used: 19.373623371124268\n","minibatch AVG loss: 0.1287607178777398\n","\n","Epoch: 7  val \n","Loss: 0.2349  Acc: 90.5697\n","Negative precision: 91.1681  recall: 96.3855\n","Negative sensitivity: 96.3855  specificity: 81.9767\n","Negative FPR: 18.0233  NPV: 92.1569\n","Negative TP: 320.0\n","Negative TN: 141.0\n","Negative FP: 31.0\n","Negative FN: 12.0\n","Positive precision: 92.1569  recall: 81.9767\n","Positive sensitivity: 81.9767  specificity: 96.3855\n","Positive FPR: 3.6145  NPV: 91.1681\n","Positive TP: 141.0\n","Positive TN: 320.0\n","Positive FP: 12.0\n","Positive FN: 31.0\n","\n","\n","\n","Epoch 8/50\n","----------\n","Epoch: 8     train index of 50 minibatch: 1      time used: 51.27262616157532\n","minibatch AVG loss: 0.1483206672500819\n","Epoch: 8     train index of 50 minibatch: 2      time used: 50.693785190582275\n","minibatch AVG loss: 0.1623037078604102\n","Epoch: 8     train index of 50 minibatch: 3      time used: 50.782697916030884\n","minibatch AVG loss: 0.14680764847900718\n","Epoch: 8     train index of 50 minibatch: 4      time used: 50.77304816246033\n","minibatch AVG loss: 0.1434037874918431\n","Epoch: 8     train index of 50 minibatch: 5      time used: 50.72331357002258\n","minibatch AVG loss: 0.16934329303912818\n","Epoch: 8     train index of 50 minibatch: 6      time used: 50.720319986343384\n","minibatch AVG loss: 0.15662906116805972\n","Epoch: 8     train index of 50 minibatch: 7      time used: 50.7004120349884\n","minibatch AVG loss: 0.15256441372912377\n","Epoch: 8     train index of 50 minibatch: 8      time used: 50.62021780014038\n","minibatch AVG loss: 0.20674920627847315\n","\n","Epoch: 8  train \n","Loss: 0.1606  Acc: 93.2360\n","Negative precision: 94.3734  recall: 95.4310\n","Negative sensitivity: 95.4310  specificity: 89.3548\n","Negative FPR: 10.6452  NPV: 91.2685\n","Negative TP: 2214.0\n","Negative TN: 1108.0\n","Negative FP: 132.0\n","Negative FN: 106.0\n","Positive precision: 91.2685  recall: 89.3548\n","Positive sensitivity: 89.3548  specificity: 95.4310\n","Positive FPR: 4.5690  NPV: 94.3734\n","Positive TP: 1108.0\n","Positive TN: 2214.0\n","Positive FP: 106.0\n","Positive FN: 132.0\n","\n","\n","Epoch: 8     val index of 50 minibatch: 1      time used: 19.337124586105347\n","minibatch AVG loss: 0.33977676300215537\n","\n","Epoch: 8  val \n","Loss: 0.2942  Acc: 87.8193\n","Negative precision: 97.9094  recall: 84.6386\n","Negative sensitivity: 84.6386  specificity: 96.5116\n","Negative FPR: 3.4884  NPV: 76.4977\n","Negative TP: 281.0\n","Negative TN: 166.0\n","Negative FP: 6.0\n","Negative FN: 51.0\n","Positive precision: 76.4977  recall: 96.5116\n","Positive sensitivity: 96.5116  specificity: 84.6386\n","Positive FPR: 15.3614  NPV: 97.9094\n","Positive TP: 166.0\n","Positive TN: 281.0\n","Positive FP: 51.0\n","Positive FN: 6.0\n","\n","\n","\n","Epoch 9/50\n","----------\n","Epoch: 9     train index of 50 minibatch: 1      time used: 51.25656056404114\n","minibatch AVG loss: 0.14339790192432703\n","Epoch: 9     train index of 50 minibatch: 2      time used: 50.75736355781555\n","minibatch AVG loss: 0.14857422776520252\n","Epoch: 9     train index of 50 minibatch: 3      time used: 50.686049938201904\n","minibatch AVG loss: 0.10209906264324672\n","Epoch: 9     train index of 50 minibatch: 4      time used: 50.6182541847229\n","minibatch AVG loss: 0.17692479092045688\n","Epoch: 9     train index of 50 minibatch: 5      time used: 50.56298875808716\n","minibatch AVG loss: 0.11696980046574026\n","Epoch: 9     train index of 50 minibatch: 6      time used: 50.71689200401306\n","minibatch AVG loss: 0.16180677962955087\n","Epoch: 9     train index of 50 minibatch: 7      time used: 50.625802755355835\n","minibatch AVG loss: 0.19261061049997807\n","Epoch: 9     train index of 50 minibatch: 8      time used: 50.61523151397705\n","minibatch AVG loss: 0.19972837451845407\n","\n","Epoch: 9  train \n","Loss: 0.1594  Acc: 93.4325\n","Negative precision: 94.4989  recall: 95.5997\n","Negative sensitivity: 95.5997  specificity: 89.6135\n","Negative FPR: 10.3865  NPV: 91.6049\n","Negative TP: 2216.0\n","Negative TN: 1113.0\n","Negative FP: 129.0\n","Negative FN: 102.0\n","Positive precision: 91.6049  recall: 89.6135\n","Positive sensitivity: 89.6135  specificity: 95.5997\n","Positive FPR: 4.4003  NPV: 94.4989\n","Positive TP: 1113.0\n","Positive TN: 2216.0\n","Positive FP: 102.0\n","Positive FN: 129.0\n","\n","\n","Epoch: 9     val index of 50 minibatch: 1      time used: 19.2367684841156\n","minibatch AVG loss: 0.16060667649959215\n","\n","Epoch: 9  val \n","Loss: 0.2288  Acc: 89.7839\n","Negative precision: 90.1408  recall: 96.3855\n","Negative sensitivity: 96.3855  specificity: 79.6512\n","Negative FPR: 20.3488  NPV: 91.9463\n","Negative TP: 320.0\n","Negative TN: 137.0\n","Negative FP: 35.0\n","Negative FN: 12.0\n","Positive precision: 91.9463  recall: 79.6512\n","Positive sensitivity: 79.6512  specificity: 96.3855\n","Positive FPR: 3.6145  NPV: 90.1408\n","Positive TP: 137.0\n","Positive TN: 320.0\n","Positive FP: 12.0\n","Positive FN: 35.0\n","\n","\n","\n","Epoch 10/50\n","----------\n","Epoch: 10     train index of 50 minibatch: 1      time used: 51.210681676864624\n","minibatch AVG loss: 0.10976002039387822\n","Epoch: 10     train index of 50 minibatch: 2      time used: 50.57452964782715\n","minibatch AVG loss: 0.10941700750496239\n","Epoch: 10     train index of 50 minibatch: 3      time used: 50.57185363769531\n","minibatch AVG loss: 0.12592081289039925\n","Epoch: 10     train index of 50 minibatch: 4      time used: 50.56632995605469\n","minibatch AVG loss: 0.10603152630006661\n","Epoch: 10     train index of 50 minibatch: 5      time used: 50.65791916847229\n","minibatch AVG loss: 0.1662503233924508\n","Epoch: 10     train index of 50 minibatch: 6      time used: 50.58944392204285\n","minibatch AVG loss: 0.17955352843506261\n","Epoch: 10     train index of 50 minibatch: 7      time used: 50.76431465148926\n","minibatch AVG loss: 0.13814438194967807\n","Epoch: 10     train index of 50 minibatch: 8      time used: 50.59344220161438\n","minibatch AVG loss: 0.1238005041750148\n","\n","Epoch: 10  train \n","Loss: 0.1465  Acc: 94.0780\n","Negative precision: 95.0107  recall: 96.0759\n","Negative sensitivity: 96.0759  specificity: 90.5721\n","Negative FPR: 9.4279  NPV: 92.5103\n","Negative TP: 2228.0\n","Negative TN: 1124.0\n","Negative FP: 117.0\n","Negative FN: 91.0\n","Positive precision: 92.5103  recall: 90.5721\n","Positive sensitivity: 90.5721  specificity: 96.0759\n","Positive FPR: 3.9241  NPV: 95.0107\n","Positive TP: 1124.0\n","Positive TN: 2228.0\n","Positive FP: 91.0\n","Positive FN: 117.0\n","\n","\n","Epoch: 10     val index of 50 minibatch: 1      time used: 19.233335733413696\n","minibatch AVG loss: 0.1714731939230114\n","\n","Epoch: 10  val \n","Loss: 0.2804  Acc: 88.0157\n","Negative precision: 87.2973  recall: 97.2892\n","Negative sensitivity: 97.2892  specificity: 72.6744\n","Negative FPR: 27.3256  NPV: 93.2836\n","Negative TP: 323.0\n","Negative TN: 125.0\n","Negative FP: 47.0\n","Negative FN: 9.0\n","Positive precision: 93.2836  recall: 72.6744\n","Positive sensitivity: 72.6744  specificity: 97.2892\n","Positive FPR: 2.7108  NPV: 87.2973\n","Positive TP: 125.0\n","Positive TN: 323.0\n","Positive FP: 9.0\n","Positive FN: 47.0\n","\n","\n","\n","Epoch 11/50\n","----------\n","Epoch: 11     train index of 50 minibatch: 1      time used: 51.30786061286926\n","minibatch AVG loss: 0.14813609085977078\n","Epoch: 11     train index of 50 minibatch: 2      time used: 50.647221326828\n","minibatch AVG loss: 0.09004197241272777\n","Epoch: 11     train index of 50 minibatch: 3      time used: 50.6435489654541\n","minibatch AVG loss: 0.19286326056346298\n","Epoch: 11     train index of 50 minibatch: 4      time used: 50.58833837509155\n","minibatch AVG loss: 0.1147797621274367\n","Epoch: 11     train index of 50 minibatch: 5      time used: 50.57800817489624\n","minibatch AVG loss: 0.17308655567001552\n","Epoch: 11     train index of 50 minibatch: 6      time used: 50.663414478302\n","minibatch AVG loss: 0.2146716994419694\n","Epoch: 11     train index of 50 minibatch: 7      time used: 50.66529941558838\n","minibatch AVG loss: 0.1837749345973134\n","Epoch: 11     train index of 50 minibatch: 8      time used: 50.66949272155762\n","minibatch AVG loss: 0.14227214842103422\n","\n","Epoch: 11  train \n","Loss: 0.1624  Acc: 93.3483\n","Negative precision: 94.3027  recall: 95.6859\n","Negative sensitivity: 95.6859  specificity: 89.2110\n","Negative FPR: 10.7890  NPV: 91.7219\n","Negative TP: 2218.0\n","Negative TN: 1108.0\n","Negative FP: 134.0\n","Negative FN: 100.0\n","Positive precision: 91.7219  recall: 89.2110\n","Positive sensitivity: 89.2110  specificity: 95.6859\n","Positive FPR: 4.3141  NPV: 94.3027\n","Positive TP: 1108.0\n","Positive TN: 2218.0\n","Positive FP: 100.0\n","Positive FN: 134.0\n","\n","\n","Epoch: 11     val index of 50 minibatch: 1      time used: 19.233651161193848\n","minibatch AVG loss: 0.14910683315305506\n","\n","Epoch: 11  val \n","Loss: 0.2188  Acc: 89.5874\n","Negative precision: 92.0118  recall: 93.6747\n","Negative sensitivity: 93.6747  specificity: 84.3023\n","Negative FPR: 15.6977  NPV: 87.3494\n","Negative TP: 311.0\n","Negative TN: 145.0\n","Negative FP: 27.0\n","Negative FN: 21.0\n","Positive precision: 87.3494  recall: 84.3023\n","Positive sensitivity: 84.3023  specificity: 93.6747\n","Positive FPR: 6.3253  NPV: 92.0118\n","Positive TP: 145.0\n","Positive TN: 311.0\n","Positive FP: 21.0\n","Positive FN: 27.0\n","\n","\n","\n","Epoch 12/50\n","----------\n","Epoch: 12     train index of 50 minibatch: 1      time used: 51.26936864852905\n","minibatch AVG loss: 0.14211498187156393\n","Epoch: 12     train index of 50 minibatch: 2      time used: 50.43681073188782\n","minibatch AVG loss: 0.13560192340170032\n","Epoch: 12     train index of 50 minibatch: 3      time used: 50.449588775634766\n","minibatch AVG loss: 0.15363466994836927\n","Epoch: 12     train index of 50 minibatch: 4      time used: 50.516069173812866\n","minibatch AVG loss: 0.12889326413162053\n","Epoch: 12     train index of 50 minibatch: 5      time used: 50.742655754089355\n","minibatch AVG loss: 0.16532838743645697\n","Epoch: 12     train index of 50 minibatch: 6      time used: 50.71071648597717\n","minibatch AVG loss: 0.09185728335520253\n","Epoch: 12     train index of 50 minibatch: 7      time used: 50.62380409240723\n","minibatch AVG loss: 0.213502931157127\n","Epoch: 12     train index of 50 minibatch: 8      time used: 50.63141202926636\n","minibatch AVG loss: 0.16025391009636222\n","\n","Epoch: 12  train \n","Loss: 0.1468  Acc: 94.3026\n","Negative precision: 95.2178  recall: 96.2036\n","Negative sensitivity: 96.2036  specificity: 90.9823\n","Negative FPR: 9.0177  NPV: 92.7750\n","Negative TP: 2230.0\n","Negative TN: 1130.0\n","Negative FP: 112.0\n","Negative FN: 88.0\n","Positive precision: 92.7750  recall: 90.9823\n","Positive sensitivity: 90.9823  specificity: 96.2036\n","Positive FPR: 3.7964  NPV: 95.2178\n","Positive TP: 1130.0\n","Positive TN: 2230.0\n","Positive FP: 88.0\n","Positive FN: 112.0\n","\n","\n","Epoch: 12     val index of 50 minibatch: 1      time used: 19.32536816596985\n","minibatch AVG loss: 0.1537613208423136\n","\n","Epoch: 12  val \n","Loss: 0.2020  Acc: 90.7662\n","Negative precision: 94.2073  recall: 93.0723\n","Negative sensitivity: 93.0723  specificity: 88.9535\n","Negative FPR: 11.0465  NPV: 86.9318\n","Negative TP: 309.0\n","Negative TN: 153.0\n","Negative FP: 19.0\n","Negative FN: 23.0\n","Positive precision: 86.9318  recall: 88.9535\n","Positive sensitivity: 88.9535  specificity: 93.0723\n","Positive FPR: 6.9277  NPV: 94.2073\n","Positive TP: 153.0\n","Positive TN: 309.0\n","Positive FP: 23.0\n","Positive FN: 19.0\n","\n","\n","\n","Epoch 13/50\n","----------\n","Epoch: 13     train index of 50 minibatch: 1      time used: 51.24435782432556\n","minibatch AVG loss: 0.14209216959774496\n","Epoch: 13     train index of 50 minibatch: 2      time used: 50.65886163711548\n","minibatch AVG loss: 0.12119247403461486\n","Epoch: 13     train index of 50 minibatch: 3      time used: 50.62524604797363\n","minibatch AVG loss: 0.13549866802524776\n","Epoch: 13     train index of 50 minibatch: 4      time used: 50.612887144088745\n","minibatch AVG loss: 0.16322912137722598\n","Epoch: 13     train index of 50 minibatch: 5      time used: 50.68300104141235\n","minibatch AVG loss: 0.16776098677888512\n","Epoch: 13     train index of 50 minibatch: 6      time used: 50.576048135757446\n","minibatch AVG loss: 0.1530309836193919\n","Epoch: 13     train index of 50 minibatch: 7      time used: 50.65219044685364\n","minibatch AVG loss: 0.13602873137686403\n","Epoch: 13     train index of 50 minibatch: 8      time used: 50.596336126327515\n","minibatch AVG loss: 0.179666792107746\n","\n","Epoch: 13  train \n","Loss: 0.1534  Acc: 93.9938\n","Negative precision: 94.8533  recall: 96.1207\n","Negative sensitivity: 96.1207  specificity: 90.2419\n","Negative FPR: 9.7581  NPV: 92.5558\n","Negative TP: 2230.0\n","Negative TN: 1119.0\n","Negative FP: 121.0\n","Negative FN: 90.0\n","Positive precision: 92.5558  recall: 90.2419\n","Positive sensitivity: 90.2419  specificity: 96.1207\n","Positive FPR: 3.8793  NPV: 94.8533\n","Positive TP: 1119.0\n","Positive TN: 2230.0\n","Positive FP: 90.0\n","Positive FN: 121.0\n","\n","\n","Epoch: 13     val index of 50 minibatch: 1      time used: 19.19446086883545\n","minibatch AVG loss: 0.11789226621127455\n","\n","Epoch: 13  val \n","Loss: 0.2337  Acc: 90.5697\n","Negative precision: 91.4040  recall: 96.0843\n","Negative sensitivity: 96.0843  specificity: 82.5581\n","Negative FPR: 17.4419  NPV: 91.6129\n","Negative TP: 319.0\n","Negative TN: 142.0\n","Negative FP: 30.0\n","Negative FN: 13.0\n","Positive precision: 91.6129  recall: 82.5581\n","Positive sensitivity: 82.5581  specificity: 96.0843\n","Positive FPR: 3.9157  NPV: 91.4040\n","Positive TP: 142.0\n","Positive TN: 319.0\n","Positive FP: 13.0\n","Positive FN: 30.0\n","\n","\n","\n","Epoch 14/50\n","----------\n","Epoch: 14     train index of 50 minibatch: 1      time used: 51.31345725059509\n","minibatch AVG loss: 0.13837575785815714\n","Epoch: 14     train index of 50 minibatch: 2      time used: 50.56543445587158\n","minibatch AVG loss: 0.12505702720955014\n","Epoch: 14     train index of 50 minibatch: 3      time used: 50.68821883201599\n","minibatch AVG loss: 0.15629350716248155\n","Epoch: 14     train index of 50 minibatch: 4      time used: 50.46649146080017\n","minibatch AVG loss: 0.1287737487675622\n","Epoch: 14     train index of 50 minibatch: 5      time used: 50.576513051986694\n","minibatch AVG loss: 0.16382404926232993\n","Epoch: 14     train index of 50 minibatch: 6      time used: 50.71534299850464\n","minibatch AVG loss: 0.17372278611175715\n","Epoch: 14     train index of 50 minibatch: 7      time used: 50.61730074882507\n","minibatch AVG loss: 0.1548827674612403\n","Epoch: 14     train index of 50 minibatch: 8      time used: 50.740492820739746\n","minibatch AVG loss: 0.1511557332240045\n","\n","Epoch: 14  train \n","Loss: 0.1459  Acc: 94.5271\n","Negative precision: 95.5071  recall: 96.2484\n","Negative sensitivity: 96.2484  specificity: 91.5391\n","Negative FPR: 8.4609  NPV: 92.8863\n","Negative TP: 2232.0\n","Negative TN: 1136.0\n","Negative FP: 105.0\n","Negative FN: 87.0\n","Positive precision: 92.8863  recall: 91.5391\n","Positive sensitivity: 91.5391  specificity: 96.2484\n","Positive FPR: 3.7516  NPV: 95.5071\n","Positive TP: 1136.0\n","Positive TN: 2232.0\n","Positive FP: 87.0\n","Positive FN: 105.0\n","\n","\n","Epoch: 14     val index of 50 minibatch: 1      time used: 19.248175859451294\n","minibatch AVG loss: 0.16622763660252532\n","\n","Epoch: 14  val \n","Loss: 0.2094  Acc: 91.9450\n","Negative precision: 94.0476  recall: 95.1807\n","Negative sensitivity: 95.1807  specificity: 88.3721\n","Negative FPR: 11.6279  NPV: 90.4762\n","Negative TP: 316.0\n","Negative TN: 152.0\n","Negative FP: 20.0\n","Negative FN: 16.0\n","Positive precision: 90.4762  recall: 88.3721\n","Positive sensitivity: 88.3721  specificity: 95.1807\n","Positive FPR: 4.8193  NPV: 94.0476\n","Positive TP: 152.0\n","Positive TN: 316.0\n","Positive FP: 16.0\n","Positive FN: 20.0\n","\n","\n","\n","Epoch 15/50\n","----------\n","Epoch: 15     train index of 50 minibatch: 1      time used: 51.445228099823\n","minibatch AVG loss: 0.12883071346092037\n","Epoch: 15     train index of 50 minibatch: 2      time used: 50.62456178665161\n","minibatch AVG loss: 0.21779599183704704\n","Epoch: 15     train index of 50 minibatch: 3      time used: 50.63460326194763\n","minibatch AVG loss: 0.19154458340257408\n","Epoch: 15     train index of 50 minibatch: 4      time used: 50.47176742553711\n","minibatch AVG loss: 0.1898759306129068\n","Epoch: 15     train index of 50 minibatch: 5      time used: 50.64858341217041\n","minibatch AVG loss: 0.11386713416082785\n","Epoch: 15     train index of 50 minibatch: 6      time used: 50.68138790130615\n","minibatch AVG loss: 0.1426108239358291\n","Epoch: 15     train index of 50 minibatch: 7      time used: 50.6083710193634\n","minibatch AVG loss: 0.1047689658217132\n","Epoch: 15     train index of 50 minibatch: 8      time used: 50.73308849334717\n","minibatch AVG loss: 0.1896569552598521\n","\n","Epoch: 15  train \n","Loss: 0.1573  Acc: 93.7974\n","Negative precision: 94.8335  recall: 95.8154\n","Negative sensitivity: 95.8154  specificity: 90.2576\n","Negative FPR: 9.7424  NPV: 92.0361\n","Negative TP: 2221.0\n","Negative TN: 1121.0\n","Negative FP: 121.0\n","Negative FN: 97.0\n","Positive precision: 92.0361  recall: 90.2576\n","Positive sensitivity: 90.2576  specificity: 95.8154\n","Positive FPR: 4.1846  NPV: 94.8335\n","Positive TP: 1121.0\n","Positive TN: 2221.0\n","Positive FP: 97.0\n","Positive FN: 121.0\n","\n","\n","Epoch: 15     val index of 50 minibatch: 1      time used: 19.256499767303467\n","minibatch AVG loss: 0.14367523264605553\n","\n","Epoch: 15  val \n","Loss: 0.2837  Acc: 89.7839\n","Negative precision: 89.9160  recall: 96.6867\n","Negative sensitivity: 96.6867  specificity: 79.0698\n","Negative FPR: 20.9302  NPV: 92.5170\n","Negative TP: 321.0\n","Negative TN: 136.0\n","Negative FP: 36.0\n","Negative FN: 11.0\n","Positive precision: 92.5170  recall: 79.0698\n","Positive sensitivity: 79.0698  specificity: 96.6867\n","Positive FPR: 3.3133  NPV: 89.9160\n","Positive TP: 136.0\n","Positive TN: 321.0\n","Positive FP: 11.0\n","Positive FN: 36.0\n","\n","\n","\n","Epoch 16/50\n","----------\n","Epoch: 16     train index of 50 minibatch: 1      time used: 51.18110203742981\n","minibatch AVG loss: 0.11207436260534451\n","Epoch: 16     train index of 50 minibatch: 2      time used: 50.676246643066406\n","minibatch AVG loss: 0.15534303997876123\n","Epoch: 16     train index of 50 minibatch: 3      time used: 50.73298764228821\n","minibatch AVG loss: 0.13410471723182127\n","Epoch: 16     train index of 50 minibatch: 4      time used: 50.623971939086914\n","minibatch AVG loss: 0.17231250379234553\n","Epoch: 16     train index of 50 minibatch: 5      time used: 50.64777064323425\n","minibatch AVG loss: 0.1452557125687599\n","Epoch: 16     train index of 50 minibatch: 6      time used: 50.586665868759155\n","minibatch AVG loss: 0.11439539871178567\n","Epoch: 16     train index of 50 minibatch: 7      time used: 50.5691282749176\n","minibatch AVG loss: 0.14585119761060925\n","Epoch: 16     train index of 50 minibatch: 8      time used: 50.675095081329346\n","minibatch AVG loss: 0.18529465372674167\n","\n","Epoch: 16  train \n","Loss: 0.1448  Acc: 94.2745\n","Negative precision: 95.1792  recall: 96.2053\n","Negative sensitivity: 96.2053  specificity: 90.8944\n","Negative FPR: 9.1056  NPV: 92.7632\n","Negative TP: 2231.0\n","Negative TN: 1128.0\n","Negative FP: 113.0\n","Negative FN: 88.0\n","Positive precision: 92.7632  recall: 90.8944\n","Positive sensitivity: 90.8944  specificity: 96.2053\n","Positive FPR: 3.7947  NPV: 95.1792\n","Positive TP: 1128.0\n","Positive TN: 2231.0\n","Positive FP: 88.0\n","Positive FN: 113.0\n","\n","\n","Epoch: 16     val index of 50 minibatch: 1      time used: 19.18317985534668\n","minibatch AVG loss: 0.11384794156532735\n","\n","Epoch: 16  val \n","Loss: 0.2021  Acc: 90.9627\n","Negative precision: 92.4198  recall: 95.4819\n","Negative sensitivity: 95.4819  specificity: 84.8837\n","Negative FPR: 15.1163  NPV: 90.6832\n","Negative TP: 317.0\n","Negative TN: 146.0\n","Negative FP: 26.0\n","Negative FN: 15.0\n","Positive precision: 90.6832  recall: 84.8837\n","Positive sensitivity: 84.8837  specificity: 95.4819\n","Positive FPR: 4.5181  NPV: 92.4198\n","Positive TP: 146.0\n","Positive TN: 317.0\n","Positive FP: 15.0\n","Positive FN: 26.0\n","\n","\n","\n","Epoch 17/50\n","----------\n","Epoch: 17     train index of 50 minibatch: 1      time used: 51.15541958808899\n","minibatch AVG loss: 0.12119967785663903\n","Epoch: 17     train index of 50 minibatch: 2      time used: 50.70767092704773\n","minibatch AVG loss: 0.16942961030479636\n","Epoch: 17     train index of 50 minibatch: 3      time used: 50.64036011695862\n","minibatch AVG loss: 0.13655271216295659\n","Epoch: 17     train index of 50 minibatch: 4      time used: 50.528733253479004\n","minibatch AVG loss: 0.114983544544084\n","Epoch: 17     train index of 50 minibatch: 5      time used: 50.583651304244995\n","minibatch AVG loss: 0.17261191009543836\n","Epoch: 17     train index of 50 minibatch: 6      time used: 50.5232138633728\n","minibatch AVG loss: 0.1286908864392899\n","Epoch: 17     train index of 50 minibatch: 7      time used: 50.867501735687256\n","minibatch AVG loss: 0.18240444571245462\n","Epoch: 17     train index of 50 minibatch: 8      time used: 50.713542461395264\n","minibatch AVG loss: 0.14406351997400635\n","\n","Epoch: 17  train \n","Loss: 0.1470  Acc: 94.0500\n","Negative precision: 94.8195  recall: 96.2500\n","Negative sensitivity: 96.2500  specificity: 90.1613\n","Negative FPR: 9.8387  NPV: 92.7801\n","Negative TP: 2233.0\n","Negative TN: 1118.0\n","Negative FP: 122.0\n","Negative FN: 87.0\n","Positive precision: 92.7801  recall: 90.1613\n","Positive sensitivity: 90.1613  specificity: 96.2500\n","Positive FPR: 3.7500  NPV: 94.8195\n","Positive TP: 1118.0\n","Positive TN: 2233.0\n","Positive FP: 87.0\n","Positive FN: 122.0\n","\n","\n","Epoch: 17     val index of 50 minibatch: 1      time used: 19.226048707962036\n","minibatch AVG loss: 0.197305914144963\n","\n","Epoch: 17  val \n","Loss: 0.2585  Acc: 88.6051\n","Negative precision: 91.6418  recall: 92.4699\n","Negative sensitivity: 92.4699  specificity: 83.7209\n","Negative FPR: 16.2791  NPV: 85.2071\n","Negative TP: 307.0\n","Negative TN: 144.0\n","Negative FP: 28.0\n","Negative FN: 25.0\n","Positive precision: 85.2071  recall: 83.7209\n","Positive sensitivity: 83.7209  specificity: 92.4699\n","Positive FPR: 7.5301  NPV: 91.6418\n","Positive TP: 144.0\n","Positive TN: 307.0\n","Positive FP: 25.0\n","Positive FN: 28.0\n","\n","\n","\n","Epoch 18/50\n","----------\n","Epoch: 18     train index of 50 minibatch: 1      time used: 51.14885401725769\n","minibatch AVG loss: 0.18001432646997273\n","Epoch: 18     train index of 50 minibatch: 2      time used: 50.645976543426514\n","minibatch AVG loss: 0.12412543585989624\n","Epoch: 18     train index of 50 minibatch: 3      time used: 50.637107849121094\n","minibatch AVG loss: 0.1182015127548948\n","Epoch: 18     train index of 50 minibatch: 4      time used: 50.78575873374939\n","minibatch AVG loss: 0.12830869162455202\n","Epoch: 18     train index of 50 minibatch: 5      time used: 50.41158580780029\n","minibatch AVG loss: 0.17332821001298726\n","Epoch: 18     train index of 50 minibatch: 6      time used: 50.655664682388306\n","minibatch AVG loss: 0.16541860153898597\n","Epoch: 18     train index of 50 minibatch: 7      time used: 50.71901774406433\n","minibatch AVG loss: 0.1914243190921843\n","Epoch: 18     train index of 50 minibatch: 8      time used: 50.48693561553955\n","minibatch AVG loss: 0.14952166145201773\n","\n","Epoch: 18  train \n","Loss: 0.1597  Acc: 93.3483\n","Negative precision: 94.5299  recall: 95.4271\n","Negative sensitivity: 95.4271  specificity: 89.6940\n","Negative FPR: 10.3060  NPV: 91.3115\n","Negative TP: 2212.0\n","Negative TN: 1114.0\n","Negative FP: 128.0\n","Negative FN: 106.0\n","Positive precision: 91.3115  recall: 89.6940\n","Positive sensitivity: 89.6940  specificity: 95.4271\n","Positive FPR: 4.5729  NPV: 94.5299\n","Positive TP: 1114.0\n","Positive TN: 2212.0\n","Positive FP: 106.0\n","Positive FN: 128.0\n","\n","\n","Epoch: 18     val index of 50 minibatch: 1      time used: 19.280447244644165\n","minibatch AVG loss: 0.14867131932871416\n","\n","Epoch: 18  val \n","Loss: 0.2335  Acc: 89.9804\n","Negative precision: 90.1685  recall: 96.6867\n","Negative sensitivity: 96.6867  specificity: 79.6512\n","Negative FPR: 20.3488  NPV: 92.5676\n","Negative TP: 321.0\n","Negative TN: 137.0\n","Negative FP: 35.0\n","Negative FN: 11.0\n","Positive precision: 92.5676  recall: 79.6512\n","Positive sensitivity: 79.6512  specificity: 96.6867\n","Positive FPR: 3.3133  NPV: 90.1685\n","Positive TP: 137.0\n","Positive TN: 321.0\n","Positive FP: 11.0\n","Positive FN: 35.0\n","\n","\n","\n","Epoch 19/50\n","----------\n","Epoch: 19     train index of 50 minibatch: 1      time used: 51.301573514938354\n","minibatch AVG loss: 0.1367163641937077\n","Epoch: 19     train index of 50 minibatch: 2      time used: 50.70531249046326\n","minibatch AVG loss: 0.1478488834196469\n","Epoch: 19     train index of 50 minibatch: 3      time used: 50.614646911621094\n","minibatch AVG loss: 0.11625469036516733\n","Epoch: 19     train index of 50 minibatch: 4      time used: 50.425140380859375\n","minibatch AVG loss: 0.1323246202734299\n","Epoch: 19     train index of 50 minibatch: 5      time used: 50.422929763793945\n","minibatch AVG loss: 0.20564491970464588\n","Epoch: 19     train index of 50 minibatch: 6      time used: 50.54445767402649\n","minibatch AVG loss: 0.1137678759265691\n","Epoch: 19     train index of 50 minibatch: 7      time used: 50.73706579208374\n","minibatch AVG loss: 0.12075088150333613\n","Epoch: 19     train index of 50 minibatch: 8      time used: 50.64933109283447\n","minibatch AVG loss: 0.16447927692439407\n","\n","Epoch: 19  train \n","Loss: 0.1411  Acc: 94.6393\n","Negative precision: 95.3211  recall: 96.6365\n","Negative sensitivity: 96.6365  specificity: 91.1362\n","Negative FPR: 8.8638  NPV: 93.5484\n","Negative TP: 2241.0\n","Negative TN: 1131.0\n","Negative FP: 110.0\n","Negative FN: 78.0\n","Positive precision: 93.5484  recall: 91.1362\n","Positive sensitivity: 91.1362  specificity: 96.6365\n","Positive FPR: 3.3635  NPV: 95.3211\n","Positive TP: 1131.0\n","Positive TN: 2241.0\n","Positive FP: 78.0\n","Positive FN: 110.0\n","\n","\n","Epoch: 19     val index of 50 minibatch: 1      time used: 19.328729152679443\n","minibatch AVG loss: 0.17845410011970672\n","\n","Epoch: 19  val \n","Loss: 0.2021  Acc: 90.3733\n","Negative precision: 94.1718  recall: 92.4699\n","Negative sensitivity: 92.4699  specificity: 88.9535\n","Negative FPR: 11.0465  NPV: 85.9551\n","Negative TP: 307.0\n","Negative TN: 153.0\n","Negative FP: 19.0\n","Negative FN: 25.0\n","Positive precision: 85.9551  recall: 88.9535\n","Positive sensitivity: 88.9535  specificity: 92.4699\n","Positive FPR: 7.5301  NPV: 94.1718\n","Positive TP: 153.0\n","Positive TN: 307.0\n","Positive FP: 25.0\n","Positive FN: 19.0\n","\n","\n","\n","Epoch 20/50\n","----------\n","Epoch: 20     train index of 50 minibatch: 1      time used: 51.31175661087036\n","minibatch AVG loss: 0.11775224179029464\n","Epoch: 20     train index of 50 minibatch: 2      time used: 50.47939586639404\n","minibatch AVG loss: 0.13281959292013198\n","Epoch: 20     train index of 50 minibatch: 3      time used: 50.60298228263855\n","minibatch AVG loss: 0.17824130202643573\n","Epoch: 20     train index of 50 minibatch: 4      time used: 50.68102431297302\n","minibatch AVG loss: 0.1484838130651042\n","Epoch: 20     train index of 50 minibatch: 5      time used: 50.52830362319946\n","minibatch AVG loss: 0.13657014153315686\n","Epoch: 20     train index of 50 minibatch: 6      time used: 50.448976039886475\n","minibatch AVG loss: 0.13794093914330005\n","Epoch: 20     train index of 50 minibatch: 7      time used: 50.573742151260376\n","minibatch AVG loss: 0.13872373914811761\n","Epoch: 20     train index of 50 minibatch: 8      time used: 50.622403383255005\n","minibatch AVG loss: 0.12509655646048487\n","\n","Epoch: 20  train \n","Loss: 0.1380  Acc: 94.2464\n","Negative precision: 95.2178  recall: 96.1207\n","Negative sensitivity: 96.1207  specificity: 90.9677\n","Negative FPR: 9.0323  NPV: 92.6108\n","Negative TP: 2230.0\n","Negative TN: 1128.0\n","Negative FP: 112.0\n","Negative FN: 90.0\n","Positive precision: 92.6108  recall: 90.9677\n","Positive sensitivity: 90.9677  specificity: 96.1207\n","Positive FPR: 3.8793  NPV: 95.2178\n","Positive TP: 1128.0\n","Positive TN: 2230.0\n","Positive FP: 90.0\n","Positive FN: 112.0\n","\n","\n","Epoch: 20     val index of 50 minibatch: 1      time used: 19.261821269989014\n","minibatch AVG loss: 0.11033218258526176\n","\n","Epoch: 20  val \n","Loss: 0.2578  Acc: 89.3910\n","Negative precision: 89.6359  recall: 96.3855\n","Negative sensitivity: 96.3855  specificity: 78.4884\n","Negative FPR: 21.5116  NPV: 91.8367\n","Negative TP: 320.0\n","Negative TN: 135.0\n","Negative FP: 37.0\n","Negative FN: 12.0\n","Positive precision: 91.8367  recall: 78.4884\n","Positive sensitivity: 78.4884  specificity: 96.3855\n","Positive FPR: 3.6145  NPV: 89.6359\n","Positive TP: 135.0\n","Positive TN: 320.0\n","Positive FP: 12.0\n","Positive FN: 37.0\n","\n","\n","\n","Epoch 21/50\n","----------\n","Epoch: 21     train index of 50 minibatch: 1      time used: 51.15176725387573\n","minibatch AVG loss: 0.0937554298125906\n","Epoch: 21     train index of 50 minibatch: 2      time used: 50.7350492477417\n","minibatch AVG loss: 0.11918615235947072\n","Epoch: 21     train index of 50 minibatch: 3      time used: 50.50526809692383\n","minibatch AVG loss: 0.10732146248221397\n","Epoch: 21     train index of 50 minibatch: 4      time used: 50.48345232009888\n","minibatch AVG loss: 0.12030070544686168\n","Epoch: 21     train index of 50 minibatch: 5      time used: 50.603111267089844\n","minibatch AVG loss: 0.13496232443954795\n","Epoch: 21     train index of 50 minibatch: 6      time used: 50.636394023895264\n","minibatch AVG loss: 0.18578889231197537\n","Epoch: 21     train index of 50 minibatch: 7      time used: 50.69160771369934\n","minibatch AVG loss: 0.1258581359917298\n","Epoch: 21     train index of 50 minibatch: 8      time used: 50.565239906311035\n","minibatch AVG loss: 0.1327794311742764\n","\n","Epoch: 21  train \n","Loss: 0.1266  Acc: 94.7235\n","Negative precision: 95.8351  recall: 96.2069\n","Negative sensitivity: 96.2069  specificity: 92.1774\n","Negative FPR: 7.8226  NPV: 92.8513\n","Negative TP: 2232.0\n","Negative TN: 1143.0\n","Negative FP: 97.0\n","Negative FN: 88.0\n","Positive precision: 92.8513  recall: 92.1774\n","Positive sensitivity: 92.1774  specificity: 96.2069\n","Positive FPR: 3.7931  NPV: 95.8351\n","Positive TP: 1143.0\n","Positive TN: 2232.0\n","Positive FP: 88.0\n","Positive FN: 97.0\n","\n","\n","Epoch: 21     val index of 50 minibatch: 1      time used: 19.216195583343506\n","minibatch AVG loss: 0.13536132626184552\n","\n","Epoch: 21  val \n","Loss: 0.2534  Acc: 90.7662\n","Negative precision: 90.9605  recall: 96.9880\n","Negative sensitivity: 96.9880  specificity: 81.3953\n","Negative FPR: 18.6047  NPV: 93.3333\n","Negative TP: 322.0\n","Negative TN: 140.0\n","Negative FP: 32.0\n","Negative FN: 10.0\n","Positive precision: 93.3333  recall: 81.3953\n","Positive sensitivity: 81.3953  specificity: 96.9880\n","Positive FPR: 3.0120  NPV: 90.9605\n","Positive TP: 140.0\n","Positive TN: 322.0\n","Positive FP: 10.0\n","Positive FN: 32.0\n","\n","\n","\n","Epoch 22/50\n","----------\n","Epoch: 22     train index of 50 minibatch: 1      time used: 51.13497495651245\n","minibatch AVG loss: 0.08576732934976462\n","Epoch: 22     train index of 50 minibatch: 2      time used: 50.69548225402832\n","minibatch AVG loss: 0.10925010095816105\n","Epoch: 22     train index of 50 minibatch: 3      time used: 50.66411781311035\n","minibatch AVG loss: 0.12923613046179525\n","Epoch: 22     train index of 50 minibatch: 4      time used: 50.736337184906006\n","minibatch AVG loss: 0.13644345344044267\n","Epoch: 22     train index of 50 minibatch: 5      time used: 50.57832717895508\n","minibatch AVG loss: 0.17072166768833996\n","Epoch: 22     train index of 50 minibatch: 6      time used: 50.469090938568115\n","minibatch AVG loss: 0.1317534341895953\n","Epoch: 22     train index of 50 minibatch: 7      time used: 50.55098056793213\n","minibatch AVG loss: 0.15779147495049983\n","Epoch: 22     train index of 50 minibatch: 8      time used: 50.55243229866028\n","minibatch AVG loss: 0.11902044273447246\n","\n","Epoch: 22  train \n","Loss: 0.1292  Acc: 94.5271\n","Negative precision: 95.5071  recall: 96.2484\n","Negative sensitivity: 96.2484  specificity: 91.5391\n","Negative FPR: 8.4609  NPV: 92.8863\n","Negative TP: 2232.0\n","Negative TN: 1136.0\n","Negative FP: 105.0\n","Negative FN: 87.0\n","Positive precision: 92.8863  recall: 91.5391\n","Positive sensitivity: 91.5391  specificity: 96.2484\n","Positive FPR: 3.7516  NPV: 95.5071\n","Positive TP: 1136.0\n","Positive TN: 2232.0\n","Positive FP: 87.0\n","Positive FN: 105.0\n","\n","\n","Epoch: 22     val index of 50 minibatch: 1      time used: 19.216349601745605\n","minibatch AVG loss: 0.19799776183797804\n","\n","Epoch: 22  val \n","Loss: 0.2465  Acc: 89.1945\n","Negative precision: 93.5185  recall: 91.2651\n","Negative sensitivity: 91.2651  specificity: 87.7907\n","Negative FPR: 12.2093  NPV: 83.8889\n","Negative TP: 303.0\n","Negative TN: 151.0\n","Negative FP: 21.0\n","Negative FN: 29.0\n","Positive precision: 83.8889  recall: 87.7907\n","Positive sensitivity: 87.7907  specificity: 91.2651\n","Positive FPR: 8.7349  NPV: 93.5185\n","Positive TP: 151.0\n","Positive TN: 303.0\n","Positive FP: 29.0\n","Positive FN: 21.0\n","\n","\n","\n","Epoch 23/50\n","----------\n","Epoch: 23     train index of 50 minibatch: 1      time used: 51.00292110443115\n","minibatch AVG loss: 0.1295711938198656\n","Epoch: 23     train index of 50 minibatch: 2      time used: 50.72096800804138\n","minibatch AVG loss: 0.13998934322968126\n","Epoch: 23     train index of 50 minibatch: 3      time used: 50.59695363044739\n","minibatch AVG loss: 0.14570737501140685\n","Epoch: 23     train index of 50 minibatch: 4      time used: 50.441681146621704\n","minibatch AVG loss: 0.11542191051878035\n","Epoch: 23     train index of 50 minibatch: 5      time used: 50.570491552352905\n","minibatch AVG loss: 0.10640916754258796\n","Epoch: 23     train index of 50 minibatch: 6      time used: 50.59011745452881\n","minibatch AVG loss: 0.12724360819440336\n","Epoch: 23     train index of 50 minibatch: 7      time used: 50.551873207092285\n","minibatch AVG loss: 0.11903828126844018\n","Epoch: 23     train index of 50 minibatch: 8      time used: 50.609246492385864\n","minibatch AVG loss: 0.12473847020883114\n","\n","Epoch: 23  train \n","Loss: 0.1270  Acc: 94.5832\n","Negative precision: 95.5128  recall: 96.3362\n","Negative sensitivity: 96.3362  specificity: 91.5323\n","Negative FPR: 8.4677  NPV: 93.0328\n","Negative TP: 2235.0\n","Negative TN: 1135.0\n","Negative FP: 105.0\n","Negative FN: 85.0\n","Positive precision: 93.0328  recall: 91.5323\n","Positive sensitivity: 91.5323  specificity: 96.3362\n","Positive FPR: 3.6638  NPV: 95.5128\n","Positive TP: 1135.0\n","Positive TN: 2235.0\n","Positive FP: 85.0\n","Positive FN: 105.0\n","\n","\n","Epoch: 23     val index of 50 minibatch: 1      time used: 19.25270414352417\n","minibatch AVG loss: 0.39514473973307757\n","\n","Epoch: 23  val \n","Loss: 0.3596  Acc: 87.2299\n","Negative precision: 95.9459  recall: 85.5422\n","Negative sensitivity: 85.5422  specificity: 93.0233\n","Negative FPR: 6.9767  NPV: 76.9231\n","Negative TP: 284.0\n","Negative TN: 160.0\n","Negative FP: 12.0\n","Negative FN: 48.0\n","Positive precision: 76.9231  recall: 93.0233\n","Positive sensitivity: 93.0233  specificity: 85.5422\n","Positive FPR: 14.4578  NPV: 95.9459\n","Positive TP: 160.0\n","Positive TN: 284.0\n","Positive FP: 48.0\n","Positive FN: 12.0\n","\n","\n","\n","Epoch 24/50\n","----------\n","Epoch: 24     train index of 50 minibatch: 1      time used: 51.19148564338684\n","minibatch AVG loss: 0.10698862345539965\n","Epoch: 24     train index of 50 minibatch: 2      time used: 50.69665575027466\n","minibatch AVG loss: 0.13067494378425182\n","Epoch: 24     train index of 50 minibatch: 3      time used: 50.45759344100952\n","minibatch AVG loss: 0.13212758901063354\n","Epoch: 24     train index of 50 minibatch: 4      time used: 50.39920687675476\n","minibatch AVG loss: 0.17962337370961903\n","Epoch: 24     train index of 50 minibatch: 5      time used: 50.620668172836304\n","minibatch AVG loss: 0.13686770082451402\n","Epoch: 24     train index of 50 minibatch: 6      time used: 50.75078892707825\n","minibatch AVG loss: 0.11647753276512958\n","Epoch: 24     train index of 50 minibatch: 7      time used: 50.70403337478638\n","minibatch AVG loss: 0.10190907309530303\n","Epoch: 24     train index of 50 minibatch: 8      time used: 50.57183909416199\n","minibatch AVG loss: 0.12637878739769803\n","\n","Epoch: 24  train \n","Loss: 0.1291  Acc: 95.0042\n","Negative precision: 95.8138  recall: 96.6810\n","Negative sensitivity: 96.6810  specificity: 92.0968\n","Negative FPR: 7.9032  NPV: 93.6833\n","Negative TP: 2243.0\n","Negative TN: 1142.0\n","Negative FP: 98.0\n","Negative FN: 77.0\n","Positive precision: 93.6833  recall: 92.0968\n","Positive sensitivity: 92.0968  specificity: 96.6810\n","Positive FPR: 3.3190  NPV: 95.8138\n","Positive TP: 1142.0\n","Positive TN: 2243.0\n","Positive FP: 77.0\n","Positive FN: 98.0\n","\n","\n","Epoch: 24     val index of 50 minibatch: 1      time used: 19.17678165435791\n","minibatch AVG loss: 0.38980651239748115\n","\n","Epoch: 24  val \n","Loss: 0.3617  Acc: 86.0511\n","Negative precision: 94.6309  recall: 84.9398\n","Negative sensitivity: 84.9398  specificity: 90.6977\n","Negative FPR: 9.3023  NPV: 75.7282\n","Negative TP: 282.0\n","Negative TN: 156.0\n","Negative FP: 16.0\n","Negative FN: 50.0\n","Positive precision: 75.7282  recall: 90.6977\n","Positive sensitivity: 90.6977  specificity: 84.9398\n","Positive FPR: 15.0602  NPV: 94.6309\n","Positive TP: 156.0\n","Positive TN: 282.0\n","Positive FP: 50.0\n","Positive FN: 16.0\n","\n","\n","\n","Epoch 25/50\n","----------\n","Epoch: 25     train index of 50 minibatch: 1      time used: 51.17273283004761\n","minibatch AVG loss: 0.10435576590709389\n","Epoch: 25     train index of 50 minibatch: 2      time used: 50.760852575302124\n","minibatch AVG loss: 0.12123625450301916\n","Epoch: 25     train index of 50 minibatch: 3      time used: 50.58923411369324\n","minibatch AVG loss: 0.11747624128591269\n","Epoch: 25     train index of 50 minibatch: 4      time used: 50.55039143562317\n","minibatch AVG loss: 0.16598682245006785\n","Epoch: 25     train index of 50 minibatch: 5      time used: 50.53455686569214\n","minibatch AVG loss: 0.16055771188111975\n","Epoch: 25     train index of 50 minibatch: 6      time used: 50.55639576911926\n","minibatch AVG loss: 0.08166707925964146\n","Epoch: 25     train index of 50 minibatch: 7      time used: 50.691388845443726\n","minibatch AVG loss: 0.09568828295916319\n","Epoch: 25     train index of 50 minibatch: 8      time used: 50.614113330841064\n","minibatch AVG loss: 0.12731014276389033\n","\n","Epoch: 25  train \n","Loss: 0.1228  Acc: 94.5832\n","Negative precision: 95.5499  recall: 96.2915\n","Negative sensitivity: 96.2915  specificity: 91.6197\n","Negative FPR: 8.3803  NPV: 92.9681\n","Negative TP: 2233.0\n","Negative TN: 1137.0\n","Negative FP: 104.0\n","Negative FN: 86.0\n","Positive precision: 92.9681  recall: 91.6197\n","Positive sensitivity: 91.6197  specificity: 96.2915\n","Positive FPR: 3.7085  NPV: 95.5499\n","Positive TP: 1137.0\n","Positive TN: 2233.0\n","Positive FP: 86.0\n","Positive FN: 104.0\n","\n","\n","Epoch: 25     val index of 50 minibatch: 1      time used: 19.160137176513672\n","minibatch AVG loss: 0.15525266899283452\n","\n","Epoch: 25  val \n","Loss: 0.2877  Acc: 89.3910\n","Negative precision: 89.6359  recall: 96.3855\n","Negative sensitivity: 96.3855  specificity: 78.4884\n","Negative FPR: 21.5116  NPV: 91.8367\n","Negative TP: 320.0\n","Negative TN: 135.0\n","Negative FP: 37.0\n","Negative FN: 12.0\n","Positive precision: 91.8367  recall: 78.4884\n","Positive sensitivity: 78.4884  specificity: 96.3855\n","Positive FPR: 3.6145  NPV: 89.6359\n","Positive TP: 135.0\n","Positive TN: 320.0\n","Positive FP: 12.0\n","Positive FN: 37.0\n","\n","\n","\n","Epoch 26/50\n","----------\n","Epoch: 26     train index of 50 minibatch: 1      time used: 51.2627112865448\n","minibatch AVG loss: 0.13970652740448714\n","Epoch: 26     train index of 50 minibatch: 2      time used: 50.410374879837036\n","minibatch AVG loss: 0.09662141706445254\n","Epoch: 26     train index of 50 minibatch: 3      time used: 50.75441384315491\n","minibatch AVG loss: 0.1252503078430891\n","Epoch: 26     train index of 50 minibatch: 4      time used: 50.564738273620605\n","minibatch AVG loss: 0.08707715826341883\n","Epoch: 26     train index of 50 minibatch: 5      time used: 50.48031282424927\n","minibatch AVG loss: 0.17072802082053384\n","Epoch: 26     train index of 50 minibatch: 6      time used: 50.47457504272461\n","minibatch AVG loss: 0.1252207146026194\n","Epoch: 26     train index of 50 minibatch: 7      time used: 50.62718152999878\n","minibatch AVG loss: 0.11492567892652004\n","Epoch: 26     train index of 50 minibatch: 8      time used: 50.53009057044983\n","minibatch AVG loss: 0.10862176679540425\n","\n","Epoch: 26  train \n","Loss: 0.1227  Acc: 94.4710\n","Negative precision: 95.6596  recall: 95.9897\n","Negative sensitivity: 95.9897  specificity: 91.8614\n","Negative FPR: 8.1386  NPV: 92.4574\n","Negative TP: 2226.0\n","Negative TN: 1140.0\n","Negative FP: 101.0\n","Negative FN: 93.0\n","Positive precision: 92.4574  recall: 91.8614\n","Positive sensitivity: 91.8614  specificity: 95.9897\n","Positive FPR: 4.0103  NPV: 95.6596\n","Positive TP: 1140.0\n","Positive TN: 2226.0\n","Positive FP: 93.0\n","Positive FN: 101.0\n","\n","\n","Epoch: 26     val index of 50 minibatch: 1      time used: 19.34599781036377\n","minibatch AVG loss: 0.17741381120460573\n","\n","Epoch: 26  val \n","Loss: 0.2513  Acc: 89.9804\n","Negative precision: 92.0588  recall: 94.2771\n","Negative sensitivity: 94.2771  specificity: 84.3023\n","Negative FPR: 15.6977  NPV: 88.4146\n","Negative TP: 313.0\n","Negative TN: 145.0\n","Negative FP: 27.0\n","Negative FN: 19.0\n","Positive precision: 88.4146  recall: 84.3023\n","Positive sensitivity: 84.3023  specificity: 94.2771\n","Positive FPR: 5.7229  NPV: 92.0588\n","Positive TP: 145.0\n","Positive TN: 313.0\n","Positive FP: 19.0\n","Positive FN: 27.0\n","\n","\n","\n","Epoch 27/50\n","----------\n","Epoch: 27     train index of 50 minibatch: 1      time used: 51.20381474494934\n","minibatch AVG loss: 0.11364628431154415\n","Epoch: 27     train index of 50 minibatch: 2      time used: 50.48953175544739\n","minibatch AVG loss: 0.11309041591244749\n","Epoch: 27     train index of 50 minibatch: 3      time used: 50.59872531890869\n","minibatch AVG loss: 0.08100706482306123\n","Epoch: 27     train index of 50 minibatch: 4      time used: 50.54024863243103\n","minibatch AVG loss: 0.09239021494984627\n","Epoch: 27     train index of 50 minibatch: 5      time used: 50.45623517036438\n","minibatch AVG loss: 0.11426670697983354\n","Epoch: 27     train index of 50 minibatch: 6      time used: 50.539185762405396\n","minibatch AVG loss: 0.12914804412517697\n","Epoch: 27     train index of 50 minibatch: 7      time used: 50.604198694229126\n","minibatch AVG loss: 0.12527492720633746\n","Epoch: 27     train index of 50 minibatch: 8      time used: 50.644734382629395\n","minibatch AVG loss: 0.11936027789022774\n","\n","Epoch: 27  train \n","Loss: 0.1142  Acc: 95.3410\n","Negative precision: 96.1078  recall: 96.8952\n","Negative sensitivity: 96.8952  specificity: 92.6672\n","Negative FPR: 7.3328  NPV: 94.1080\n","Negative TP: 2247.0\n","Negative TN: 1150.0\n","Negative FP: 91.0\n","Negative FN: 72.0\n","Positive precision: 94.1080  recall: 92.6672\n","Positive sensitivity: 92.6672  specificity: 96.8952\n","Positive FPR: 3.1048  NPV: 96.1078\n","Positive TP: 1150.0\n","Positive TN: 2247.0\n","Positive FP: 72.0\n","Positive FN: 91.0\n","\n","\n","Epoch: 27     val index of 50 minibatch: 1      time used: 19.162796020507812\n","minibatch AVG loss: 0.19436512666346972\n","\n","Epoch: 27  val \n","Loss: 0.2379  Acc: 89.9804\n","Negative precision: 93.8650  recall: 92.1687\n","Negative sensitivity: 92.1687  specificity: 88.3721\n","Negative FPR: 11.6279  NPV: 85.3933\n","Negative TP: 306.0\n","Negative TN: 152.0\n","Negative FP: 20.0\n","Negative FN: 26.0\n","Positive precision: 85.3933  recall: 88.3721\n","Positive sensitivity: 88.3721  specificity: 92.1687\n","Positive FPR: 7.8313  NPV: 93.8650\n","Positive TP: 152.0\n","Positive TN: 306.0\n","Positive FP: 26.0\n","Positive FN: 20.0\n","\n","\n","\n","Epoch 28/50\n","----------\n","Epoch: 28     train index of 50 minibatch: 1      time used: 51.187684297561646\n","minibatch AVG loss: 0.09233380358899013\n","Epoch: 28     train index of 50 minibatch: 2      time used: 50.35383582115173\n","minibatch AVG loss: 0.09794630729476922\n","Epoch: 28     train index of 50 minibatch: 3      time used: 50.61972498893738\n","minibatch AVG loss: 0.0957537263049744\n","Epoch: 28     train index of 50 minibatch: 4      time used: 50.540820360183716\n","minibatch AVG loss: 0.14268647597404197\n","Epoch: 28     train index of 50 minibatch: 5      time used: 50.51853537559509\n","minibatch AVG loss: 0.08608752214815468\n","Epoch: 28     train index of 50 minibatch: 6      time used: 50.576297998428345\n","minibatch AVG loss: 0.12392689793836326\n","Epoch: 28     train index of 50 minibatch: 7      time used: 50.43427562713623\n","minibatch AVG loss: 0.11713460823753849\n","Epoch: 28     train index of 50 minibatch: 8      time used: 50.57322072982788\n","minibatch AVG loss: 0.09304739122628235\n","\n","Epoch: 28  train \n","Loss: 0.1066  Acc: 95.7620\n","Negative precision: 96.4087  recall: 97.2402\n","Negative sensitivity: 97.2402  specificity: 93.2313\n","Negative FPR: 6.7687  NPV: 94.7584\n","Negative TP: 2255.0\n","Negative TN: 1157.0\n","Negative FP: 84.0\n","Negative FN: 64.0\n","Positive precision: 94.7584  recall: 93.2313\n","Positive sensitivity: 93.2313  specificity: 97.2402\n","Positive FPR: 2.7598  NPV: 96.4087\n","Positive TP: 1157.0\n","Positive TN: 2255.0\n","Positive FP: 64.0\n","Positive FN: 84.0\n","\n","\n","Epoch: 28     val index of 50 minibatch: 1      time used: 19.21018409729004\n","minibatch AVG loss: 0.10655226498143748\n","\n","Epoch: 28  val \n","Loss: 0.2098  Acc: 90.1768\n","Negative precision: 91.8367  recall: 94.8795\n","Negative sensitivity: 94.8795  specificity: 83.7209\n","Negative FPR: 16.2791  NPV: 89.4410\n","Negative TP: 315.0\n","Negative TN: 144.0\n","Negative FP: 28.0\n","Negative FN: 17.0\n","Positive precision: 89.4410  recall: 83.7209\n","Positive sensitivity: 83.7209  specificity: 94.8795\n","Positive FPR: 5.1205  NPV: 91.8367\n","Positive TP: 144.0\n","Positive TN: 315.0\n","Positive FP: 17.0\n","Positive FN: 28.0\n","\n","\n","\n","Epoch 29/50\n","----------\n","Epoch: 29     train index of 50 minibatch: 1      time used: 51.15806007385254\n","minibatch AVG loss: 0.105125723881647\n","Epoch: 29     train index of 50 minibatch: 2      time used: 50.498043060302734\n","minibatch AVG loss: 0.06155237452592701\n","Epoch: 29     train index of 50 minibatch: 3      time used: 50.54911947250366\n","minibatch AVG loss: 0.1368133802129887\n","Epoch: 29     train index of 50 minibatch: 4      time used: 50.52691459655762\n","minibatch AVG loss: 0.10830218577757478\n","Epoch: 29     train index of 50 minibatch: 5      time used: 50.362334966659546\n","minibatch AVG loss: 0.11053572363918647\n","Epoch: 29     train index of 50 minibatch: 6      time used: 50.64033055305481\n","minibatch AVG loss: 0.15481635136064142\n","Epoch: 29     train index of 50 minibatch: 7      time used: 50.5288245677948\n","minibatch AVG loss: 0.0954890806786716\n","Epoch: 29     train index of 50 minibatch: 8      time used: 50.48163890838623\n","minibatch AVG loss: 0.11302127022529021\n","\n","Epoch: 29  train \n","Loss: 0.1086  Acc: 95.9304\n","Negative precision: 96.7770  recall: 97.1108\n","Negative sensitivity: 97.1108  specificity: 93.9565\n","Negative FPR: 6.0435  NPV: 94.5661\n","Negative TP: 2252.0\n","Negative TN: 1166.0\n","Negative FP: 75.0\n","Negative FN: 67.0\n","Positive precision: 94.5661  recall: 93.9565\n","Positive sensitivity: 93.9565  specificity: 97.1108\n","Positive FPR: 2.8892  NPV: 96.7770\n","Positive TP: 1166.0\n","Positive TN: 2252.0\n","Positive FP: 67.0\n","Positive FN: 75.0\n","\n","\n","Epoch: 29     val index of 50 minibatch: 1      time used: 19.169057369232178\n","minibatch AVG loss: 0.11503761578911507\n","\n","Epoch: 29  val \n","Loss: 0.2553  Acc: 89.7839\n","Negative precision: 89.6936  recall: 96.9880\n","Negative sensitivity: 96.9880  specificity: 78.4884\n","Negative FPR: 21.5116  NPV: 93.1034\n","Negative TP: 322.0\n","Negative TN: 135.0\n","Negative FP: 37.0\n","Negative FN: 10.0\n","Positive precision: 93.1034  recall: 78.4884\n","Positive sensitivity: 78.4884  specificity: 96.9880\n","Positive FPR: 3.0120  NPV: 89.6936\n","Positive TP: 135.0\n","Positive TN: 322.0\n","Positive FP: 10.0\n","Positive FN: 37.0\n","\n","\n","\n","Epoch 30/50\n","----------\n","Epoch: 30     train index of 50 minibatch: 1      time used: 51.20007562637329\n","minibatch AVG loss: 0.08244464146671816\n","Epoch: 30     train index of 50 minibatch: 2      time used: 50.651670694351196\n","minibatch AVG loss: 0.13082428199239074\n","Epoch: 30     train index of 50 minibatch: 3      time used: 50.490721702575684\n","minibatch AVG loss: 0.0635217174841091\n","Epoch: 30     train index of 50 minibatch: 4      time used: 50.676504611968994\n","minibatch AVG loss: 0.09290410023415462\n","Epoch: 30     train index of 50 minibatch: 5      time used: 50.39585304260254\n","minibatch AVG loss: 0.11385902116191574\n","Epoch: 30     train index of 50 minibatch: 6      time used: 50.65560746192932\n","minibatch AVG loss: 0.08988434082828461\n","Epoch: 30     train index of 50 minibatch: 7      time used: 50.53032970428467\n","minibatch AVG loss: 0.1414459001738578\n","Epoch: 30     train index of 50 minibatch: 8      time used: 50.57944297790527\n","minibatch AVG loss: 0.15591506764758378\n","\n","Epoch: 30  train \n","Loss: 0.1076  Acc: 95.5655\n","Negative precision: 96.5963  recall: 96.7213\n","Negative sensitivity: 96.7213  specificity: 93.6393\n","Negative FPR: 6.3607  NPV: 93.8660\n","Negative TP: 2242.0\n","Negative TN: 1163.0\n","Negative FP: 79.0\n","Negative FN: 76.0\n","Positive precision: 93.8660  recall: 93.6393\n","Positive sensitivity: 93.6393  specificity: 96.7213\n","Positive FPR: 3.2787  NPV: 96.5963\n","Positive TP: 1163.0\n","Positive TN: 2242.0\n","Positive FP: 76.0\n","Positive FN: 79.0\n","\n","\n","Epoch: 30     val index of 50 minibatch: 1      time used: 19.253567695617676\n","minibatch AVG loss: 0.2912355955550447\n","\n","Epoch: 30  val \n","Loss: 0.3040  Acc: 87.8193\n","Negative precision: 95.0820  recall: 87.3494\n","Negative sensitivity: 87.3494  specificity: 91.2791\n","Negative FPR: 8.7209  NPV: 78.8945\n","Negative TP: 290.0\n","Negative TN: 157.0\n","Negative FP: 15.0\n","Negative FN: 42.0\n","Positive precision: 78.8945  recall: 91.2791\n","Positive sensitivity: 91.2791  specificity: 87.3494\n","Positive FPR: 12.6506  NPV: 95.0820\n","Positive TP: 157.0\n","Positive TN: 290.0\n","Positive FP: 42.0\n","Positive FN: 15.0\n","\n","\n","\n","Epoch 31/50\n","----------\n","Epoch: 31     train index of 50 minibatch: 1      time used: 51.16262483596802\n","minibatch AVG loss: 0.08810541089624166\n","Epoch: 31     train index of 50 minibatch: 2      time used: 50.60385060310364\n","minibatch AVG loss: 0.14239195096306503\n","Epoch: 31     train index of 50 minibatch: 3      time used: 50.60003352165222\n","minibatch AVG loss: 0.10549242504173889\n","Epoch: 31     train index of 50 minibatch: 4      time used: 50.587499380111694\n","minibatch AVG loss: 0.130963939614594\n","Epoch: 31     train index of 50 minibatch: 5      time used: 50.661614656448364\n","minibatch AVG loss: 0.05918168325908482\n","Epoch: 31     train index of 50 minibatch: 6      time used: 50.36172389984131\n","minibatch AVG loss: 0.08781301086070016\n","Epoch: 31     train index of 50 minibatch: 7      time used: 50.73002028465271\n","minibatch AVG loss: 0.10860074374591931\n","Epoch: 31     train index of 50 minibatch: 8      time used: 50.53032207489014\n","minibatch AVG loss: 0.0874045422335621\n","\n","Epoch: 31  train \n","Loss: 0.0987  Acc: 96.0988\n","Negative precision: 96.6283  recall: 97.5442\n","Negative sensitivity: 97.5442  specificity: 93.6239\n","Negative FPR: 6.3761  NPV: 95.3164\n","Negative TP: 2264.0\n","Negative TN: 1160.0\n","Negative FP: 79.0\n","Negative FN: 57.0\n","Positive precision: 95.3164  recall: 93.6239\n","Positive sensitivity: 93.6239  specificity: 97.5442\n","Positive FPR: 2.4558  NPV: 96.6283\n","Positive TP: 1160.0\n","Positive TN: 2264.0\n","Positive FP: 57.0\n","Positive FN: 79.0\n","\n","\n","Epoch: 31     val index of 50 minibatch: 1      time used: 19.130314350128174\n","minibatch AVG loss: 0.3197821392910555\n","\n","Epoch: 31  val \n","Loss: 0.3120  Acc: 89.3910\n","Negative precision: 96.0912  recall: 88.8554\n","Negative sensitivity: 88.8554  specificity: 93.0233\n","Negative FPR: 6.9767  NPV: 81.2183\n","Negative TP: 295.0\n","Negative TN: 160.0\n","Negative FP: 12.0\n","Negative FN: 37.0\n","Positive precision: 81.2183  recall: 93.0233\n","Positive sensitivity: 93.0233  specificity: 88.8554\n","Positive FPR: 11.1446  NPV: 96.0912\n","Positive TP: 160.0\n","Positive TN: 295.0\n","Positive FP: 37.0\n","Positive FN: 12.0\n","\n","\n","\n","Epoch 32/50\n","----------\n","Epoch: 32     train index of 50 minibatch: 1      time used: 51.25157046318054\n","minibatch AVG loss: 0.13459183488972484\n","Epoch: 32     train index of 50 minibatch: 2      time used: 50.44186782836914\n","minibatch AVG loss: 0.12391027158126235\n","Epoch: 32     train index of 50 minibatch: 3      time used: 50.530818700790405\n","minibatch AVG loss: 0.06969776568585076\n","Epoch: 32     train index of 50 minibatch: 4      time used: 50.598674297332764\n","minibatch AVG loss: 0.13444606939796358\n","Epoch: 32     train index of 50 minibatch: 5      time used: 50.58879280090332\n","minibatch AVG loss: 0.09657213482074439\n","Epoch: 32     train index of 50 minibatch: 6      time used: 50.57147216796875\n","minibatch AVG loss: 0.09821258471696638\n","Epoch: 32     train index of 50 minibatch: 7      time used: 50.43318200111389\n","minibatch AVG loss: 0.09800106422575482\n","Epoch: 32     train index of 50 minibatch: 8      time used: 50.67880296707153\n","minibatch AVG loss: 0.12465387528704014\n","\n","Epoch: 32  train \n","Loss: 0.1093  Acc: 95.4533\n","Negative precision: 96.3918  recall: 96.7658\n","Negative sensitivity: 96.7658  specificity: 93.2313\n","Negative FPR: 6.7687  NPV: 93.9123\n","Negative TP: 2244.0\n","Negative TN: 1157.0\n","Negative FP: 84.0\n","Negative FN: 75.0\n","Positive precision: 93.9123  recall: 93.2313\n","Positive sensitivity: 93.2313  specificity: 96.7658\n","Positive FPR: 3.2342  NPV: 96.3918\n","Positive TP: 1157.0\n","Positive TN: 2244.0\n","Positive FP: 75.0\n","Positive FN: 84.0\n","\n","\n","Epoch: 32     val index of 50 minibatch: 1      time used: 19.20073890686035\n","minibatch AVG loss: 0.24471732998121298\n","\n","Epoch: 32  val \n","Loss: 0.2543  Acc: 91.1591\n","Negative precision: 97.4026  recall: 90.3614\n","Negative sensitivity: 90.3614  specificity: 95.3488\n","Negative FPR: 4.6512  NPV: 83.6735\n","Negative TP: 300.0\n","Negative TN: 164.0\n","Negative FP: 8.0\n","Negative FN: 32.0\n","Positive precision: 83.6735  recall: 95.3488\n","Positive sensitivity: 95.3488  specificity: 90.3614\n","Positive FPR: 9.6386  NPV: 97.4026\n","Positive TP: 164.0\n","Positive TN: 300.0\n","Positive FP: 32.0\n","Positive FN: 8.0\n","\n","\n","\n","Epoch 33/50\n","----------\n","Epoch: 33     train index of 50 minibatch: 1      time used: 51.232182025909424\n","minibatch AVG loss: 0.100132045308128\n","Epoch: 33     train index of 50 minibatch: 2      time used: 50.613065004348755\n","minibatch AVG loss: 0.1006994900945574\n","Epoch: 33     train index of 50 minibatch: 3      time used: 50.53890657424927\n","minibatch AVG loss: 0.09332527932710946\n","Epoch: 33     train index of 50 minibatch: 4      time used: 50.67283034324646\n","minibatch AVG loss: 0.06550293465610593\n","Epoch: 33     train index of 50 minibatch: 5      time used: 50.513063192367554\n","minibatch AVG loss: 0.1034403386968188\n","Epoch: 33     train index of 50 minibatch: 6      time used: 50.59197187423706\n","minibatch AVG loss: 0.09339525215909816\n","Epoch: 33     train index of 50 minibatch: 7      time used: 50.61409378051758\n","minibatch AVG loss: 0.09852098693721928\n","Epoch: 33     train index of 50 minibatch: 8      time used: 50.420432329177856\n","minibatch AVG loss: 0.11955146667547524\n","\n","Epoch: 33  train \n","Loss: 0.0937  Acc: 96.0988\n","Negative precision: 96.6652  recall: 97.4989\n","Negative sensitivity: 97.4989  specificity: 93.7147\n","Negative FPR: 6.2853  NPV: 95.2498\n","Negative TP: 2261.0\n","Negative TN: 1163.0\n","Negative FP: 78.0\n","Negative FN: 58.0\n","Positive precision: 95.2498  recall: 93.7147\n","Positive sensitivity: 93.7147  specificity: 97.4989\n","Positive FPR: 2.5011  NPV: 96.6652\n","Positive TP: 1163.0\n","Positive TN: 2261.0\n","Positive FP: 58.0\n","Positive FN: 78.0\n","\n","\n","Epoch: 33     val index of 50 minibatch: 1      time used: 19.178084135055542\n","minibatch AVG loss: 0.17389770371104532\n","\n","Epoch: 33  val \n","Loss: 0.2383  Acc: 90.7662\n","Negative precision: 92.8994  recall: 94.5783\n","Negative sensitivity: 94.5783  specificity: 86.0465\n","Negative FPR: 13.9535  NPV: 89.1566\n","Negative TP: 314.0\n","Negative TN: 148.0\n","Negative FP: 24.0\n","Negative FN: 18.0\n","Positive precision: 89.1566  recall: 86.0465\n","Positive sensitivity: 86.0465  specificity: 94.5783\n","Positive FPR: 5.4217  NPV: 92.8994\n","Positive TP: 148.0\n","Positive TN: 314.0\n","Positive FP: 18.0\n","Positive FN: 24.0\n","\n","\n","\n","Epoch 34/50\n","----------\n","Epoch: 34     train index of 50 minibatch: 1      time used: 51.0715913772583\n","minibatch AVG loss: 0.06411599538027075\n","Epoch: 34     train index of 50 minibatch: 2      time used: 50.61476254463196\n","minibatch AVG loss: 0.05821688090916723\n","Epoch: 34     train index of 50 minibatch: 3      time used: 50.47370791435242\n","minibatch AVG loss: 0.07549114821769763\n","Epoch: 34     train index of 50 minibatch: 4      time used: 50.46111989021301\n","minibatch AVG loss: 0.06385965037807181\n","Epoch: 34     train index of 50 minibatch: 5      time used: 50.61426854133606\n","minibatch AVG loss: 0.07922329814056867\n","Epoch: 34     train index of 50 minibatch: 6      time used: 50.59012007713318\n","minibatch AVG loss: 0.08700558986049145\n","Epoch: 34     train index of 50 minibatch: 7      time used: 50.503992557525635\n","minibatch AVG loss: 0.06278396064648405\n","Epoch: 34     train index of 50 minibatch: 8      time used: 50.646461486816406\n","minibatch AVG loss: 0.07808587769046425\n","\n","Epoch: 34  train \n","Loss: 0.0697  Acc: 97.3337\n","Negative precision: 97.8532  recall: 98.1904\n","Negative sensitivity: 98.1904  specificity: 95.9645\n","Negative FPR: 4.0355  NPV: 96.5881\n","Negative TP: 2279.0\n","Negative TN: 1189.0\n","Negative FP: 50.0\n","Negative FN: 42.0\n","Positive precision: 96.5881  recall: 95.9645\n","Positive sensitivity: 95.9645  specificity: 98.1904\n","Positive FPR: 1.8096  NPV: 97.8532\n","Positive TP: 1189.0\n","Positive TN: 2279.0\n","Positive FP: 42.0\n","Positive FN: 50.0\n","\n","\n","Epoch: 34     val index of 50 minibatch: 1      time used: 19.168776512145996\n","minibatch AVG loss: 0.2875841136080453\n","\n","Epoch: 34  val \n","Loss: 0.3301  Acc: 89.9804\n","Negative precision: 94.9686  recall: 90.9639\n","Negative sensitivity: 90.9639  specificity: 90.6977\n","Negative FPR: 9.3023  NPV: 83.8710\n","Negative TP: 302.0\n","Negative TN: 156.0\n","Negative FP: 16.0\n","Negative FN: 30.0\n","Positive precision: 83.8710  recall: 90.6977\n","Positive sensitivity: 90.6977  specificity: 90.9639\n","Positive FPR: 9.0361  NPV: 94.9686\n","Positive TP: 156.0\n","Positive TN: 302.0\n","Positive FP: 30.0\n","Positive FN: 16.0\n","\n","\n","\n","Epoch 35/50\n","----------\n","Epoch: 35     train index of 50 minibatch: 1      time used: 51.06327557563782\n","minibatch AVG loss: 0.07506385598826455\n","Epoch: 35     train index of 50 minibatch: 2      time used: 50.54547190666199\n","minibatch AVG loss: 0.0645392227685079\n","Epoch: 35     train index of 50 minibatch: 3      time used: 50.717464447021484\n","minibatch AVG loss: 0.07172017861623317\n","Epoch: 35     train index of 50 minibatch: 4      time used: 50.48858690261841\n","minibatch AVG loss: 0.14300522002740762\n","Epoch: 35     train index of 50 minibatch: 5      time used: 50.55563235282898\n","minibatch AVG loss: 0.11613487677415833\n","Epoch: 35     train index of 50 minibatch: 6      time used: 50.58242321014404\n","minibatch AVG loss: 0.08669720150995999\n","Epoch: 35     train index of 50 minibatch: 7      time used: 50.40966558456421\n","minibatch AVG loss: 0.057995013820473104\n","Epoch: 35     train index of 50 minibatch: 8      time used: 50.45765709877014\n","minibatch AVG loss: 0.041664824223844335\n","\n","Epoch: 35  train \n","Loss: 0.0802  Acc: 97.0811\n","Negative precision: 97.4743  recall: 98.1889\n","Negative sensitivity: 98.1889  specificity: 95.2458\n","Negative FPR: 4.7542  NPV: 96.5686\n","Negative TP: 2277.0\n","Negative TN: 1182.0\n","Negative FP: 59.0\n","Negative FN: 42.0\n","Positive precision: 96.5686  recall: 95.2458\n","Positive sensitivity: 95.2458  specificity: 98.1889\n","Positive FPR: 1.8111  NPV: 97.4743\n","Positive TP: 1182.0\n","Positive TN: 2277.0\n","Positive FP: 42.0\n","Positive FN: 59.0\n","\n","\n","Epoch: 35     val index of 50 minibatch: 1      time used: 19.203654050827026\n","minibatch AVG loss: 0.3766411627922207\n","\n","Epoch: 35  val \n","Loss: 0.3692  Acc: 86.6405\n","Negative precision: 94.3894  recall: 86.1446\n","Negative sensitivity: 86.1446  specificity: 90.1163\n","Negative FPR: 9.8837  NPV: 77.1144\n","Negative TP: 286.0\n","Negative TN: 155.0\n","Negative FP: 17.0\n","Negative FN: 46.0\n","Positive precision: 77.1144  recall: 90.1163\n","Positive sensitivity: 90.1163  specificity: 86.1446\n","Positive FPR: 13.8554  NPV: 94.3894\n","Positive TP: 155.0\n","Positive TN: 286.0\n","Positive FP: 46.0\n","Positive FN: 17.0\n","\n","\n","\n","Epoch 36/50\n","----------\n","Epoch: 36     train index of 50 minibatch: 1      time used: 51.13663673400879\n","minibatch AVG loss: 0.08964894625823945\n","Epoch: 36     train index of 50 minibatch: 2      time used: 50.364861488342285\n","minibatch AVG loss: 0.0790519122342812\n","Epoch: 36     train index of 50 minibatch: 3      time used: 50.692416191101074\n","minibatch AVG loss: 0.042049841574626046\n","Epoch: 36     train index of 50 minibatch: 4      time used: 50.38175344467163\n","minibatch AVG loss: 0.05410208833403885\n","Epoch: 36     train index of 50 minibatch: 5      time used: 50.68587350845337\n","minibatch AVG loss: 0.07546071899996605\n","Epoch: 36     train index of 50 minibatch: 6      time used: 50.607765674591064\n","minibatch AVG loss: 0.11519481366063701\n","Epoch: 36     train index of 50 minibatch: 7      time used: 50.64845585823059\n","minibatch AVG loss: 0.06300469464826165\n","Epoch: 36     train index of 50 minibatch: 8      time used: 50.67219161987305\n","minibatch AVG loss: 0.06400028125266545\n","\n","Epoch: 36  train \n","Loss: 0.0779  Acc: 97.1934\n","Negative precision: 97.7224  recall: 98.1018\n","Negative sensitivity: 98.1018  specificity: 95.7327\n","Negative FPR: 4.2673  NPV: 96.4315\n","Negative TP: 2274.0\n","Negative TN: 1189.0\n","Negative FP: 53.0\n","Negative FN: 44.0\n","Positive precision: 96.4315  recall: 95.7327\n","Positive sensitivity: 95.7327  specificity: 98.1018\n","Positive FPR: 1.8982  NPV: 97.7224\n","Positive TP: 1189.0\n","Positive TN: 2274.0\n","Positive FP: 44.0\n","Positive FN: 53.0\n","\n","\n","Epoch: 36     val index of 50 minibatch: 1      time used: 19.182599306106567\n","minibatch AVG loss: 0.2226640660240082\n","\n","Epoch: 36  val \n","Loss: 0.2790  Acc: 89.3910\n","Negative precision: 93.2722  recall: 91.8675\n","Negative sensitivity: 91.8675  specificity: 87.2093\n","Negative FPR: 12.7907  NPV: 84.7458\n","Negative TP: 305.0\n","Negative TN: 150.0\n","Negative FP: 22.0\n","Negative FN: 27.0\n","Positive precision: 84.7458  recall: 87.2093\n","Positive sensitivity: 87.2093  specificity: 91.8675\n","Positive FPR: 8.1325  NPV: 93.2722\n","Positive TP: 150.0\n","Positive TN: 305.0\n","Positive FP: 27.0\n","Positive FN: 22.0\n","\n","\n","\n","Epoch 37/50\n","----------\n","Epoch: 37     train index of 50 minibatch: 1      time used: 50.97177219390869\n","minibatch AVG loss: 0.13311012558406218\n","Epoch: 37     train index of 50 minibatch: 2      time used: 50.477275133132935\n","minibatch AVG loss: 0.06675031860824675\n","Epoch: 37     train index of 50 minibatch: 3      time used: 50.452088594436646\n","minibatch AVG loss: 0.062488366258330645\n","Epoch: 37     train index of 50 minibatch: 4      time used: 50.45567512512207\n","minibatch AVG loss: 0.09103844536177348\n","Epoch: 37     train index of 50 minibatch: 5      time used: 50.497405767440796\n","minibatch AVG loss: 0.0788539807125926\n","Epoch: 37     train index of 50 minibatch: 6      time used: 50.467939376831055\n","minibatch AVG loss: 0.04205233504821081\n","Epoch: 37     train index of 50 minibatch: 7      time used: 50.74396109580994\n","minibatch AVG loss: 0.03911292751377914\n","Epoch: 37     train index of 50 minibatch: 8      time used: 50.32669496536255\n","minibatch AVG loss: 0.08180089215573388\n","\n","Epoch: 37  train \n","Loss: 0.0774  Acc: 96.7724\n","Negative precision: 97.4613  recall: 97.7135\n","Negative sensitivity: 97.7135  specificity: 95.2496\n","Negative FPR: 4.7504  NPV: 95.7120\n","Negative TP: 2265.0\n","Negative TN: 1183.0\n","Negative FP: 59.0\n","Negative FN: 53.0\n","Positive precision: 95.7120  recall: 95.2496\n","Positive sensitivity: 95.2496  specificity: 97.7135\n","Positive FPR: 2.2865  NPV: 97.4613\n","Positive TP: 1183.0\n","Positive TN: 2265.0\n","Positive FP: 53.0\n","Positive FN: 59.0\n","\n","\n","Epoch: 37     val index of 50 minibatch: 1      time used: 19.234013557434082\n","minibatch AVG loss: 0.16777349322252122\n","\n","Epoch: 37  val \n","Loss: 0.2331  Acc: 91.3556\n","Negative precision: 92.9619  recall: 95.4819\n","Negative sensitivity: 95.4819  specificity: 86.0465\n","Negative FPR: 13.9535  NPV: 90.7975\n","Negative TP: 317.0\n","Negative TN: 148.0\n","Negative FP: 24.0\n","Negative FN: 15.0\n","Positive precision: 90.7975  recall: 86.0465\n","Positive sensitivity: 86.0465  specificity: 95.4819\n","Positive FPR: 4.5181  NPV: 92.9619\n","Positive TP: 148.0\n","Positive TN: 317.0\n","Positive FP: 15.0\n","Positive FN: 24.0\n","\n","\n","\n","Epoch 38/50\n","----------\n","Epoch: 38     train index of 50 minibatch: 1      time used: 50.94073247909546\n","minibatch AVG loss: 0.05104649177752435\n","Epoch: 38     train index of 50 minibatch: 2      time used: 50.710099935531616\n","minibatch AVG loss: 0.06984652317187283\n","Epoch: 38     train index of 50 minibatch: 3      time used: 50.623531341552734\n","minibatch AVG loss: 0.07435195037571248\n","Epoch: 38     train index of 50 minibatch: 4      time used: 50.472845792770386\n","minibatch AVG loss: 0.107918062650715\n","Epoch: 38     train index of 50 minibatch: 5      time used: 50.62604737281799\n","minibatch AVG loss: 0.07660695543047041\n","Epoch: 38     train index of 50 minibatch: 6      time used: 50.37747883796692\n","minibatch AVG loss: 0.037264927617798094\n","Epoch: 38     train index of 50 minibatch: 7      time used: 50.4599711894989\n","minibatch AVG loss: 0.0942894946213346\n","Epoch: 38     train index of 50 minibatch: 8      time used: 50.59844088554382\n","minibatch AVG loss: 0.08190915186773054\n","\n","Epoch: 38  train \n","Loss: 0.0730  Acc: 97.2495\n","Negative precision: 97.6027  recall: 98.3182\n","Negative sensitivity: 98.3182  specificity: 95.4875\n","Negative FPR: 4.5125  NPV: 96.8137\n","Negative TP: 2280.0\n","Negative TN: 1185.0\n","Negative FP: 56.0\n","Negative FN: 39.0\n","Positive precision: 96.8137  recall: 95.4875\n","Positive sensitivity: 95.4875  specificity: 98.3182\n","Positive FPR: 1.6818  NPV: 97.6027\n","Positive TP: 1185.0\n","Positive TN: 2280.0\n","Positive FP: 39.0\n","Positive FN: 56.0\n","\n","\n","Epoch: 38     val index of 50 minibatch: 1      time used: 19.297834634780884\n","minibatch AVG loss: 0.15923536834363403\n","\n","Epoch: 38  val \n","Loss: 0.2583  Acc: 89.5874\n","Negative precision: 92.0118  recall: 93.6747\n","Negative sensitivity: 93.6747  specificity: 84.3023\n","Negative FPR: 15.6977  NPV: 87.3494\n","Negative TP: 311.0\n","Negative TN: 145.0\n","Negative FP: 27.0\n","Negative FN: 21.0\n","Positive precision: 87.3494  recall: 84.3023\n","Positive sensitivity: 84.3023  specificity: 93.6747\n","Positive FPR: 6.3253  NPV: 92.0118\n","Positive TP: 145.0\n","Positive TN: 311.0\n","Positive FP: 21.0\n","Positive FN: 27.0\n","\n","\n","\n","Epoch 39/50\n","----------\n","Epoch: 39     train index of 50 minibatch: 1      time used: 51.177770376205444\n","minibatch AVG loss: 0.05917830227350351\n","Epoch: 39     train index of 50 minibatch: 2      time used: 50.5802161693573\n","minibatch AVG loss: 0.08798649106407538\n","Epoch: 39     train index of 50 minibatch: 3      time used: 50.46274375915527\n","minibatch AVG loss: 0.04240008333697915\n","Epoch: 39     train index of 50 minibatch: 4      time used: 50.63704490661621\n","minibatch AVG loss: 0.11778981027542614\n","Epoch: 39     train index of 50 minibatch: 5      time used: 50.44701838493347\n","minibatch AVG loss: 0.0556235002737958\n","Epoch: 39     train index of 50 minibatch: 6      time used: 50.51300549507141\n","minibatch AVG loss: 0.06229764315590728\n","Epoch: 39     train index of 50 minibatch: 7      time used: 50.68930435180664\n","minibatch AVG loss: 0.08814967366401107\n","Epoch: 39     train index of 50 minibatch: 8      time used: 50.642802476882935\n","minibatch AVG loss: 0.07669881280395202\n","\n","Epoch: 39  train \n","Loss: 0.0736  Acc: 97.3056\n","Negative precision: 97.8504  recall: 98.1458\n","Negative sensitivity: 98.1458  specificity: 95.9710\n","Negative FPR: 4.0290  NPV: 96.5154\n","Negative TP: 2276.0\n","Negative TN: 1191.0\n","Negative FP: 50.0\n","Negative FN: 43.0\n","Positive precision: 96.5154  recall: 95.9710\n","Positive sensitivity: 95.9710  specificity: 98.1458\n","Positive FPR: 1.8542  NPV: 97.8504\n","Positive TP: 1191.0\n","Positive TN: 2276.0\n","Positive FP: 43.0\n","Positive FN: 50.0\n","\n","\n","Epoch: 39     val index of 50 minibatch: 1      time used: 19.371376752853394\n","minibatch AVG loss: 0.17376998875370192\n","\n","Epoch: 39  val \n","Loss: 0.2526  Acc: 90.1768\n","Negative precision: 92.5816  recall: 93.9759\n","Negative sensitivity: 93.9759  specificity: 85.4651\n","Negative FPR: 14.5349  NPV: 88.0240\n","Negative TP: 312.0\n","Negative TN: 147.0\n","Negative FP: 25.0\n","Negative FN: 20.0\n","Positive precision: 88.0240  recall: 85.4651\n","Positive sensitivity: 85.4651  specificity: 93.9759\n","Positive FPR: 6.0241  NPV: 92.5816\n","Positive TP: 147.0\n","Positive TN: 312.0\n","Positive FP: 20.0\n","Positive FN: 25.0\n","\n","\n","\n","Epoch 40/50\n","----------\n","Epoch: 40     train index of 50 minibatch: 1      time used: 51.243626832962036\n","minibatch AVG loss: 0.06183121200563619\n","Epoch: 40     train index of 50 minibatch: 2      time used: 50.55737566947937\n","minibatch AVG loss: 0.06428032487572637\n","Epoch: 40     train index of 50 minibatch: 3      time used: 50.6166775226593\n","minibatch AVG loss: 0.03953422552556731\n","Epoch: 40     train index of 50 minibatch: 4      time used: 50.43394446372986\n","minibatch AVG loss: 0.04630212661984842\n","Epoch: 40     train index of 50 minibatch: 5      time used: 50.42008996009827\n","minibatch AVG loss: 0.04683202173840982\n","Epoch: 40     train index of 50 minibatch: 6      time used: 50.608866930007935\n","minibatch AVG loss: 0.0735032673671958\n","Epoch: 40     train index of 50 minibatch: 7      time used: 50.61314916610718\n","minibatch AVG loss: 0.07275194723741152\n","Epoch: 40     train index of 50 minibatch: 8      time used: 50.530203342437744\n","minibatch AVG loss: 0.03097538400674239\n","\n","Epoch: 40  train \n","Loss: 0.0537  Acc: 98.0073\n","Negative precision: 98.4920  recall: 98.5770\n","Negative sensitivity: 98.5770  specificity: 97.1797\n","Negative FPR: 2.8203  NPV: 97.3366\n","Negative TP: 2286.0\n","Negative TN: 1206.0\n","Negative FP: 35.0\n","Negative FN: 33.0\n","Positive precision: 97.3366  recall: 97.1797\n","Positive sensitivity: 97.1797  specificity: 98.5770\n","Positive FPR: 1.4230  NPV: 98.4920\n","Positive TP: 1206.0\n","Positive TN: 2286.0\n","Positive FP: 33.0\n","Positive FN: 35.0\n","\n","\n","Epoch: 40     val index of 50 minibatch: 1      time used: 19.27151370048523\n","minibatch AVG loss: 0.3028295654398607\n","\n","Epoch: 40  val \n","Loss: 0.3283  Acc: 90.1768\n","Negative precision: 95.8466  recall: 90.3614\n","Negative sensitivity: 90.3614  specificity: 92.4419\n","Negative FPR: 7.5581  NPV: 83.2461\n","Negative TP: 300.0\n","Negative TN: 159.0\n","Negative FP: 13.0\n","Negative FN: 32.0\n","Positive precision: 83.2461  recall: 92.4419\n","Positive sensitivity: 92.4419  specificity: 90.3614\n","Positive FPR: 9.6386  NPV: 95.8466\n","Positive TP: 159.0\n","Positive TN: 300.0\n","Positive FP: 32.0\n","Positive FN: 13.0\n","\n","\n","\n","Epoch 41/50\n","----------\n","Epoch: 41     train index of 50 minibatch: 1      time used: 51.18665957450867\n","minibatch AVG loss: 0.08856609635055065\n","Epoch: 41     train index of 50 minibatch: 2      time used: 50.6666533946991\n","minibatch AVG loss: 0.04337072368107329\n","Epoch: 41     train index of 50 minibatch: 3      time used: 50.55769610404968\n","minibatch AVG loss: 0.041645365958102046\n","Epoch: 41     train index of 50 minibatch: 4      time used: 50.53270125389099\n","minibatch AVG loss: 0.0879444500534737\n","Epoch: 41     train index of 50 minibatch: 5      time used: 50.45159935951233\n","minibatch AVG loss: 0.09073369397607166\n","Epoch: 41     train index of 50 minibatch: 6      time used: 50.58679151535034\n","minibatch AVG loss: 0.0696148413507035\n","Epoch: 41     train index of 50 minibatch: 7      time used: 50.73216962814331\n","minibatch AVG loss: 0.07864016316423658\n","Epoch: 41     train index of 50 minibatch: 8      time used: 50.65002632141113\n","minibatch AVG loss: 0.05091598169499775\n","\n","Epoch: 41  train \n","Loss: 0.0685  Acc: 97.6144\n","Negative precision: 98.2744  recall: 98.1897\n","Negative sensitivity: 98.1897  specificity: 96.7742\n","Negative FPR: 3.2258  NPV: 96.6184\n","Negative TP: 2278.0\n","Negative TN: 1200.0\n","Negative FP: 40.0\n","Negative FN: 42.0\n","Positive precision: 96.6184  recall: 96.7742\n","Positive sensitivity: 96.7742  specificity: 98.1897\n","Positive FPR: 1.8103  NPV: 98.2744\n","Positive TP: 1200.0\n","Positive TN: 2278.0\n","Positive FP: 42.0\n","Positive FN: 40.0\n","\n","\n","Epoch: 41     val index of 50 minibatch: 1      time used: 19.16645622253418\n","minibatch AVG loss: 0.285132161827496\n","\n","Epoch: 41  val \n","Loss: 0.3172  Acc: 88.8016\n","Negative precision: 95.1613  recall: 88.8554\n","Negative sensitivity: 88.8554  specificity: 91.2791\n","Negative FPR: 8.7209  NPV: 80.9278\n","Negative TP: 295.0\n","Negative TN: 157.0\n","Negative FP: 15.0\n","Negative FN: 37.0\n","Positive precision: 80.9278  recall: 91.2791\n","Positive sensitivity: 91.2791  specificity: 88.8554\n","Positive FPR: 11.1446  NPV: 95.1613\n","Positive TP: 157.0\n","Positive TN: 295.0\n","Positive FP: 37.0\n","Positive FN: 15.0\n","\n","\n","\n","Epoch 42/50\n","----------\n","Epoch: 42     train index of 50 minibatch: 1      time used: 51.223766803741455\n","minibatch AVG loss: 0.06009727570170071\n","Epoch: 42     train index of 50 minibatch: 2      time used: 50.518330574035645\n","minibatch AVG loss: 0.03739266720425803\n","Epoch: 42     train index of 50 minibatch: 3      time used: 50.44082283973694\n","minibatch AVG loss: 0.06187675342123839\n","Epoch: 42     train index of 50 minibatch: 4      time used: 50.49110770225525\n","minibatch AVG loss: 0.07159431420179317\n","Epoch: 42     train index of 50 minibatch: 5      time used: 50.67729568481445\n","minibatch AVG loss: 0.0702868772301008\n","Epoch: 42     train index of 50 minibatch: 6      time used: 50.47006940841675\n","minibatch AVG loss: 0.09204833837546175\n","Epoch: 42     train index of 50 minibatch: 7      time used: 50.53665328025818\n","minibatch AVG loss: 0.056291097254143094\n","Epoch: 42     train index of 50 minibatch: 8      time used: 50.645482778549194\n","minibatch AVG loss: 0.05536761764029507\n","\n","Epoch: 42  train \n","Loss: 0.0615  Acc: 97.4740\n","Negative precision: 98.0612  recall: 98.1881\n","Negative sensitivity: 98.1881  specificity: 96.3768\n","Negative FPR: 3.6232  NPV: 96.6102\n","Negative TP: 2276.0\n","Negative TN: 1197.0\n","Negative FP: 45.0\n","Negative FN: 42.0\n","Positive precision: 96.6102  recall: 96.3768\n","Positive sensitivity: 96.3768  specificity: 98.1881\n","Positive FPR: 1.8119  NPV: 98.0612\n","Positive TP: 1197.0\n","Positive TN: 2276.0\n","Positive FP: 42.0\n","Positive FN: 45.0\n","\n","\n","Epoch: 42     val index of 50 minibatch: 1      time used: 19.10356569290161\n","minibatch AVG loss: 0.3462941827671966\n","\n","Epoch: 42  val \n","Loss: 0.3557  Acc: 88.4086\n","Negative precision: 95.7237  recall: 87.6506\n","Negative sensitivity: 87.6506  specificity: 92.4419\n","Negative FPR: 7.5581  NPV: 79.5000\n","Negative TP: 291.0\n","Negative TN: 159.0\n","Negative FP: 13.0\n","Negative FN: 41.0\n","Positive precision: 79.5000  recall: 92.4419\n","Positive sensitivity: 92.4419  specificity: 87.6506\n","Positive FPR: 12.3494  NPV: 95.7237\n","Positive TP: 159.0\n","Positive TN: 291.0\n","Positive FP: 41.0\n","Positive FN: 13.0\n","\n","\n","\n","Epoch 43/50\n","----------\n","Epoch: 43     train index of 50 minibatch: 1      time used: 51.235668420791626\n","minibatch AVG loss: 0.07741523010037782\n","Epoch: 43     train index of 50 minibatch: 2      time used: 50.38094425201416\n","minibatch AVG loss: 0.04946716907084919\n","Epoch: 43     train index of 50 minibatch: 3      time used: 50.59950661659241\n","minibatch AVG loss: 0.04624656928994227\n","Epoch: 43     train index of 50 minibatch: 4      time used: 50.498778104782104\n","minibatch AVG loss: 0.04306884619712946\n","Epoch: 43     train index of 50 minibatch: 5      time used: 50.59700560569763\n","minibatch AVG loss: 0.047787077275716\n","Epoch: 43     train index of 50 minibatch: 6      time used: 50.45888662338257\n","minibatch AVG loss: 0.08162567370440228\n","Epoch: 43     train index of 50 minibatch: 7      time used: 50.570568799972534\n","minibatch AVG loss: 0.06237154236179777\n","Epoch: 43     train index of 50 minibatch: 8      time used: 50.47702622413635\n","minibatch AVG loss: 0.07547231978387572\n","\n","Epoch: 43  train \n","Loss: 0.0596  Acc: 97.7266\n","Negative precision: 98.1521  recall: 98.4907\n","Negative sensitivity: 98.4907  specificity: 96.5351\n","Negative FPR: 3.4649  NPV: 97.1614\n","Negative TP: 2284.0\n","Negative TN: 1198.0\n","Negative FP: 43.0\n","Negative FN: 35.0\n","Positive precision: 97.1614  recall: 96.5351\n","Positive sensitivity: 96.5351  specificity: 98.4907\n","Positive FPR: 1.5093  NPV: 98.1521\n","Positive TP: 1198.0\n","Positive TN: 2284.0\n","Positive FP: 35.0\n","Positive FN: 43.0\n","\n","\n","Epoch: 43     val index of 50 minibatch: 1      time used: 19.20573925971985\n","minibatch AVG loss: 0.23042701764268714\n","\n","Epoch: 43  val \n","Loss: 0.2533  Acc: 90.1768\n","Negative precision: 96.1415  recall: 90.0602\n","Negative sensitivity: 90.0602  specificity: 93.0233\n","Negative FPR: 6.9767  NPV: 82.9016\n","Negative TP: 299.0\n","Negative TN: 160.0\n","Negative FP: 12.0\n","Negative FN: 33.0\n","Positive precision: 82.9016  recall: 93.0233\n","Positive sensitivity: 93.0233  specificity: 90.0602\n","Positive FPR: 9.9398  NPV: 96.1415\n","Positive TP: 160.0\n","Positive TN: 299.0\n","Positive FP: 33.0\n","Positive FN: 12.0\n","\n","\n","\n","Epoch 44/50\n","----------\n","Epoch: 44     train index of 50 minibatch: 1      time used: 51.06763815879822\n","minibatch AVG loss: 0.03448746041132836\n","Epoch: 44     train index of 50 minibatch: 2      time used: 50.60482907295227\n","minibatch AVG loss: 0.04108311438409146\n","Epoch: 44     train index of 50 minibatch: 3      time used: 50.67683291435242\n","minibatch AVG loss: 0.0807876322933589\n","Epoch: 44     train index of 50 minibatch: 4      time used: 50.53284549713135\n","minibatch AVG loss: 0.04068656210321933\n","Epoch: 44     train index of 50 minibatch: 5      time used: 50.485002756118774\n","minibatch AVG loss: 0.05614263797120657\n","Epoch: 44     train index of 50 minibatch: 6      time used: 50.516510248184204\n","minibatch AVG loss: 0.047850084209512714\n","Epoch: 44     train index of 50 minibatch: 7      time used: 50.344966650009155\n","minibatch AVG loss: 0.08259915212576743\n","Epoch: 44     train index of 50 minibatch: 8      time used: 50.37536334991455\n","minibatch AVG loss: 0.057219096450135114\n","\n","Epoch: 44  train \n","Loss: 0.0553  Acc: 97.4179\n","Negative precision: 97.9785  recall: 98.1897\n","Negative sensitivity: 98.1897  specificity: 96.2097\n","Negative FPR: 3.7903  NPV: 96.5992\n","Negative TP: 2278.0\n","Negative TN: 1193.0\n","Negative FP: 47.0\n","Negative FN: 42.0\n","Positive precision: 96.5992  recall: 96.2097\n","Positive sensitivity: 96.2097  specificity: 98.1897\n","Positive FPR: 1.8103  NPV: 97.9785\n","Positive TP: 1193.0\n","Positive TN: 2278.0\n","Positive FP: 42.0\n","Positive FN: 47.0\n","\n","\n","Epoch: 44     val index of 50 minibatch: 1      time used: 19.176798105239868\n","minibatch AVG loss: 0.23632214399112855\n","\n","Epoch: 44  val \n","Loss: 0.2834  Acc: 89.7839\n","Negative precision: 94.6708  recall: 90.9639\n","Negative sensitivity: 90.9639  specificity: 90.1163\n","Negative FPR: 9.8837  NPV: 83.7838\n","Negative TP: 302.0\n","Negative TN: 155.0\n","Negative FP: 17.0\n","Negative FN: 30.0\n","Positive precision: 83.7838  recall: 90.1163\n","Positive sensitivity: 90.1163  specificity: 90.9639\n","Positive FPR: 9.0361  NPV: 94.6708\n","Positive TP: 155.0\n","Positive TN: 302.0\n","Positive FP: 30.0\n","Positive FN: 17.0\n","\n","\n","\n","Epoch 45/50\n","----------\n","Epoch: 45     train index of 50 minibatch: 1      time used: 51.23389005661011\n","minibatch AVG loss: 0.043377137730567485\n","Epoch: 45     train index of 50 minibatch: 2      time used: 50.5009868144989\n","minibatch AVG loss: 0.06734003098659741\n","Epoch: 45     train index of 50 minibatch: 3      time used: 50.34264922142029\n","minibatch AVG loss: 0.054393067132041326\n","Epoch: 45     train index of 50 minibatch: 4      time used: 50.63473916053772\n","minibatch AVG loss: 0.07601127691392322\n","Epoch: 45     train index of 50 minibatch: 5      time used: 50.67553639411926\n","minibatch AVG loss: 0.061659773084684275\n","Epoch: 45     train index of 50 minibatch: 6      time used: 50.46247577667236\n","minibatch AVG loss: 0.04105497112963349\n","Epoch: 45     train index of 50 minibatch: 7      time used: 50.58636403083801\n","minibatch AVG loss: 0.05659698449613643\n","Epoch: 45     train index of 50 minibatch: 8      time used: 50.45141625404358\n","minibatch AVG loss: 0.07067757098498988\n","\n","Epoch: 45  train \n","Loss: 0.0567  Acc: 97.7828\n","Negative precision: 98.2781  recall: 98.4476\n","Negative sensitivity: 98.4476  specificity: 96.7768\n","Negative FPR: 3.2232  NPV: 97.0897\n","Negative TP: 2283.0\n","Negative TN: 1201.0\n","Negative FP: 40.0\n","Negative FN: 36.0\n","Positive precision: 97.0897  recall: 96.7768\n","Positive sensitivity: 96.7768  specificity: 98.4476\n","Positive FPR: 1.5524  NPV: 98.2781\n","Positive TP: 1201.0\n","Positive TN: 2283.0\n","Positive FP: 36.0\n","Positive FN: 40.0\n","\n","\n","Epoch: 45     val index of 50 minibatch: 1      time used: 19.235832452774048\n","minibatch AVG loss: 0.21206140154623426\n","\n","Epoch: 45  val \n","Loss: 0.3047  Acc: 90.5697\n","Negative precision: 93.3934  recall: 93.6747\n","Negative sensitivity: 93.6747  specificity: 87.2093\n","Negative FPR: 12.7907  NPV: 87.7193\n","Negative TP: 311.0\n","Negative TN: 150.0\n","Negative FP: 22.0\n","Negative FN: 21.0\n","Positive precision: 87.7193  recall: 87.2093\n","Positive sensitivity: 87.2093  specificity: 93.6747\n","Positive FPR: 6.3253  NPV: 93.3934\n","Positive TP: 150.0\n","Positive TN: 311.0\n","Positive FP: 21.0\n","Positive FN: 22.0\n","\n","\n","\n","Epoch 46/50\n","----------\n","Epoch: 46     train index of 50 minibatch: 1      time used: 50.964900732040405\n","minibatch AVG loss: 0.027218456612463342\n","Epoch: 46     train index of 50 minibatch: 2      time used: 50.40400576591492\n","minibatch AVG loss: 0.07115455568244215\n","Epoch: 46     train index of 50 minibatch: 3      time used: 50.59057903289795\n","minibatch AVG loss: 0.02292467791849049\n","Epoch: 46     train index of 50 minibatch: 4      time used: 50.50736379623413\n","minibatch AVG loss: 0.06159985928868991\n","Epoch: 46     train index of 50 minibatch: 5      time used: 50.48229670524597\n","minibatch AVG loss: 0.04496380977099761\n","Epoch: 46     train index of 50 minibatch: 6      time used: 50.59699535369873\n","minibatch AVG loss: 0.05221599741395039\n","Epoch: 46     train index of 50 minibatch: 7      time used: 50.40470504760742\n","minibatch AVG loss: 0.042334972923708844\n","Epoch: 46     train index of 50 minibatch: 8      time used: 50.6464946269989\n","minibatch AVG loss: 0.046391577247268286\n","\n","Epoch: 46  train \n","Loss: 0.0477  Acc: 97.8389\n","Negative precision: 98.3211  recall: 98.4907\n","Negative sensitivity: 98.4907  specificity: 96.8574\n","Negative FPR: 3.1426  NPV: 97.1706\n","Negative TP: 2284.0\n","Negative TN: 1202.0\n","Negative FP: 39.0\n","Negative FN: 35.0\n","Positive precision: 97.1706  recall: 96.8574\n","Positive sensitivity: 96.8574  specificity: 98.4907\n","Positive FPR: 1.5093  NPV: 98.3211\n","Positive TP: 1202.0\n","Positive TN: 2284.0\n","Positive FP: 35.0\n","Positive FN: 39.0\n","\n","\n","Epoch: 46     val index of 50 minibatch: 1      time used: 19.33012342453003\n","minibatch AVG loss: 0.19278688171316388\n","\n","Epoch: 46  val \n","Loss: 0.2963  Acc: 90.1768\n","Negative precision: 92.8358  recall: 93.6747\n","Negative sensitivity: 93.6747  specificity: 86.0465\n","Negative FPR: 13.9535  NPV: 87.5740\n","Negative TP: 311.0\n","Negative TN: 148.0\n","Negative FP: 24.0\n","Negative FN: 21.0\n","Positive precision: 87.5740  recall: 86.0465\n","Positive sensitivity: 86.0465  specificity: 93.6747\n","Positive FPR: 6.3253  NPV: 92.8358\n","Positive TP: 148.0\n","Positive TN: 311.0\n","Positive FP: 21.0\n","Positive FN: 24.0\n","\n","\n","\n","Epoch 47/50\n","----------\n","Epoch: 47     train index of 50 minibatch: 1      time used: 51.278615951538086\n","minibatch AVG loss: 0.03926480735608493\n","Epoch: 47     train index of 50 minibatch: 2      time used: 50.425596714019775\n","minibatch AVG loss: 0.036882911403372416\n","Epoch: 47     train index of 50 minibatch: 3      time used: 50.44949126243591\n","minibatch AVG loss: 0.032975537343536414\n","Epoch: 47     train index of 50 minibatch: 4      time used: 50.673312187194824\n","minibatch AVG loss: 0.03063316790518911\n","Epoch: 47     train index of 50 minibatch: 5      time used: 50.59705376625061\n","minibatch AVG loss: 0.07556103572656866\n","Epoch: 47     train index of 50 minibatch: 6      time used: 50.50468564033508\n","minibatch AVG loss: 0.021481267832277808\n","Epoch: 47     train index of 50 minibatch: 7      time used: 50.51223802566528\n","minibatch AVG loss: 0.03134351547647384\n","Epoch: 47     train index of 50 minibatch: 8      time used: 50.655272483825684\n","minibatch AVG loss: 0.016161452750966417\n","\n","Epoch: 47  train \n","Loss: 0.0377  Acc: 98.4283\n","Negative precision: 98.6678  recall: 99.0509\n","Negative sensitivity: 99.0509  specificity: 97.5040\n","Negative FPR: 2.4960  NPV: 98.2157\n","Negative TP: 2296.0\n","Negative TN: 1211.0\n","Negative FP: 31.0\n","Negative FN: 22.0\n","Positive precision: 98.2157  recall: 97.5040\n","Positive sensitivity: 97.5040  specificity: 99.0509\n","Positive FPR: 0.9491  NPV: 98.6678\n","Positive TP: 1211.0\n","Positive TN: 2296.0\n","Positive FP: 22.0\n","Positive FN: 31.0\n","\n","\n","Epoch: 47     val index of 50 minibatch: 1      time used: 19.12182116508484\n","minibatch AVG loss: 0.15415053090001493\n","\n","Epoch: 47  val \n","Loss: 0.3842  Acc: 89.9804\n","Negative precision: 90.6250  recall: 96.0843\n","Negative sensitivity: 96.0843  specificity: 80.8140\n","Negative FPR: 19.1860  NPV: 91.4474\n","Negative TP: 319.0\n","Negative TN: 139.0\n","Negative FP: 33.0\n","Negative FN: 13.0\n","Positive precision: 91.4474  recall: 80.8140\n","Positive sensitivity: 80.8140  specificity: 96.0843\n","Positive FPR: 3.9157  NPV: 90.6250\n","Positive TP: 139.0\n","Positive TN: 319.0\n","Positive FP: 13.0\n","Positive FN: 33.0\n","\n","\n","\n","Epoch 48/50\n","----------\n","Epoch: 48     train index of 50 minibatch: 1      time used: 51.14104223251343\n","minibatch AVG loss: 0.08884547007488436\n","Epoch: 48     train index of 50 minibatch: 2      time used: 50.637635231018066\n","minibatch AVG loss: 0.06522949363919907\n","Epoch: 48     train index of 50 minibatch: 3      time used: 50.42904543876648\n","minibatch AVG loss: 0.09531718583166367\n","Epoch: 48     train index of 50 minibatch: 4      time used: 50.48301959037781\n","minibatch AVG loss: 0.030162314814515413\n","Epoch: 48     train index of 50 minibatch: 5      time used: 50.64095592498779\n","minibatch AVG loss: 0.03351295156578999\n","Epoch: 48     train index of 50 minibatch: 6      time used: 50.69905138015747\n","minibatch AVG loss: 0.05622285066347103\n","Epoch: 48     train index of 50 minibatch: 7      time used: 50.57940340042114\n","minibatch AVG loss: 0.03881675451702904\n","Epoch: 48     train index of 50 minibatch: 8      time used: 50.35865545272827\n","minibatch AVG loss: 0.03748368397908052\n","\n","Epoch: 48  train \n","Loss: 0.0563  Acc: 97.5582\n","Negative precision: 98.1051  recall: 98.2744\n","Negative sensitivity: 98.2744  specificity: 96.4573\n","Negative FPR: 3.5427  NPV: 96.7690\n","Negative TP: 2278.0\n","Negative TN: 1198.0\n","Negative FP: 44.0\n","Negative FN: 40.0\n","Positive precision: 96.7690  recall: 96.4573\n","Positive sensitivity: 96.4573  specificity: 98.2744\n","Positive FPR: 1.7256  NPV: 98.1051\n","Positive TP: 1198.0\n","Positive TN: 2278.0\n","Positive FP: 40.0\n","Positive FN: 44.0\n","\n","\n","Epoch: 48     val index of 50 minibatch: 1      time used: 19.21998357772827\n","minibatch AVG loss: 0.38116145691878045\n","\n","Epoch: 48  val \n","Loss: 0.3739  Acc: 89.9804\n","Negative precision: 96.7320  recall: 89.1566\n","Negative sensitivity: 89.1566  specificity: 94.1860\n","Negative FPR: 5.8140  NPV: 81.8182\n","Negative TP: 296.0\n","Negative TN: 162.0\n","Negative FP: 10.0\n","Negative FN: 36.0\n","Positive precision: 81.8182  recall: 94.1860\n","Positive sensitivity: 94.1860  specificity: 89.1566\n","Positive FPR: 10.8434  NPV: 96.7320\n","Positive TP: 162.0\n","Positive TN: 296.0\n","Positive FP: 36.0\n","Positive FN: 10.0\n","\n","\n","\n","Epoch 49/50\n","----------\n","Epoch: 49     train index of 50 minibatch: 1      time used: 51.25639772415161\n","minibatch AVG loss: 0.045727568557485936\n","Epoch: 49     train index of 50 minibatch: 2      time used: 50.79588985443115\n","minibatch AVG loss: 0.047292801566654816\n","Epoch: 49     train index of 50 minibatch: 3      time used: 50.628413677215576\n","minibatch AVG loss: 0.06742138759756927\n","Epoch: 49     train index of 50 minibatch: 4      time used: 50.41205453872681\n","minibatch AVG loss: 0.060359371712256686\n","Epoch: 49     train index of 50 minibatch: 5      time used: 50.58748173713684\n","minibatch AVG loss: 0.03403657239425229\n","Epoch: 49     train index of 50 minibatch: 6      time used: 50.68105363845825\n","minibatch AVG loss: 0.06384866739041171\n","Epoch: 49     train index of 50 minibatch: 7      time used: 50.46370530128479\n","minibatch AVG loss: 0.046556735709491474\n","Epoch: 49     train index of 50 minibatch: 8      time used: 50.32394552230835\n","minibatch AVG loss: 0.04618821719050174\n","\n","Epoch: 49  train \n","Loss: 0.0544  Acc: 97.8108\n","Negative precision: 98.4038  recall: 98.3614\n","Negative sensitivity: 98.3614  specificity: 97.0185\n","Negative FPR: 2.9815  NPV: 96.9404\n","Negative TP: 2281.0\n","Negative TN: 1204.0\n","Negative FP: 37.0\n","Negative FN: 38.0\n","Positive precision: 96.9404  recall: 97.0185\n","Positive sensitivity: 97.0185  specificity: 98.3614\n","Positive FPR: 1.6386  NPV: 98.4038\n","Positive TP: 1204.0\n","Positive TN: 2281.0\n","Positive FP: 38.0\n","Positive FN: 37.0\n","\n","\n","Epoch: 49     val index of 50 minibatch: 1      time used: 19.21412491798401\n","minibatch AVG loss: 0.20026155473573454\n","\n","Epoch: 49  val \n","Loss: 0.3015  Acc: 90.7662\n","Negative precision: 92.3977  recall: 95.1807\n","Negative sensitivity: 95.1807  specificity: 84.8837\n","Negative FPR: 15.1163  NPV: 90.1235\n","Negative TP: 316.0\n","Negative TN: 146.0\n","Negative FP: 26.0\n","Negative FN: 16.0\n","Positive precision: 90.1235  recall: 84.8837\n","Positive sensitivity: 84.8837  specificity: 95.1807\n","Positive FPR: 4.8193  NPV: 92.3977\n","Positive TP: 146.0\n","Positive TN: 316.0\n","Positive FP: 16.0\n","Positive FN: 26.0\n","\n","\n","\n","Epoch 50/50\n","----------\n","Epoch: 50     train index of 50 minibatch: 1      time used: 51.3516685962677\n","minibatch AVG loss: 0.03908431727119023\n","Epoch: 50     train index of 50 minibatch: 2      time used: 50.483417987823486\n","minibatch AVG loss: 0.02964073022187222\n","Epoch: 50     train index of 50 minibatch: 3      time used: 50.37483525276184\n","minibatch AVG loss: 0.04343297177951172\n","Epoch: 50     train index of 50 minibatch: 4      time used: 50.694167137145996\n","minibatch AVG loss: 0.037343562631431265\n","Epoch: 50     train index of 50 minibatch: 5      time used: 50.730687856674194\n","minibatch AVG loss: 0.04242750892793992\n","Epoch: 50     train index of 50 minibatch: 6      time used: 50.39883375167847\n","minibatch AVG loss: 0.049933112892322246\n","Epoch: 50     train index of 50 minibatch: 7      time used: 50.3761887550354\n","minibatch AVG loss: 0.03893785230087815\n","Epoch: 50     train index of 50 minibatch: 8      time used: 50.727251052856445\n","minibatch AVG loss: 0.059063421492028284\n","\n","Epoch: 50  train \n","Loss: 0.0419  Acc: 98.4002\n","Negative precision: 98.7091  recall: 98.9646\n","Negative sensitivity: 98.9646  specificity: 97.5845\n","Negative FPR: 2.4155  NPV: 98.0583\n","Negative TP: 2294.0\n","Negative TN: 1212.0\n","Negative FP: 30.0\n","Negative FN: 24.0\n","Positive precision: 98.0583  recall: 97.5845\n","Positive sensitivity: 97.5845  specificity: 98.9646\n","Positive FPR: 1.0354  NPV: 98.7091\n","Positive TP: 1212.0\n","Positive TN: 2294.0\n","Positive FP: 24.0\n","Positive FN: 30.0\n","\n","\n","Epoch: 50     val index of 50 minibatch: 1      time used: 19.334981679916382\n","minibatch AVG loss: 0.24428260089094692\n","\n","Epoch: 50  val \n","Loss: 0.3129  Acc: 90.7662\n","Negative precision: 94.4785  recall: 92.7711\n","Negative sensitivity: 92.7711  specificity: 89.5349\n","Negative FPR: 10.4651  NPV: 86.5169\n","Negative TP: 308.0\n","Negative TN: 154.0\n","Negative FP: 18.0\n","Negative FN: 24.0\n","Positive precision: 86.5169  recall: 89.5349\n","Positive sensitivity: 89.5349  specificity: 92.7711\n","Positive FPR: 7.2289  NPV: 94.4785\n","Positive TP: 154.0\n","Positive TN: 308.0\n","Positive FP: 24.0\n","Positive FN: 18.0\n","\n","\n","\n","Training complete in 395m 53s\n","Best epoch idx:  14\n","Best epoch train Acc: 94.527084\n","Best epoch val Acc: 91.944990\n","Negative precision: 94.0476  recall: 95.1807\n","Negative sensitivity: 95.1807  specificity: 88.3721\n","Negative FPR: 11.6279  NPV: 90.4762\n","Positive precision: 90.4762  recall: 88.3721\n","Positive sensitivity: 88.3721  specificity: 95.1807\n","Positive FPR: 4.8193  NPV: 94.0476\n","model trained by GPU (idx:0) has been saved at  /home/Pathology_Experiment/saved_models/CLS_ViT_384_401_PT_lf25_b8_ROSE_CLS.pth\n"]}],"source":["!python Train.py --model_idx ViT_384_401_PT_lf25_b8_ROSE_CLS --patch_strategy loss_hold --ratio_strategy loss_hold --enable_tensorboard --edge_size 384 --data_augmentation_mode 0 --lr 0.00001 --lrf 0.25 --dataroot /data/Pathology_Experiment/dataset/ROSE_CLS --model_path /home/Pathology_Experiment/saved_models --draw_root /home/Pathology_Experiment/runs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"W2kidnpz2XLY","outputId":"b7031004-7791-4756-82ac-4935a1841009"},"outputs":[{"name":"stdout","output_type":"stream","text":["class_names: ['Negative', 'Positive']\n","['convit_base',\n"," 'convit_small',\n"," 'convit_tiny',\n"," 'crossvit_9_240',\n"," 'crossvit_9_dagger_240',\n"," 'crossvit_15_240',\n"," 'crossvit_15_dagger_240',\n"," 'crossvit_15_dagger_408',\n"," 'crossvit_18_240',\n"," 'crossvit_18_dagger_240',\n"," 'crossvit_18_dagger_408',\n"," 'crossvit_base_240',\n"," 'crossvit_small_240',\n"," 'crossvit_tiny_240',\n"," 'gcvit_base',\n"," 'gcvit_small',\n"," 'gcvit_tiny',\n"," 'gcvit_xtiny',\n"," 'gcvit_xxtiny',\n"," 'levit_128',\n"," 'levit_128s',\n"," 'levit_192',\n"," 'levit_256',\n"," 'levit_256d',\n"," 'levit_384',\n"," 'maxvit_base_224',\n"," 'maxvit_large_224',\n"," 'maxvit_nano_rw_256',\n"," 'maxvit_pico_rw_256',\n"," 'maxvit_rmlp_nano_rw_256',\n"," 'maxvit_rmlp_pico_rw_256',\n"," 'maxvit_rmlp_small_rw_224',\n"," 'maxvit_rmlp_small_rw_256',\n"," 'maxvit_rmlp_tiny_rw_256',\n"," 'maxvit_small_224',\n"," 'maxvit_tiny_224',\n"," 'maxvit_tiny_pm_256',\n"," 'maxvit_tiny_rw_224',\n"," 'maxvit_tiny_rw_256',\n"," 'maxvit_xlarge_224',\n"," 'maxxvit_rmlp_nano_rw_256',\n"," 'maxxvit_rmlp_small_rw_256',\n"," 'maxxvit_rmlp_tiny_rw_256',\n"," 'mobilevit_s',\n"," 'mobilevit_xs',\n"," 'mobilevit_xxs',\n"," 'mobilevitv2_050',\n"," 'mobilevitv2_075',\n"," 'mobilevitv2_100',\n"," 'mobilevitv2_125',\n"," 'mobilevitv2_150',\n"," 'mobilevitv2_150_384_in22ft1k',\n"," 'mobilevitv2_150_in22ft1k',\n"," 'mobilevitv2_175',\n"," 'mobilevitv2_175_384_in22ft1k',\n"," 'mobilevitv2_175_in22ft1k',\n"," 'mobilevitv2_200',\n"," 'mobilevitv2_200_384_in22ft1k',\n"," 'mobilevitv2_200_in22ft1k',\n"," 'mvitv2_base',\n"," 'mvitv2_large',\n"," 'mvitv2_small',\n"," 'mvitv2_small_cls',\n"," 'mvitv2_tiny',\n"," 'semobilevit_s',\n"," 'vit_base_patch8_224',\n"," 'vit_base_patch8_224_dino',\n"," 'vit_base_patch8_224_in21k',\n"," 'vit_base_patch16_18x2_224',\n"," 'vit_base_patch16_224',\n"," 'vit_base_patch16_224_dino',\n"," 'vit_base_patch16_224_in21k',\n"," 'vit_base_patch16_224_miil',\n"," 'vit_base_patch16_224_miil_in21k',\n"," 'vit_base_patch16_224_sam',\n"," 'vit_base_patch16_384',\n"," 'vit_base_patch16_plus_240',\n"," 'vit_base_patch16_rpn_224',\n"," 'vit_base_patch32_224',\n"," 'vit_base_patch32_224_clip_laion2b',\n"," 'vit_base_patch32_224_in21k',\n"," 'vit_base_patch32_224_sam',\n"," 'vit_base_patch32_384',\n"," 'vit_base_patch32_plus_256',\n"," 'vit_base_r26_s32_224',\n"," 'vit_base_r50_s16_224',\n"," 'vit_base_r50_s16_224_in21k',\n"," 'vit_base_r50_s16_384',\n"," 'vit_base_resnet26d_224',\n"," 'vit_base_resnet50_224_in21k',\n"," 'vit_base_resnet50_384',\n"," 'vit_base_resnet50d_224',\n"," 'vit_giant_patch14_224',\n"," 'vit_giant_patch14_224_clip_laion2b',\n"," 'vit_gigantic_patch14_224',\n"," 'vit_huge_patch14_224',\n"," 'vit_huge_patch14_224_clip_laion2b',\n"," 'vit_huge_patch14_224_in21k',\n"," 'vit_large_patch14_224',\n"," 'vit_large_patch14_224_clip_laion2b',\n"," 'vit_large_patch16_224',\n"," 'vit_large_patch16_224_in21k',\n"," 'vit_large_patch16_384',\n"," 'vit_large_patch32_224',\n"," 'vit_large_patch32_224_in21k',\n"," 'vit_large_patch32_384',\n"," 'vit_large_r50_s32_224',\n"," 'vit_large_r50_s32_224_in21k',\n"," 'vit_large_r50_s32_384',\n"," 'vit_relpos_base_patch16_224',\n"," 'vit_relpos_base_patch16_cls_224',\n"," 'vit_relpos_base_patch16_clsgap_224',\n"," 'vit_relpos_base_patch16_plus_240',\n"," 'vit_relpos_base_patch16_rpn_224',\n"," 'vit_relpos_base_patch32_plus_rpn_256',\n"," 'vit_relpos_medium_patch16_224',\n"," 'vit_relpos_medium_patch16_cls_224',\n"," 'vit_relpos_medium_patch16_rpn_224',\n"," 'vit_relpos_small_patch16_224',\n"," 'vit_relpos_small_patch16_rpn_224',\n"," 'vit_small_patch8_224_dino',\n"," 'vit_small_patch16_18x2_224',\n"," 'vit_small_patch16_36x1_224',\n"," 'vit_small_patch16_224',\n"," 'vit_small_patch16_224_dino',\n"," 'vit_small_patch16_224_in21k',\n"," 'vit_small_patch16_384',\n"," 'vit_small_patch32_224',\n"," 'vit_small_patch32_224_in21k',\n"," 'vit_small_patch32_384',\n"," 'vit_small_r26_s32_224',\n"," 'vit_small_r26_s32_224_in21k',\n"," 'vit_small_r26_s32_384',\n"," 'vit_small_resnet26d_224',\n"," 'vit_small_resnet50d_s16_224',\n"," 'vit_srelpos_medium_patch16_224',\n"," 'vit_srelpos_small_patch16_224',\n"," 'vit_tiny_patch16_224',\n"," 'vit_tiny_patch16_224_in21k',\n"," 'vit_tiny_patch16_384',\n"," 'vit_tiny_r_s16_p8_224',\n"," 'vit_tiny_r_s16_p8_224_in21k',\n"," 'vit_tiny_r_s16_p8_384']\n","test model output： tensor([[-0.0583,  0.3585]], grad_fn=<AddmmBackward0>)\n","model is ready now!\n","model loaded\n","model : ViT_384_401_PT_lf25_b8_ROSE_CLS\n","*********************************setting*************************************\n","Namespace(Pre_Trained_model_path=None, PromptTuning=None, PromptUnFreeze=False, Prompt_Token_num=20, att_module='SimAM', attn_drop_rate=0.0, batch_size=1, check_minibatch=None, cls_token_off=False, data_augmentation_mode=0, dataroot='/data/Pathology_Experiment/dataset/ROSE_CLS', draw_root='/home/Pathology_Experiment/runs', drop_path_rate=0.0, drop_rate=0.0, edge_size=384, enable_attention_check=True, enable_notify=False, enable_tensorboard=False, enable_visualize_check=False, gpu_idx=0, model_idx='ViT_384_401_PT_lf25_b8_ROSE_CLS', model_path='/home/Pathology_Experiment/saved_models', model_path_by_hand=None, num_classes=0, paint=True, pos_embedding_off=False)\n","Epoch: Test\n","----------\n","Epoch: test     test index of 50 minibatch: 1      time used: 2.468223810195923\n","minibatch AVG loss: 0.24001685688630459\n","/home/Pathology_Experiment/code/utils/visual_usage.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  return sof(x)\n","Epoch: test     test index of 50 minibatch: 2      time used: 2.284289836883545\n","minibatch AVG loss: 0.00754357352924444\n","Epoch: test     test index of 50 minibatch: 3      time used: 2.31471848487854\n","minibatch AVG loss: 0.049149821190643476\n","Epoch: test     test index of 50 minibatch: 4      time used: 2.336151361465454\n","minibatch AVG loss: 0.004975995243112266\n","Epoch: test     test index of 50 minibatch: 5      time used: 2.3641915321350098\n","minibatch AVG loss: 0.0060120013980434804\n","Epoch: test     test index of 50 minibatch: 6      time used: 2.4051353931427\n","minibatch AVG loss: 0.004354464833772767\n","Epoch: test     test index of 50 minibatch: 7      time used: 2.431436538696289\n","minibatch AVG loss: 0.029473278002417374\n","Epoch: test     test index of 50 minibatch: 8      time used: 2.449148654937744\n","minibatch AVG loss: 0.18922423431824428\n","Epoch: test     test index of 50 minibatch: 9      time used: 2.4631505012512207\n","minibatch AVG loss: 0.016931550716544733\n","Epoch: test     test index of 50 minibatch: 10      time used: 2.4575226306915283\n","minibatch AVG loss: 0.1625222492813191\n","Epoch: test     test index of 50 minibatch: 11      time used: 2.4278998374938965\n","minibatch AVG loss: 0.49774069255508946\n","Epoch: test     test index of 50 minibatch: 12      time used: 2.4070305824279785\n","minibatch AVG loss: 0.17561750888329697\n","Epoch: test     test index of 50 minibatch: 13      time used: 2.387000560760498\n","minibatch AVG loss: 0.15520027506305267\n","Epoch: test     test index of 50 minibatch: 14      time used: 2.3767476081848145\n","minibatch AVG loss: 0.25188526969321173\n","Epoch: test     test index of 50 minibatch: 15      time used: 2.350679874420166\n","minibatch AVG loss: 0.49906888783563774\n","Epoch: test     test index of 50 minibatch: 16      time used: 2.336548328399658\n","minibatch AVG loss: 0.5496438809353095\n","Epoch: test     test index of 50 minibatch: 17      time used: 2.3270339965820312\n","minibatch AVG loss: 0.9695505578769235\n","Epoch: test     test index of 50 minibatch: 18      time used: 2.323488235473633\n","minibatch AVG loss: 0.2448026189602888\n","Epoch: test     test index of 50 minibatch: 19      time used: 2.3136978149414062\n","minibatch AVG loss: 0.6215589119166998\n","Epoch: test     test index of 50 minibatch: 20      time used: 2.3037383556365967\n","minibatch AVG loss: 0.1924328134489042\n","\n","Epoch:  test \n","Loss: 0.2456  Acc: 91.2402\n","Negative precision: 91.1047  recall: 95.9215\n","Negative sensitivity: 95.9215  specificity: 82.4859\n","Negative FPR: 17.5141  NPV: 91.5361\n","Negative TP: 635.0\n","Negative TN: 292.0\n","Negative FP: 62.0\n","Negative FN: 27.0\n","Positive precision: 91.5361  recall: 82.4859\n","Positive sensitivity: 82.4859  specificity: 95.9215\n","Positive FPR: 4.0785  NPV: 91.1047\n","Positive TP: 292.0\n","Positive TN: 635.0\n","Positive FP: 27.0\n","Positive FN: 62.0\n","\n","\n","Testing complete in 1m 20s\n"]}],"source":["!python Test.py --model_idx ViT_384_401_PT_lf25_b8_ROSE_CLS --enable_attention_check --edge_size 384 --data_augmentation_mode 0 --dataroot /data/Pathology_Experiment/dataset/ROSE_CLS --model_path /home/Pathology_Experiment/saved_models --draw_root /home/Pathology_Experiment/runs"]},{"cell_type":"markdown","metadata":{"id":"9A2NqlIySHZo"},"source":["# CellMix"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"IU5yqDQyKfuU","outputId":"00e386fc-8122-45c7-d763-8f908774853e"},"outputs":[{"name":"stdout","output_type":"stream","text":["class_names: ['Negative', 'Positive']\n","*********************************setting*************************************\n","Namespace(Pre_Trained_model_path=None, PromptTuning=None, PromptUnFreeze=False, Prompt_Token_num=20, Prompt_state_path=None, att_module='SimAM', attn_drop_rate=0.0, augmentation_name='CellMix-Group', backbone_PT_off=False, batch_size=8, check_minibatch=None, cls_token_off=False, data_augmentation_mode=0, dataroot='/data/Pathology_Experiment/dataset/ROSE_CLS', draw_root='/home/Pathology_Experiment/runs', drop_path_rate=0.0, drop_rate=0.0, edge_size=384, enable_attention_check=False, enable_notify=False, enable_sam=False, enable_tensorboard=True, enable_visualize_check=False, fix_patch_size=None, fix_position_ratio=None, gpu_idx=-1, intake_epochs=0, linearprobing=False, loss_drive_threshold=4.0, lr=1e-05, lrf=0.25, model_idx='ViT_384_401_PT_lf25_b8_ROSE_CellMix_Group_CLS', model_path='/home/Pathology_Experiment/saved_models', num_classes=0, num_epochs=50, num_workers=2, opt_name='Adam', paint=True, patch_size_jump=None, patch_strategy='loss_hold', pos_embedding_off=False, ratio_strategy='loss_hold')\n","we dont have more GPU idx here, try to use gpu_idx=0\n","['convit_base',\n"," 'convit_small',\n"," 'convit_tiny',\n"," 'crossvit_9_240',\n"," 'crossvit_9_dagger_240',\n"," 'crossvit_15_240',\n"," 'crossvit_15_dagger_240',\n"," 'crossvit_15_dagger_408',\n"," 'crossvit_18_240',\n"," 'crossvit_18_dagger_240',\n"," 'crossvit_18_dagger_408',\n"," 'crossvit_base_240',\n"," 'crossvit_small_240',\n"," 'crossvit_tiny_240',\n"," 'gcvit_base',\n"," 'gcvit_small',\n"," 'gcvit_tiny',\n"," 'gcvit_xtiny',\n"," 'gcvit_xxtiny',\n"," 'levit_128',\n"," 'levit_128s',\n"," 'levit_192',\n"," 'levit_256',\n"," 'levit_256d',\n"," 'levit_384',\n"," 'maxvit_base_224',\n"," 'maxvit_large_224',\n"," 'maxvit_nano_rw_256',\n"," 'maxvit_pico_rw_256',\n"," 'maxvit_rmlp_nano_rw_256',\n"," 'maxvit_rmlp_pico_rw_256',\n"," 'maxvit_rmlp_small_rw_224',\n"," 'maxvit_rmlp_small_rw_256',\n"," 'maxvit_rmlp_tiny_rw_256',\n"," 'maxvit_small_224',\n"," 'maxvit_tiny_224',\n"," 'maxvit_tiny_pm_256',\n"," 'maxvit_tiny_rw_224',\n"," 'maxvit_tiny_rw_256',\n"," 'maxvit_xlarge_224',\n"," 'maxxvit_rmlp_nano_rw_256',\n"," 'maxxvit_rmlp_small_rw_256',\n"," 'maxxvit_rmlp_tiny_rw_256',\n"," 'mobilevit_s',\n"," 'mobilevit_xs',\n"," 'mobilevit_xxs',\n"," 'mobilevitv2_050',\n"," 'mobilevitv2_075',\n"," 'mobilevitv2_100',\n"," 'mobilevitv2_125',\n"," 'mobilevitv2_150',\n"," 'mobilevitv2_150_384_in22ft1k',\n"," 'mobilevitv2_150_in22ft1k',\n"," 'mobilevitv2_175',\n"," 'mobilevitv2_175_384_in22ft1k',\n"," 'mobilevitv2_175_in22ft1k',\n"," 'mobilevitv2_200',\n"," 'mobilevitv2_200_384_in22ft1k',\n"," 'mobilevitv2_200_in22ft1k',\n"," 'mvitv2_base',\n"," 'mvitv2_large',\n"," 'mvitv2_small',\n"," 'mvitv2_small_cls',\n"," 'mvitv2_tiny',\n"," 'semobilevit_s',\n"," 'vit_base_patch8_224',\n"," 'vit_base_patch8_224_dino',\n"," 'vit_base_patch8_224_in21k',\n"," 'vit_base_patch16_18x2_224',\n"," 'vit_base_patch16_224',\n"," 'vit_base_patch16_224_dino',\n"," 'vit_base_patch16_224_in21k',\n"," 'vit_base_patch16_224_miil',\n"," 'vit_base_patch16_224_miil_in21k',\n"," 'vit_base_patch16_224_sam',\n"," 'vit_base_patch16_384',\n"," 'vit_base_patch16_plus_240',\n"," 'vit_base_patch16_rpn_224',\n"," 'vit_base_patch32_224',\n"," 'vit_base_patch32_224_clip_laion2b',\n"," 'vit_base_patch32_224_in21k',\n"," 'vit_base_patch32_224_sam',\n"," 'vit_base_patch32_384',\n"," 'vit_base_patch32_plus_256',\n"," 'vit_base_r26_s32_224',\n"," 'vit_base_r50_s16_224',\n"," 'vit_base_r50_s16_224_in21k',\n"," 'vit_base_r50_s16_384',\n"," 'vit_base_resnet26d_224',\n"," 'vit_base_resnet50_224_in21k',\n"," 'vit_base_resnet50_384',\n"," 'vit_base_resnet50d_224',\n"," 'vit_giant_patch14_224',\n"," 'vit_giant_patch14_224_clip_laion2b',\n"," 'vit_gigantic_patch14_224',\n"," 'vit_huge_patch14_224',\n"," 'vit_huge_patch14_224_clip_laion2b',\n"," 'vit_huge_patch14_224_in21k',\n"," 'vit_large_patch14_224',\n"," 'vit_large_patch14_224_clip_laion2b',\n"," 'vit_large_patch16_224',\n"," 'vit_large_patch16_224_in21k',\n"," 'vit_large_patch16_384',\n"," 'vit_large_patch32_224',\n"," 'vit_large_patch32_224_in21k',\n"," 'vit_large_patch32_384',\n"," 'vit_large_r50_s32_224',\n"," 'vit_large_r50_s32_224_in21k',\n"," 'vit_large_r50_s32_384',\n"," 'vit_relpos_base_patch16_224',\n"," 'vit_relpos_base_patch16_cls_224',\n"," 'vit_relpos_base_patch16_clsgap_224',\n"," 'vit_relpos_base_patch16_plus_240',\n"," 'vit_relpos_base_patch16_rpn_224',\n"," 'vit_relpos_base_patch32_plus_rpn_256',\n"," 'vit_relpos_medium_patch16_224',\n"," 'vit_relpos_medium_patch16_cls_224',\n"," 'vit_relpos_medium_patch16_rpn_224',\n"," 'vit_relpos_small_patch16_224',\n"," 'vit_relpos_small_patch16_rpn_224',\n"," 'vit_small_patch8_224_dino',\n"," 'vit_small_patch16_18x2_224',\n"," 'vit_small_patch16_36x1_224',\n"," 'vit_small_patch16_224',\n"," 'vit_small_patch16_224_dino',\n"," 'vit_small_patch16_224_in21k',\n"," 'vit_small_patch16_384',\n"," 'vit_small_patch32_224',\n"," 'vit_small_patch32_224_in21k',\n"," 'vit_small_patch32_384',\n"," 'vit_small_r26_s32_224',\n"," 'vit_small_r26_s32_224_in21k',\n"," 'vit_small_r26_s32_384',\n"," 'vit_small_resnet26d_224',\n"," 'vit_small_resnet50d_s16_224',\n"," 'vit_srelpos_medium_patch16_224',\n"," 'vit_srelpos_small_patch16_224',\n"," 'vit_tiny_patch16_224',\n"," 'vit_tiny_patch16_224_in21k',\n"," 'vit_tiny_patch16_384',\n"," 'vit_tiny_r_s16_p8_224',\n"," 'vit_tiny_r_s16_p8_224_in21k',\n"," 'vit_tiny_r_s16_p8_384']\n","test model output： tensor([[ 0.9823, -1.2481]], grad_fn=<AddmmBackward0>)\n","model is ready now!\n","GPU: 0\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1          [-1, 768, 24, 24]         590,592\n","          Identity-2             [-1, 576, 768]               0\n","        PatchEmbed-3             [-1, 576, 768]               0\n","           Dropout-4             [-1, 577, 768]               0\n","          Identity-5             [-1, 577, 768]               0\n","         LayerNorm-6             [-1, 577, 768]           1,536\n","            Linear-7            [-1, 577, 2304]       1,771,776\n","           Dropout-8         [-1, 12, 577, 577]               0\n","            Linear-9             [-1, 577, 768]         590,592\n","          Dropout-10             [-1, 577, 768]               0\n","        Attention-11             [-1, 577, 768]               0\n","         Identity-12             [-1, 577, 768]               0\n","         Identity-13             [-1, 577, 768]               0\n","        LayerNorm-14             [-1, 577, 768]           1,536\n","           Linear-15            [-1, 577, 3072]       2,362,368\n","             GELU-16            [-1, 577, 3072]               0\n","          Dropout-17            [-1, 577, 3072]               0\n","           Linear-18             [-1, 577, 768]       2,360,064\n","          Dropout-19             [-1, 577, 768]               0\n","              Mlp-20             [-1, 577, 768]               0\n","         Identity-21             [-1, 577, 768]               0\n","         Identity-22             [-1, 577, 768]               0\n","            Block-23             [-1, 577, 768]               0\n","        LayerNorm-24             [-1, 577, 768]           1,536\n","           Linear-25            [-1, 577, 2304]       1,771,776\n","          Dropout-26         [-1, 12, 577, 577]               0\n","           Linear-27             [-1, 577, 768]         590,592\n","          Dropout-28             [-1, 577, 768]               0\n","        Attention-29             [-1, 577, 768]               0\n","         Identity-30             [-1, 577, 768]               0\n","         Identity-31             [-1, 577, 768]               0\n","        LayerNorm-32             [-1, 577, 768]           1,536\n","           Linear-33            [-1, 577, 3072]       2,362,368\n","             GELU-34            [-1, 577, 3072]               0\n","          Dropout-35            [-1, 577, 3072]               0\n","           Linear-36             [-1, 577, 768]       2,360,064\n","          Dropout-37             [-1, 577, 768]               0\n","              Mlp-38             [-1, 577, 768]               0\n","         Identity-39             [-1, 577, 768]               0\n","         Identity-40             [-1, 577, 768]               0\n","            Block-41             [-1, 577, 768]               0\n","        LayerNorm-42             [-1, 577, 768]           1,536\n","           Linear-43            [-1, 577, 2304]       1,771,776\n","          Dropout-44         [-1, 12, 577, 577]               0\n","           Linear-45             [-1, 577, 768]         590,592\n","          Dropout-46             [-1, 577, 768]               0\n","        Attention-47             [-1, 577, 768]               0\n","         Identity-48             [-1, 577, 768]               0\n","         Identity-49             [-1, 577, 768]               0\n","        LayerNorm-50             [-1, 577, 768]           1,536\n","           Linear-51            [-1, 577, 3072]       2,362,368\n","             GELU-52            [-1, 577, 3072]               0\n","          Dropout-53            [-1, 577, 3072]               0\n","           Linear-54             [-1, 577, 768]       2,360,064\n","          Dropout-55             [-1, 577, 768]               0\n","              Mlp-56             [-1, 577, 768]               0\n","         Identity-57             [-1, 577, 768]               0\n","         Identity-58             [-1, 577, 768]               0\n","            Block-59             [-1, 577, 768]               0\n","        LayerNorm-60             [-1, 577, 768]           1,536\n","           Linear-61            [-1, 577, 2304]       1,771,776\n","          Dropout-62         [-1, 12, 577, 577]               0\n","           Linear-63             [-1, 577, 768]         590,592\n","          Dropout-64             [-1, 577, 768]               0\n","        Attention-65             [-1, 577, 768]               0\n","         Identity-66             [-1, 577, 768]               0\n","         Identity-67             [-1, 577, 768]               0\n","        LayerNorm-68             [-1, 577, 768]           1,536\n","           Linear-69            [-1, 577, 3072]       2,362,368\n","             GELU-70            [-1, 577, 3072]               0\n","          Dropout-71            [-1, 577, 3072]               0\n","           Linear-72             [-1, 577, 768]       2,360,064\n","          Dropout-73             [-1, 577, 768]               0\n","              Mlp-74             [-1, 577, 768]               0\n","         Identity-75             [-1, 577, 768]               0\n","         Identity-76             [-1, 577, 768]               0\n","            Block-77             [-1, 577, 768]               0\n","        LayerNorm-78             [-1, 577, 768]           1,536\n","           Linear-79            [-1, 577, 2304]       1,771,776\n","          Dropout-80         [-1, 12, 577, 577]               0\n","           Linear-81             [-1, 577, 768]         590,592\n","          Dropout-82             [-1, 577, 768]               0\n","        Attention-83             [-1, 577, 768]               0\n","         Identity-84             [-1, 577, 768]               0\n","         Identity-85             [-1, 577, 768]               0\n","        LayerNorm-86             [-1, 577, 768]           1,536\n","           Linear-87            [-1, 577, 3072]       2,362,368\n","             GELU-88            [-1, 577, 3072]               0\n","          Dropout-89            [-1, 577, 3072]               0\n","           Linear-90             [-1, 577, 768]       2,360,064\n","          Dropout-91             [-1, 577, 768]               0\n","              Mlp-92             [-1, 577, 768]               0\n","         Identity-93             [-1, 577, 768]               0\n","         Identity-94             [-1, 577, 768]               0\n","            Block-95             [-1, 577, 768]               0\n","        LayerNorm-96             [-1, 577, 768]           1,536\n","           Linear-97            [-1, 577, 2304]       1,771,776\n","          Dropout-98         [-1, 12, 577, 577]               0\n","           Linear-99             [-1, 577, 768]         590,592\n","         Dropout-100             [-1, 577, 768]               0\n","       Attention-101             [-1, 577, 768]               0\n","        Identity-102             [-1, 577, 768]               0\n","        Identity-103             [-1, 577, 768]               0\n","       LayerNorm-104             [-1, 577, 768]           1,536\n","          Linear-105            [-1, 577, 3072]       2,362,368\n","            GELU-106            [-1, 577, 3072]               0\n","         Dropout-107            [-1, 577, 3072]               0\n","          Linear-108             [-1, 577, 768]       2,360,064\n","         Dropout-109             [-1, 577, 768]               0\n","             Mlp-110             [-1, 577, 768]               0\n","        Identity-111             [-1, 577, 768]               0\n","        Identity-112             [-1, 577, 768]               0\n","           Block-113             [-1, 577, 768]               0\n","       LayerNorm-114             [-1, 577, 768]           1,536\n","          Linear-115            [-1, 577, 2304]       1,771,776\n","         Dropout-116         [-1, 12, 577, 577]               0\n","          Linear-117             [-1, 577, 768]         590,592\n","         Dropout-118             [-1, 577, 768]               0\n","       Attention-119             [-1, 577, 768]               0\n","        Identity-120             [-1, 577, 768]               0\n","        Identity-121             [-1, 577, 768]               0\n","       LayerNorm-122             [-1, 577, 768]           1,536\n","          Linear-123            [-1, 577, 3072]       2,362,368\n","            GELU-124            [-1, 577, 3072]               0\n","         Dropout-125            [-1, 577, 3072]               0\n","          Linear-126             [-1, 577, 768]       2,360,064\n","         Dropout-127             [-1, 577, 768]               0\n","             Mlp-128             [-1, 577, 768]               0\n","        Identity-129             [-1, 577, 768]               0\n","        Identity-130             [-1, 577, 768]               0\n","           Block-131             [-1, 577, 768]               0\n","       LayerNorm-132             [-1, 577, 768]           1,536\n","          Linear-133            [-1, 577, 2304]       1,771,776\n","         Dropout-134         [-1, 12, 577, 577]               0\n","          Linear-135             [-1, 577, 768]         590,592\n","         Dropout-136             [-1, 577, 768]               0\n","       Attention-137             [-1, 577, 768]               0\n","        Identity-138             [-1, 577, 768]               0\n","        Identity-139             [-1, 577, 768]               0\n","       LayerNorm-140             [-1, 577, 768]           1,536\n","          Linear-141            [-1, 577, 3072]       2,362,368\n","            GELU-142            [-1, 577, 3072]               0\n","         Dropout-143            [-1, 577, 3072]               0\n","          Linear-144             [-1, 577, 768]       2,360,064\n","         Dropout-145             [-1, 577, 768]               0\n","             Mlp-146             [-1, 577, 768]               0\n","        Identity-147             [-1, 577, 768]               0\n","        Identity-148             [-1, 577, 768]               0\n","           Block-149             [-1, 577, 768]               0\n","       LayerNorm-150             [-1, 577, 768]           1,536\n","          Linear-151            [-1, 577, 2304]       1,771,776\n","         Dropout-152         [-1, 12, 577, 577]               0\n","          Linear-153             [-1, 577, 768]         590,592\n","         Dropout-154             [-1, 577, 768]               0\n","       Attention-155             [-1, 577, 768]               0\n","        Identity-156             [-1, 577, 768]               0\n","        Identity-157             [-1, 577, 768]               0\n","       LayerNorm-158             [-1, 577, 768]           1,536\n","          Linear-159            [-1, 577, 3072]       2,362,368\n","            GELU-160            [-1, 577, 3072]               0\n","         Dropout-161            [-1, 577, 3072]               0\n","          Linear-162             [-1, 577, 768]       2,360,064\n","         Dropout-163             [-1, 577, 768]               0\n","             Mlp-164             [-1, 577, 768]               0\n","        Identity-165             [-1, 577, 768]               0\n","        Identity-166             [-1, 577, 768]               0\n","           Block-167             [-1, 577, 768]               0\n","       LayerNorm-168             [-1, 577, 768]           1,536\n","          Linear-169            [-1, 577, 2304]       1,771,776\n","         Dropout-170         [-1, 12, 577, 577]               0\n","          Linear-171             [-1, 577, 768]         590,592\n","         Dropout-172             [-1, 577, 768]               0\n","       Attention-173             [-1, 577, 768]               0\n","        Identity-174             [-1, 577, 768]               0\n","        Identity-175             [-1, 577, 768]               0\n","       LayerNorm-176             [-1, 577, 768]           1,536\n","          Linear-177            [-1, 577, 3072]       2,362,368\n","            GELU-178            [-1, 577, 3072]               0\n","         Dropout-179            [-1, 577, 3072]               0\n","          Linear-180             [-1, 577, 768]       2,360,064\n","         Dropout-181             [-1, 577, 768]               0\n","             Mlp-182             [-1, 577, 768]               0\n","        Identity-183             [-1, 577, 768]               0\n","        Identity-184             [-1, 577, 768]               0\n","           Block-185             [-1, 577, 768]               0\n","       LayerNorm-186             [-1, 577, 768]           1,536\n","          Linear-187            [-1, 577, 2304]       1,771,776\n","         Dropout-188         [-1, 12, 577, 577]               0\n","          Linear-189             [-1, 577, 768]         590,592\n","         Dropout-190             [-1, 577, 768]               0\n","       Attention-191             [-1, 577, 768]               0\n","        Identity-192             [-1, 577, 768]               0\n","        Identity-193             [-1, 577, 768]               0\n","       LayerNorm-194             [-1, 577, 768]           1,536\n","          Linear-195            [-1, 577, 3072]       2,362,368\n","            GELU-196            [-1, 577, 3072]               0\n","         Dropout-197            [-1, 577, 3072]               0\n","          Linear-198             [-1, 577, 768]       2,360,064\n","         Dropout-199             [-1, 577, 768]               0\n","             Mlp-200             [-1, 577, 768]               0\n","        Identity-201             [-1, 577, 768]               0\n","        Identity-202             [-1, 577, 768]               0\n","           Block-203             [-1, 577, 768]               0\n","       LayerNorm-204             [-1, 577, 768]           1,536\n","          Linear-205            [-1, 577, 2304]       1,771,776\n","         Dropout-206         [-1, 12, 577, 577]               0\n","          Linear-207             [-1, 577, 768]         590,592\n","         Dropout-208             [-1, 577, 768]               0\n","       Attention-209             [-1, 577, 768]               0\n","        Identity-210             [-1, 577, 768]               0\n","        Identity-211             [-1, 577, 768]               0\n","       LayerNorm-212             [-1, 577, 768]           1,536\n","          Linear-213            [-1, 577, 3072]       2,362,368\n","            GELU-214            [-1, 577, 3072]               0\n","         Dropout-215            [-1, 577, 3072]               0\n","          Linear-216             [-1, 577, 768]       2,360,064\n","         Dropout-217             [-1, 577, 768]               0\n","             Mlp-218             [-1, 577, 768]               0\n","        Identity-219             [-1, 577, 768]               0\n","        Identity-220             [-1, 577, 768]               0\n","           Block-221             [-1, 577, 768]               0\n","       LayerNorm-222             [-1, 577, 768]           1,536\n","        Identity-223                  [-1, 768]               0\n","          Linear-224                    [-1, 2]           1,538\n","================================================================\n","Total params: 85,648,130\n","Trainable params: 85,648,130\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 1.69\n","Forward/backward pass size (MB): 1522.01\n","Params size (MB): 326.72\n","Estimated Total Size (MB): 1850.42\n","----------------------------------------------------------------\n","model : ViT_384_401_PT_lf25_b8_ROSE_CellMix_Group_CLS\n","patch_list: [192, 128, 96, 64, 48, 32, 16]\n","/usr/local/lib/python3.8/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n","  warnings.warn(warning.format(ret))\n","Epoch 1/50\n","----------\n","Epoch: 1     train index of 50 minibatch: 1      time used: 52.144076108932495\n","minibatch AVG loss: 6.244857186079026\n","Epoch: 1     train index of 50 minibatch: 2      time used: 50.12121224403381\n","minibatch AVG loss: 4.424350032806396\n","Epoch: 1     train index of 50 minibatch: 3      time used: 50.78485131263733\n","minibatch AVG loss: 4.021787112951278\n","Epoch: 1     train index of 50 minibatch: 4      time used: 50.381897926330566\n","minibatch AVG loss: 3.4029972553253174\n","Epoch: 1     train index of 50 minibatch: 5      time used: 50.57955622673035\n","minibatch AVG loss: 3.016547278165817\n","Epoch: 1     train index of 50 minibatch: 6      time used: 50.76205086708069\n","minibatch AVG loss: 3.363047849535942\n","Epoch: 1     train index of 50 minibatch: 7      time used: 50.57372784614563\n","minibatch AVG loss: 3.2239283716678617\n","Epoch: 1     train index of 50 minibatch: 8      time used: 50.39132285118103\n","minibatch AVG loss: 3.250186417102814\n","\n","Epoch: 1  train \n","Loss: 3.7904  Acc: 80.6904\n","\n","Epoch: 1, Fix_position_ratio: 0.9, Puzzle_patch_size: 192\n","Negative precision: 83.2384  recall: 88.2277\n","Negative sensitivity: 88.2277  specificity: 66.8010\n","Negative FPR: 33.1990  NPV: 75.2269\n","Negative TP: 2046.0\n","Negative TN: 829.0\n","Negative FP: 412.0\n","Negative FN: 273.0\n","Positive precision: 75.2269  recall: 66.8010\n","Positive sensitivity: 66.8010  specificity: 88.2277\n","Positive FPR: 11.7723  NPV: 83.2384\n","Positive TP: 829.0\n","Positive TN: 2046.0\n","Positive FP: 273.0\n","Positive FN: 412.0\n","\n","\n","Epoch: 1     val index of 50 minibatch: 1      time used: 19.25331974029541\n","minibatch AVG loss: 1.3981219631433488\n","\n","Epoch: 1  val \n","Loss: 2.2451  Acc: 87.0334\n","Negative precision: 87.1233  recall: 95.7831\n","Negative sensitivity: 95.7831  specificity: 72.6744\n","Negative FPR: 27.3256  NPV: 89.9281\n","Negative TP: 318.0\n","Negative TN: 125.0\n","Negative FP: 47.0\n","Negative FN: 14.0\n","Positive precision: 89.9281  recall: 72.6744\n","Positive sensitivity: 72.6744  specificity: 95.7831\n","Positive FPR: 4.2169  NPV: 87.1233\n","Positive TP: 125.0\n","Positive TN: 318.0\n","Positive FP: 14.0\n","Positive FN: 47.0\n","\n","\n","\n","Epoch 2/50\n","----------\n","Epoch: 2     train index of 50 minibatch: 1      time used: 51.23593521118164\n","minibatch AVG loss: 2.9169558289647104\n","Epoch: 2     train index of 50 minibatch: 2      time used: 50.560364723205566\n","minibatch AVG loss: 4.0926291108131405\n","Epoch: 2     train index of 50 minibatch: 3      time used: 50.86092972755432\n","minibatch AVG loss: 2.402816849350929\n","Epoch: 2     train index of 50 minibatch: 4      time used: 50.58573842048645\n","minibatch AVG loss: 3.181004967689514\n","Epoch: 2     train index of 50 minibatch: 5      time used: 50.61354660987854\n","minibatch AVG loss: 2.699422048330307\n","Epoch: 2     train index of 50 minibatch: 6      time used: 50.92785906791687\n","minibatch AVG loss: 2.5724623170495033\n","Epoch: 2     train index of 50 minibatch: 7      time used: 50.54160165786743\n","minibatch AVG loss: 2.629660931825638\n","Epoch: 2     train index of 50 minibatch: 8      time used: 50.47670650482178\n","minibatch AVG loss: 2.548651309013367\n","\n","Epoch: 2  train \n","Loss: 2.8675  Acc: 86.6124\n","\n","Epoch: 2, Fix_position_ratio: 0.882, Puzzle_patch_size: 192\n","Negative precision: 88.0726  recall: 92.0224\n","Negative sensitivity: 92.0224  specificity: 76.7123\n","Negative FPR: 23.2877  NPV: 83.7291\n","Negative TP: 2134.0\n","Negative TN: 952.0\n","Negative FP: 289.0\n","Negative FN: 185.0\n","Positive precision: 83.7291  recall: 76.7123\n","Positive sensitivity: 76.7123  specificity: 92.0224\n","Positive FPR: 7.9776  NPV: 88.0726\n","Positive TP: 952.0\n","Positive TN: 2134.0\n","Positive FP: 185.0\n","Positive FN: 289.0\n","\n","\n","Epoch: 2     val index of 50 minibatch: 1      time used: 19.505401134490967\n","minibatch AVG loss: 1.5620289999246597\n","\n","Epoch: 2  val \n","Loss: 1.7351  Acc: 90.1768\n","Negative precision: 94.1538  recall: 92.1687\n","Negative sensitivity: 92.1687  specificity: 88.9535\n","Negative FPR: 11.0465  NPV: 85.4749\n","Negative TP: 306.0\n","Negative TN: 153.0\n","Negative FP: 19.0\n","Negative FN: 26.0\n","Positive precision: 85.4749  recall: 88.9535\n","Positive sensitivity: 88.9535  specificity: 92.1687\n","Positive FPR: 7.8313  NPV: 94.1538\n","Positive TP: 153.0\n","Positive TN: 306.0\n","Positive FP: 26.0\n","Positive FN: 19.0\n","\n","\n","\n","Epoch 3/50\n","----------\n","Epoch: 3     train index of 50 minibatch: 1      time used: 51.275768518447876\n","minibatch AVG loss: 2.5222071808576585\n","Epoch: 3     train index of 50 minibatch: 2      time used: 50.61777687072754\n","minibatch AVG loss: 2.74875796854496\n","Epoch: 3     train index of 50 minibatch: 3      time used: 50.66124725341797\n","minibatch AVG loss: 2.4103963589668274\n","Epoch: 3     train index of 50 minibatch: 4      time used: 50.547348976135254\n","minibatch AVG loss: 2.7154978305101394\n","Epoch: 3     train index of 50 minibatch: 5      time used: 50.63433122634888\n","minibatch AVG loss: 2.726015253663063\n","Epoch: 3     train index of 50 minibatch: 6      time used: 50.766602993011475\n","minibatch AVG loss: 2.4587143355607988\n","Epoch: 3     train index of 50 minibatch: 7      time used: 50.658971309661865\n","minibatch AVG loss: 2.5848166412115097\n","Epoch: 3     train index of 50 minibatch: 8      time used: 50.56180477142334\n","minibatch AVG loss: 2.773307399749756\n","\n","Epoch: 3  train \n","Loss: 2.6058  Acc: 88.4928\n","\n","Epoch: 3, Fix_position_ratio: 0.864, Puzzle_patch_size: 192\n","Negative precision: 90.0377  recall: 92.7155\n","Negative sensitivity: 92.7155  specificity: 80.8065\n","Negative FPR: 19.1935  NPV: 85.5679\n","Negative TP: 2151.0\n","Negative TN: 1002.0\n","Negative FP: 238.0\n","Negative FN: 169.0\n","Positive precision: 85.5679  recall: 80.8065\n","Positive sensitivity: 80.8065  specificity: 92.7155\n","Positive FPR: 7.2845  NPV: 90.0377\n","Positive TP: 1002.0\n","Positive TN: 2151.0\n","Positive FP: 169.0\n","Positive FN: 238.0\n","\n","\n","Epoch: 3     val index of 50 minibatch: 1      time used: 19.280510663986206\n","minibatch AVG loss: 1.5575323596596717\n","\n","Epoch: 3  val \n","Loss: 1.6114  Acc: 90.5697\n","Negative precision: 95.8730  recall: 90.9639\n","Negative sensitivity: 90.9639  specificity: 92.4419\n","Negative FPR: 7.5581  NPV: 84.1270\n","Negative TP: 302.0\n","Negative TN: 159.0\n","Negative FP: 13.0\n","Negative FN: 30.0\n","Positive precision: 84.1270  recall: 92.4419\n","Positive sensitivity: 92.4419  specificity: 90.9639\n","Positive FPR: 9.0361  NPV: 95.8730\n","Positive TP: 159.0\n","Positive TN: 302.0\n","Positive FP: 30.0\n","Positive FN: 13.0\n","\n","\n","\n","Epoch 4/50\n","----------\n","Epoch: 4     train index of 50 minibatch: 1      time used: 51.11714005470276\n","minibatch AVG loss: 2.0603844010829926\n","Epoch: 4     train index of 50 minibatch: 2      time used: 50.6129789352417\n","minibatch AVG loss: 2.11477026283741\n","Epoch: 4     train index of 50 minibatch: 3      time used: 50.648784160614014\n","minibatch AVG loss: 2.638648716211319\n","Epoch: 4     train index of 50 minibatch: 4      time used: 50.64516091346741\n","minibatch AVG loss: 2.3524537269771097\n","Epoch: 4     train index of 50 minibatch: 5      time used: 50.70798134803772\n","minibatch AVG loss: 2.3052511391043664\n","Epoch: 4     train index of 50 minibatch: 6      time used: 50.69726276397705\n","minibatch AVG loss: 2.119816267490387\n","Epoch: 4     train index of 50 minibatch: 7      time used: 50.696592569351196\n","minibatch AVG loss: 2.437173131406307\n","Epoch: 4     train index of 50 minibatch: 8      time used: 50.73328137397766\n","minibatch AVG loss: 2.60536782592535\n","\n","Epoch: 4  train \n","Loss: 2.3143  Acc: 90.7101\n","\n","Epoch: 4, Fix_position_ratio: 0.846, Puzzle_patch_size: 192\n","Negative precision: 91.6702  recall: 94.4373\n","Negative sensitivity: 94.4373  specificity: 83.9645\n","Negative FPR: 16.0355  NPV: 88.9838\n","Negative TP: 2190.0\n","Negative TN: 1042.0\n","Negative FP: 199.0\n","Negative FN: 129.0\n","Positive precision: 88.9838  recall: 83.9645\n","Positive sensitivity: 83.9645  specificity: 94.4373\n","Positive FPR: 5.5627  NPV: 91.6702\n","Positive TP: 1042.0\n","Positive TN: 2190.0\n","Positive FP: 129.0\n","Positive FN: 199.0\n","\n","\n","Epoch: 4     val index of 50 minibatch: 1      time used: 19.367151021957397\n","minibatch AVG loss: 0.9253703425545245\n","\n","Epoch: 4  val \n","Loss: 2.1634  Acc: 87.4263\n","Negative precision: 85.2713  recall: 99.3976\n","Negative sensitivity: 99.3976  specificity: 66.8605\n","Negative FPR: 33.1395  NPV: 98.2906\n","Negative TP: 330.0\n","Negative TN: 115.0\n","Negative FP: 57.0\n","Negative FN: 2.0\n","Positive precision: 98.2906  recall: 66.8605\n","Positive sensitivity: 66.8605  specificity: 99.3976\n","Positive FPR: 0.6024  NPV: 85.2713\n","Positive TP: 115.0\n","Positive TN: 330.0\n","Positive FP: 2.0\n","Positive FN: 57.0\n","\n","\n","\n","Epoch 5/50\n","----------\n","Epoch: 5     train index of 50 minibatch: 1      time used: 51.16628170013428\n","minibatch AVG loss: 2.5440244472026823\n","Epoch: 5     train index of 50 minibatch: 2      time used: 50.6606764793396\n","minibatch AVG loss: 2.249472521543503\n","Epoch: 5     train index of 50 minibatch: 3      time used: 50.74670195579529\n","minibatch AVG loss: 2.4452078266441823\n","Epoch: 5     train index of 50 minibatch: 4      time used: 50.72263789176941\n","minibatch AVG loss: 2.566984978020191\n","Epoch: 5     train index of 50 minibatch: 5      time used: 50.68351721763611\n","minibatch AVG loss: 2.348212940096855\n","Epoch: 5     train index of 50 minibatch: 6      time used: 50.69570875167847\n","minibatch AVG loss: 2.4499922037124633\n","Epoch: 5     train index of 50 minibatch: 7      time used: 50.67299151420593\n","minibatch AVG loss: 1.7614585141092538\n","Epoch: 5     train index of 50 minibatch: 8      time used: 50.72258973121643\n","minibatch AVG loss: 3.009078814983368\n","\n","Epoch: 5  train \n","Loss: 2.4285  Acc: 90.3171\n","\n","Epoch: 5, Fix_position_ratio: 0.8280000000000001, Puzzle_patch_size: 192\n","Negative precision: 91.3080  recall: 94.2216\n","Negative sensitivity: 94.2216  specificity: 83.2393\n","Negative FPR: 16.7607  NPV: 88.5176\n","Negative TP: 2185.0\n","Negative TN: 1033.0\n","Negative FP: 208.0\n","Negative FN: 134.0\n","Positive precision: 88.5176  recall: 83.2393\n","Positive sensitivity: 83.2393  specificity: 94.2216\n","Positive FPR: 5.7784  NPV: 91.3080\n","Positive TP: 1033.0\n","Positive TN: 2185.0\n","Positive FP: 134.0\n","Positive FN: 208.0\n","\n","\n","Epoch: 5     val index of 50 minibatch: 1      time used: 19.34632897377014\n","minibatch AVG loss: 1.0572158450633287\n","\n","Epoch: 5  val \n","Loss: 1.6251  Acc: 91.1591\n","Negative precision: 91.9540  recall: 96.3855\n","Negative sensitivity: 96.3855  specificity: 83.7209\n","Negative FPR: 16.2791  NPV: 92.3077\n","Negative TP: 320.0\n","Negative TN: 144.0\n","Negative FP: 28.0\n","Negative FN: 12.0\n","Positive precision: 92.3077  recall: 83.7209\n","Positive sensitivity: 83.7209  specificity: 96.3855\n","Positive FPR: 3.6145  NPV: 91.9540\n","Positive TP: 144.0\n","Positive TN: 320.0\n","Positive FP: 12.0\n","Positive FN: 28.0\n","\n","\n","\n","Epoch 6/50\n","----------\n","Epoch: 6     train index of 50 minibatch: 1      time used: 51.2524950504303\n","minibatch AVG loss: 1.9836343321204186\n","Epoch: 6     train index of 50 minibatch: 2      time used: 50.8144850730896\n","minibatch AVG loss: 2.2988239108026027\n","Epoch: 6     train index of 50 minibatch: 3      time used: 50.69235563278198\n","minibatch AVG loss: 2.342522937953472\n","Epoch: 6     train index of 50 minibatch: 4      time used: 50.64748978614807\n","minibatch AVG loss: 2.3674034160375594\n","Epoch: 6     train index of 50 minibatch: 5      time used: 50.5998432636261\n","minibatch AVG loss: 2.109394862502813\n","Epoch: 6     train index of 50 minibatch: 6      time used: 50.66265821456909\n","minibatch AVG loss: 1.9429892295598983\n","Epoch: 6     train index of 50 minibatch: 7      time used: 50.971696615219116\n","minibatch AVG loss: 2.2938036525249483\n","Epoch: 6     train index of 50 minibatch: 8      time used: 50.750463247299194\n","minibatch AVG loss: 2.3201916933059694\n","\n","Epoch: 6  train \n","Loss: 2.2817  Acc: 91.5521\n","\n","Epoch: 6, Fix_position_ratio: 0.81, Puzzle_patch_size: 192\n","Negative precision: 92.7634  recall: 94.5235\n","Negative sensitivity: 94.5235  specificity: 86.2208\n","Negative FPR: 13.7792  NPV: 89.3901\n","Negative TP: 2192.0\n","Negative TN: 1070.0\n","Negative FP: 171.0\n","Negative FN: 127.0\n","Positive precision: 89.3901  recall: 86.2208\n","Positive sensitivity: 86.2208  specificity: 94.5235\n","Positive FPR: 5.4765  NPV: 92.7634\n","Positive TP: 1070.0\n","Positive TN: 2192.0\n","Positive FP: 127.0\n","Positive FN: 171.0\n","\n","\n","Epoch: 6     val index of 50 minibatch: 1      time used: 19.285614490509033\n","minibatch AVG loss: 1.317899166494608\n","\n","Epoch: 6  val \n","Loss: 1.7155  Acc: 89.1945\n","Negative precision: 93.2515  recall: 91.5663\n","Negative sensitivity: 91.5663  specificity: 87.2093\n","Negative FPR: 12.7907  NPV: 84.2697\n","Negative TP: 304.0\n","Negative TN: 150.0\n","Negative FP: 22.0\n","Negative FN: 28.0\n","Positive precision: 84.2697  recall: 87.2093\n","Positive sensitivity: 87.2093  specificity: 91.5663\n","Positive FPR: 8.4337  NPV: 93.2515\n","Positive TP: 150.0\n","Positive TN: 304.0\n","Positive FP: 28.0\n","Positive FN: 22.0\n","\n","\n","\n","Epoch 7/50\n","----------\n","Epoch: 7     train index of 50 minibatch: 1      time used: 51.105172634124756\n","minibatch AVG loss: 1.5884977354109286\n","Epoch: 7     train index of 50 minibatch: 2      time used: 50.70144319534302\n","minibatch AVG loss: 2.461358535885811\n","Epoch: 7     train index of 50 minibatch: 3      time used: 50.722612380981445\n","minibatch AVG loss: 1.823123776987195\n","Epoch: 7     train index of 50 minibatch: 4      time used: 50.821269273757935\n","minibatch AVG loss: 1.7093077889084816\n","Epoch: 7     train index of 50 minibatch: 5      time used: 50.78693413734436\n","minibatch AVG loss: 1.9807388691604138\n","Epoch: 7     train index of 50 minibatch: 6      time used: 50.64959406852722\n","minibatch AVG loss: 1.964626813828945\n","Epoch: 7     train index of 50 minibatch: 7      time used: 50.657875061035156\n","minibatch AVG loss: 2.115197067409754\n","Epoch: 7     train index of 50 minibatch: 8      time used: 50.88316345214844\n","minibatch AVG loss: 2.4094146409630777\n","\n","Epoch: 7  train \n","Loss: 2.0029  Acc: 93.0396\n","\n","Epoch: 7, Fix_position_ratio: 0.792, Puzzle_patch_size: 192\n","Negative precision: 93.9035  recall: 95.6447\n","Negative sensitivity: 95.6447  specificity: 88.3965\n","Negative FPR: 11.6035  NPV: 91.5693\n","Negative TP: 2218.0\n","Negative TN: 1097.0\n","Negative FP: 144.0\n","Negative FN: 101.0\n","Positive precision: 91.5693  recall: 88.3965\n","Positive sensitivity: 88.3965  specificity: 95.6447\n","Positive FPR: 4.3553  NPV: 93.9035\n","Positive TP: 1097.0\n","Positive TN: 2218.0\n","Positive FP: 101.0\n","Positive FN: 144.0\n","\n","\n","Epoch: 7     val index of 50 minibatch: 1      time used: 19.350056409835815\n","minibatch AVG loss: 1.0595028296858073\n","\n","Epoch: 7  val \n","Loss: 1.4721  Acc: 91.5521\n","Negative precision: 93.4911  recall: 95.1807\n","Negative sensitivity: 95.1807  specificity: 87.2093\n","Negative FPR: 12.7907  NPV: 90.3614\n","Negative TP: 316.0\n","Negative TN: 150.0\n","Negative FP: 22.0\n","Negative FN: 16.0\n","Positive precision: 90.3614  recall: 87.2093\n","Positive sensitivity: 87.2093  specificity: 95.1807\n","Positive FPR: 4.8193  NPV: 93.4911\n","Positive TP: 150.0\n","Positive TN: 316.0\n","Positive FP: 16.0\n","Positive FN: 22.0\n","\n","\n","\n","Epoch 8/50\n","----------\n","Epoch: 8     train index of 50 minibatch: 1      time used: 51.174394369125366\n","minibatch AVG loss: 1.9375930857658386\n","Epoch: 8     train index of 50 minibatch: 2      time used: 50.80481934547424\n","minibatch AVG loss: 2.2478099834918974\n","Epoch: 8     train index of 50 minibatch: 3      time used: 50.55518889427185\n","minibatch AVG loss: 2.2828024600446226\n","Epoch: 8     train index of 50 minibatch: 4      time used: 50.917271852493286\n","minibatch AVG loss: 2.4323987478017806\n","Epoch: 8     train index of 50 minibatch: 5      time used: 50.637418270111084\n","minibatch AVG loss: 2.350562985241413\n","Epoch: 8     train index of 50 minibatch: 6      time used: 50.60643815994263\n","minibatch AVG loss: 1.9359164233505726\n","Epoch: 8     train index of 50 minibatch: 7      time used: 50.636723279953\n","minibatch AVG loss: 2.2602609056979417\n","Epoch: 8     train index of 50 minibatch: 8      time used: 50.74497175216675\n","minibatch AVG loss: 1.8207715215533973\n","\n","Epoch: 8  train \n","Loss: 2.1251  Acc: 92.3660\n","\n","Epoch: 8, Fix_position_ratio: 0.774, Puzzle_patch_size: 192\n","Negative precision: 93.1063  recall: 95.4741\n","Negative sensitivity: 95.4741  specificity: 86.7742\n","Negative FPR: 13.2258  NPV: 91.1092\n","Negative TP: 2215.0\n","Negative TN: 1076.0\n","Negative FP: 164.0\n","Negative FN: 105.0\n","Positive precision: 91.1092  recall: 86.7742\n","Positive sensitivity: 86.7742  specificity: 95.4741\n","Positive FPR: 4.5259  NPV: 93.1063\n","Positive TP: 1076.0\n","Positive TN: 2215.0\n","Positive FP: 105.0\n","Positive FN: 164.0\n","\n","\n","Epoch: 8     val index of 50 minibatch: 1      time used: 19.416253566741943\n","minibatch AVG loss: 1.5822423158958554\n","\n","Epoch: 8  val \n","Loss: 1.6270  Acc: 91.3556\n","Negative precision: 96.8051  recall: 91.2651\n","Negative sensitivity: 91.2651  specificity: 94.1860\n","Negative FPR: 5.8140  NPV: 84.8168\n","Negative TP: 303.0\n","Negative TN: 162.0\n","Negative FP: 10.0\n","Negative FN: 29.0\n","Positive precision: 84.8168  recall: 94.1860\n","Positive sensitivity: 94.1860  specificity: 91.2651\n","Positive FPR: 8.7349  NPV: 96.8051\n","Positive TP: 162.0\n","Positive TN: 303.0\n","Positive FP: 29.0\n","Positive FN: 10.0\n","\n","\n","\n","Epoch 9/50\n","----------\n","Epoch: 9     train index of 50 minibatch: 1      time used: 51.32765507698059\n","minibatch AVG loss: 1.9914279933273793\n","Epoch: 9     train index of 50 minibatch: 2      time used: 50.870776891708374\n","minibatch AVG loss: 2.314102328568697\n","Epoch: 9     train index of 50 minibatch: 3      time used: 50.71692204475403\n","minibatch AVG loss: 2.1729129907488822\n","Epoch: 9     train index of 50 minibatch: 4      time used: 50.56038427352905\n","minibatch AVG loss: 2.6286555495858193\n","Epoch: 9     train index of 50 minibatch: 5      time used: 50.775880575180054\n","minibatch AVG loss: 2.10106000892818\n","Epoch: 9     train index of 50 minibatch: 6      time used: 50.933308601379395\n","minibatch AVG loss: 2.373504830300808\n","Epoch: 9     train index of 50 minibatch: 7      time used: 50.95260739326477\n","minibatch AVG loss: 2.695462882220745\n","Epoch: 9     train index of 50 minibatch: 8      time used: 50.61742043495178\n","minibatch AVG loss: 2.1679823091626167\n","\n","Epoch: 9  train \n","Loss: 2.2952  Acc: 89.8962\n","\n","Epoch: 9, Fix_position_ratio: 0.756, Puzzle_patch_size: 128\n","Negative precision: 91.8838  recall: 92.7955\n","Negative sensitivity: 92.7955  specificity: 84.7021\n","Negative FPR: 15.2979  NPV: 86.3002\n","Negative TP: 2151.0\n","Negative TN: 1052.0\n","Negative FP: 190.0\n","Negative FN: 167.0\n","Positive precision: 86.3002  recall: 84.7021\n","Positive sensitivity: 84.7021  specificity: 92.7955\n","Positive FPR: 7.2045  NPV: 91.8838\n","Positive TP: 1052.0\n","Positive TN: 2151.0\n","Positive FP: 167.0\n","Positive FN: 190.0\n","\n","\n","Epoch: 9     val index of 50 minibatch: 1      time used: 19.435128450393677\n","minibatch AVG loss: 0.8347487089410425\n","\n","Epoch: 9  val \n","Loss: 1.8520  Acc: 89.5874\n","Negative precision: 88.3784  recall: 98.4940\n","Negative sensitivity: 98.4940  specificity: 75.0000\n","Negative FPR: 25.0000  NPV: 96.2687\n","Negative TP: 327.0\n","Negative TN: 129.0\n","Negative FP: 43.0\n","Negative FN: 5.0\n","Positive precision: 96.2687  recall: 75.0000\n","Positive sensitivity: 75.0000  specificity: 98.4940\n","Positive FPR: 1.5060  NPV: 88.3784\n","Positive TP: 129.0\n","Positive TN: 327.0\n","Positive FP: 5.0\n","Positive FN: 43.0\n","\n","\n","\n","Epoch 10/50\n","----------\n","Epoch: 10     train index of 50 minibatch: 1      time used: 51.37746000289917\n","minibatch AVG loss: 1.7399319629371166\n","Epoch: 10     train index of 50 minibatch: 2      time used: 50.554073333740234\n","minibatch AVG loss: 2.1696204601228235\n","Epoch: 10     train index of 50 minibatch: 3      time used: 50.567283153533936\n","minibatch AVG loss: 1.9892464510072023\n","Epoch: 10     train index of 50 minibatch: 4      time used: 50.97784924507141\n","minibatch AVG loss: 2.241885243803263\n","Epoch: 10     train index of 50 minibatch: 5      time used: 50.79499864578247\n","minibatch AVG loss: 1.9820029333978892\n","Epoch: 10     train index of 50 minibatch: 6      time used: 50.67177772521973\n","minibatch AVG loss: 2.1897716615349054\n","Epoch: 10     train index of 50 minibatch: 7      time used: 50.56614542007446\n","minibatch AVG loss: 2.6123379142582417\n","Epoch: 10     train index of 50 minibatch: 8      time used: 50.82066345214844\n","minibatch AVG loss: 2.0805357579514383\n","\n","Epoch: 10  train \n","Loss: 2.1061  Acc: 90.9065\n","\n","Epoch: 10, Fix_position_ratio: 0.738, Puzzle_patch_size: 128\n","Negative precision: 92.0101  recall: 94.3510\n","Negative sensitivity: 94.3510  specificity: 84.6898\n","Negative FPR: 15.3102  NPV: 88.9171\n","Negative TP: 2188.0\n","Negative TN: 1051.0\n","Negative FP: 190.0\n","Negative FN: 131.0\n","Positive precision: 88.9171  recall: 84.6898\n","Positive sensitivity: 84.6898  specificity: 94.3510\n","Positive FPR: 5.6490  NPV: 92.0101\n","Positive TP: 1051.0\n","Positive TN: 2188.0\n","Positive FP: 131.0\n","Positive FN: 190.0\n","\n","\n","Epoch: 10     val index of 50 minibatch: 1      time used: 19.375317335128784\n","minibatch AVG loss: 1.2404018203914164\n","\n","Epoch: 10  val \n","Loss: 1.6103  Acc: 90.5697\n","Negative precision: 93.9210  recall: 93.0723\n","Negative sensitivity: 93.0723  specificity: 88.3721\n","Negative FPR: 11.6279  NPV: 86.8571\n","Negative TP: 309.0\n","Negative TN: 152.0\n","Negative FP: 20.0\n","Negative FN: 23.0\n","Positive precision: 86.8571  recall: 88.3721\n","Positive sensitivity: 88.3721  specificity: 93.0723\n","Positive FPR: 6.9277  NPV: 93.9210\n","Positive TP: 152.0\n","Positive TN: 309.0\n","Positive FP: 23.0\n","Positive FN: 20.0\n","\n","\n","\n","Epoch 11/50\n","----------\n","Epoch: 11     train index of 50 minibatch: 1      time used: 51.215102434158325\n","minibatch AVG loss: 2.283020298779011\n","Epoch: 11     train index of 50 minibatch: 2      time used: 50.78921341896057\n","minibatch AVG loss: 2.051541615575552\n","Epoch: 11     train index of 50 minibatch: 3      time used: 50.86723709106445\n","minibatch AVG loss: 2.0739150255173446\n","Epoch: 11     train index of 50 minibatch: 4      time used: 50.88027215003967\n","minibatch AVG loss: 1.4597214929386972\n","Epoch: 11     train index of 50 minibatch: 5      time used: 50.87059688568115\n","minibatch AVG loss: 2.062409400343895\n","Epoch: 11     train index of 50 minibatch: 6      time used: 50.74866724014282\n","minibatch AVG loss: 2.107001548372209\n","Epoch: 11     train index of 50 minibatch: 7      time used: 50.63613772392273\n","minibatch AVG loss: 2.198812111094594\n","Epoch: 11     train index of 50 minibatch: 8      time used: 50.733537912368774\n","minibatch AVG loss: 2.168855948485434\n","\n","Epoch: 11  train \n","Loss: 2.0994  Acc: 91.7766\n","\n","Epoch: 11, Fix_position_ratio: 0.7200000000000001, Puzzle_patch_size: 128\n","Negative precision: 92.8934  recall: 94.7368\n","Negative sensitivity: 94.7368  specificity: 86.4734\n","Negative FPR: 13.5266  NPV: 89.7993\n","Negative TP: 2196.0\n","Negative TN: 1074.0\n","Negative FP: 168.0\n","Negative FN: 122.0\n","Positive precision: 89.7993  recall: 86.4734\n","Positive sensitivity: 86.4734  specificity: 94.7368\n","Positive FPR: 5.2632  NPV: 92.8934\n","Positive TP: 1074.0\n","Positive TN: 2196.0\n","Positive FP: 122.0\n","Positive FN: 168.0\n","\n","\n","Epoch: 11     val index of 50 minibatch: 1      time used: 19.398401260375977\n","minibatch AVG loss: 1.5442630588263273\n","\n","Epoch: 11  val \n","Loss: 1.8309  Acc: 89.5874\n","Negative precision: 95.2229  recall: 90.0602\n","Negative sensitivity: 90.0602  specificity: 91.2791\n","Negative FPR: 8.7209  NPV: 82.6316\n","Negative TP: 299.0\n","Negative TN: 157.0\n","Negative FP: 15.0\n","Negative FN: 33.0\n","Positive precision: 82.6316  recall: 91.2791\n","Positive sensitivity: 91.2791  specificity: 90.0602\n","Positive FPR: 9.9398  NPV: 95.2229\n","Positive TP: 157.0\n","Positive TN: 299.0\n","Positive FP: 33.0\n","Positive FN: 15.0\n","\n","\n","\n","Epoch 12/50\n","----------\n","Epoch: 12     train index of 50 minibatch: 1      time used: 51.268272399902344\n","minibatch AVG loss: 2.2127379968017338\n","Epoch: 12     train index of 50 minibatch: 2      time used: 50.83542537689209\n","minibatch AVG loss: 1.8073278517462312\n","Epoch: 12     train index of 50 minibatch: 3      time used: 50.660741329193115\n","minibatch AVG loss: 1.6878519056737422\n","Epoch: 12     train index of 50 minibatch: 4      time used: 50.6687216758728\n","minibatch AVG loss: 1.8704483424127103\n","Epoch: 12     train index of 50 minibatch: 5      time used: 50.78665828704834\n","minibatch AVG loss: 1.6364545034989715\n","Epoch: 12     train index of 50 minibatch: 6      time used: 50.89828705787659\n","minibatch AVG loss: 2.003444469869137\n","Epoch: 12     train index of 50 minibatch: 7      time used: 50.89616870880127\n","minibatch AVG loss: 1.9629712454788386\n","Epoch: 12     train index of 50 minibatch: 8      time used: 50.613781690597534\n","minibatch AVG loss: 1.6813858330249787\n","\n","Epoch: 12  train \n","Loss: 1.8233  Acc: 93.0115\n","\n","Epoch: 12, Fix_position_ratio: 0.7020000000000001, Puzzle_patch_size: 128\n","Negative precision: 94.1603  recall: 95.2977\n","Negative sensitivity: 95.2977  specificity: 88.9694\n","Negative FPR: 11.0306  NPV: 91.0214\n","Negative TP: 2209.0\n","Negative TN: 1105.0\n","Negative FP: 137.0\n","Negative FN: 109.0\n","Positive precision: 91.0214  recall: 88.9694\n","Positive sensitivity: 88.9694  specificity: 95.2977\n","Positive FPR: 4.7023  NPV: 94.1603\n","Positive TP: 1105.0\n","Positive TN: 2209.0\n","Positive FP: 109.0\n","Positive FN: 137.0\n","\n","\n","Epoch: 12     val index of 50 minibatch: 1      time used: 19.374103784561157\n","minibatch AVG loss: 2.2759487237408758\n","\n","Epoch: 12  val \n","Loss: 2.1412  Acc: 88.8016\n","Negative precision: 96.3576  recall: 87.6506\n","Negative sensitivity: 87.6506  specificity: 93.6047\n","Negative FPR: 6.3953  NPV: 79.7030\n","Negative TP: 291.0\n","Negative TN: 161.0\n","Negative FP: 11.0\n","Negative FN: 41.0\n","Positive precision: 79.7030  recall: 93.6047\n","Positive sensitivity: 93.6047  specificity: 87.6506\n","Positive FPR: 12.3494  NPV: 96.3576\n","Positive TP: 161.0\n","Positive TN: 291.0\n","Positive FP: 41.0\n","Positive FN: 11.0\n","\n","\n","\n","Epoch 13/50\n","----------\n","Epoch: 13     train index of 50 minibatch: 1      time used: 51.38540434837341\n","minibatch AVG loss: 1.9069439850002528\n","Epoch: 13     train index of 50 minibatch: 2      time used: 50.621094703674316\n","minibatch AVG loss: 1.711024002879858\n","Epoch: 13     train index of 50 minibatch: 3      time used: 50.770519971847534\n","minibatch AVG loss: 1.553916198182851\n","Epoch: 13     train index of 50 minibatch: 4      time used: 50.69645571708679\n","minibatch AVG loss: 2.155402214229107\n","Epoch: 13     train index of 50 minibatch: 5      time used: 50.68409872055054\n","minibatch AVG loss: 1.8834212815761566\n","Epoch: 13     train index of 50 minibatch: 6      time used: 50.827603340148926\n","minibatch AVG loss: 2.1065769817680122\n","Epoch: 13     train index of 50 minibatch: 7      time used: 50.90684795379639\n","minibatch AVG loss: 2.379808625727892\n","Epoch: 13     train index of 50 minibatch: 8      time used: 50.74289608001709\n","minibatch AVG loss: 2.330971609428525\n","\n","Epoch: 13  train \n","Loss: 1.9868  Acc: 91.6643\n","\n","Epoch: 13, Fix_position_ratio: 0.684, Puzzle_patch_size: 128\n","Negative precision: 92.9966  recall: 94.4397\n","Negative sensitivity: 94.4397  specificity: 86.6935\n","Negative FPR: 13.3065  NPV: 89.2857\n","Negative TP: 2191.0\n","Negative TN: 1075.0\n","Negative FP: 165.0\n","Negative FN: 129.0\n","Positive precision: 89.2857  recall: 86.6935\n","Positive sensitivity: 86.6935  specificity: 94.4397\n","Positive FPR: 5.5603  NPV: 92.9966\n","Positive TP: 1075.0\n","Positive TN: 2191.0\n","Positive FP: 129.0\n","Positive FN: 165.0\n","\n","\n","Epoch: 13     val index of 50 minibatch: 1      time used: 19.29901909828186\n","minibatch AVG loss: 0.8528479969757609\n","\n","Epoch: 13  val \n","Loss: 1.9091  Acc: 91.7485\n","Negative precision: 92.5072  recall: 96.6867\n","Negative sensitivity: 96.6867  specificity: 84.8837\n","Negative FPR: 15.1163  NPV: 92.9936\n","Negative TP: 321.0\n","Negative TN: 146.0\n","Negative FP: 26.0\n","Negative FN: 11.0\n","Positive precision: 92.9936  recall: 84.8837\n","Positive sensitivity: 84.8837  specificity: 96.6867\n","Positive FPR: 3.3133  NPV: 92.5072\n","Positive TP: 146.0\n","Positive TN: 321.0\n","Positive FP: 11.0\n","Positive FN: 26.0\n","\n","\n","\n","Epoch 14/50\n","----------\n","Epoch: 14     train index of 50 minibatch: 1      time used: 51.2613046169281\n","minibatch AVG loss: 1.9825749362260103\n","Epoch: 14     train index of 50 minibatch: 2      time used: 51.03691363334656\n","minibatch AVG loss: 2.034469870114699\n","Epoch: 14     train index of 50 minibatch: 3      time used: 50.872801303863525\n","minibatch AVG loss: 2.1518941614311187\n","Epoch: 14     train index of 50 minibatch: 4      time used: 50.58500671386719\n","minibatch AVG loss: 2.8071111047267916\n","Epoch: 14     train index of 50 minibatch: 5      time used: 50.69186782836914\n","minibatch AVG loss: 2.0889378207921983\n","Epoch: 14     train index of 50 minibatch: 6      time used: 50.879600524902344\n","minibatch AVG loss: 1.5874985368549823\n","Epoch: 14     train index of 50 minibatch: 7      time used: 50.863529205322266\n","minibatch AVG loss: 1.9167487036436797\n","Epoch: 14     train index of 50 minibatch: 8      time used: 50.72937202453613\n","minibatch AVG loss: 2.1121932765096427\n","\n","Epoch: 14  train \n","Loss: 2.0586  Acc: 88.9138\n","\n","Epoch: 14, Fix_position_ratio: 0.666, Puzzle_patch_size: 128\n","Negative precision: 90.8782  recall: 92.3674\n","Negative sensitivity: 92.3674  specificity: 82.6753\n","Negative FPR: 17.3247  NPV: 85.2868\n","Negative TP: 2142.0\n","Negative TN: 1026.0\n","Negative FP: 215.0\n","Negative FN: 177.0\n","Positive precision: 85.2868  recall: 82.6753\n","Positive sensitivity: 82.6753  specificity: 92.3674\n","Positive FPR: 7.6326  NPV: 90.8782\n","Positive TP: 1026.0\n","Positive TN: 2142.0\n","Positive FP: 177.0\n","Positive FN: 215.0\n","\n","\n","Epoch: 14     val index of 50 minibatch: 1      time used: 19.324766635894775\n","minibatch AVG loss: 0.9748102620569989\n","\n","Epoch: 14  val \n","Loss: 1.5723  Acc: 90.7662\n","Negative precision: 92.6471  recall: 94.8795\n","Negative sensitivity: 94.8795  specificity: 85.4651\n","Negative FPR: 14.5349  NPV: 89.6341\n","Negative TP: 315.0\n","Negative TN: 147.0\n","Negative FP: 25.0\n","Negative FN: 17.0\n","Positive precision: 89.6341  recall: 85.4651\n","Positive sensitivity: 85.4651  specificity: 94.8795\n","Positive FPR: 5.1205  NPV: 92.6471\n","Positive TP: 147.0\n","Positive TN: 315.0\n","Positive FP: 17.0\n","Positive FN: 25.0\n","\n","\n","\n","Epoch 15/50\n","----------\n","Epoch: 15     train index of 50 minibatch: 1      time used: 51.31108331680298\n","minibatch AVG loss: 2.0928571159765124\n","Epoch: 15     train index of 50 minibatch: 2      time used: 50.98092699050903\n","minibatch AVG loss: 2.642276589088142\n","Epoch: 15     train index of 50 minibatch: 3      time used: 50.76293325424194\n","minibatch AVG loss: 1.3731843619048596\n","Epoch: 15     train index of 50 minibatch: 4      time used: 50.65904211997986\n","minibatch AVG loss: 2.2967795222252607\n","Epoch: 15     train index of 50 minibatch: 5      time used: 50.64782786369324\n","minibatch AVG loss: 1.7681141725182534\n","Epoch: 15     train index of 50 minibatch: 6      time used: 50.668734073638916\n","minibatch AVG loss: 1.809099370315671\n","Epoch: 15     train index of 50 minibatch: 7      time used: 50.68686246871948\n","minibatch AVG loss: 1.6964670502766968\n","Epoch: 15     train index of 50 minibatch: 8      time used: 50.66344881057739\n","minibatch AVG loss: 1.669951717457734\n","\n","Epoch: 15  train \n","Loss: 1.9412  Acc: 89.3629\n","\n","Epoch: 15, Fix_position_ratio: 0.648, Puzzle_patch_size: 128\n","Negative precision: 91.4957  recall: 92.3641\n","Negative sensitivity: 92.3641  specificity: 83.9775\n","Negative FPR: 16.0225  NPV: 85.4918\n","Negative TP: 2141.0\n","Negative TN: 1043.0\n","Negative FP: 199.0\n","Negative FN: 177.0\n","Positive precision: 85.4918  recall: 83.9775\n","Positive sensitivity: 83.9775  specificity: 92.3641\n","Positive FPR: 7.6359  NPV: 91.4957\n","Positive TP: 1043.0\n","Positive TN: 2141.0\n","Positive FP: 177.0\n","Positive FN: 199.0\n","\n","\n","Epoch: 15     val index of 50 minibatch: 1      time used: 19.30297303199768\n","minibatch AVG loss: 0.8513588465016801\n","\n","Epoch: 15  val \n","Loss: 1.6716  Acc: 91.7485\n","Negative precision: 92.0228  recall: 97.2892\n","Negative sensitivity: 97.2892  specificity: 83.7209\n","Negative FPR: 16.2791  NPV: 94.1176\n","Negative TP: 323.0\n","Negative TN: 144.0\n","Negative FP: 28.0\n","Negative FN: 9.0\n","Positive precision: 94.1176  recall: 83.7209\n","Positive sensitivity: 83.7209  specificity: 97.2892\n","Positive FPR: 2.7108  NPV: 92.0228\n","Positive TP: 144.0\n","Positive TN: 323.0\n","Positive FP: 9.0\n","Positive FN: 28.0\n","\n","\n","\n","Epoch 16/50\n","----------\n","Epoch: 16     train index of 50 minibatch: 1      time used: 51.26859211921692\n","minibatch AVG loss: 1.52354027941823\n","Epoch: 16     train index of 50 minibatch: 2      time used: 51.04201364517212\n","minibatch AVG loss: 1.587547909040004\n","Epoch: 16     train index of 50 minibatch: 3      time used: 51.01879596710205\n","minibatch AVG loss: 1.4610043125227095\n","Epoch: 16     train index of 50 minibatch: 4      time used: 50.66639542579651\n","minibatch AVG loss: 2.1888057661429046\n","Epoch: 16     train index of 50 minibatch: 5      time used: 50.64213562011719\n","minibatch AVG loss: 2.128060800805688\n","Epoch: 16     train index of 50 minibatch: 6      time used: 50.792579889297485\n","minibatch AVG loss: 1.7696148100029676\n","Epoch: 16     train index of 50 minibatch: 7      time used: 50.9510543346405\n","minibatch AVG loss: 2.427270647995174\n","Epoch: 16     train index of 50 minibatch: 8      time used: 51.00270414352417\n","minibatch AVG loss: 1.6559506046958268\n","\n","Epoch: 16  train \n","Loss: 1.8537  Acc: 91.5801\n","\n","Epoch: 16, Fix_position_ratio: 0.63, Puzzle_patch_size: 96\n","Negative precision: 92.9482  recall: 94.3510\n","Negative sensitivity: 94.3510  specificity: 86.6237\n","Negative FPR: 13.3763  NPV: 89.1376\n","Negative TP: 2188.0\n","Negative TN: 1075.0\n","Negative FP: 166.0\n","Negative FN: 131.0\n","Positive precision: 89.1376  recall: 86.6237\n","Positive sensitivity: 86.6237  specificity: 94.3510\n","Positive FPR: 5.6490  NPV: 92.9482\n","Positive TP: 1075.0\n","Positive TN: 2188.0\n","Positive FP: 131.0\n","Positive FN: 166.0\n","\n","\n","Epoch: 16     val index of 50 minibatch: 1      time used: 19.283591270446777\n","minibatch AVG loss: 1.9144201267510652\n","\n","Epoch: 16  val \n","Loss: 2.0024  Acc: 89.5874\n","Negative precision: 95.2229  recall: 90.0602\n","Negative sensitivity: 90.0602  specificity: 91.2791\n","Negative FPR: 8.7209  NPV: 82.6316\n","Negative TP: 299.0\n","Negative TN: 157.0\n","Negative FP: 15.0\n","Negative FN: 33.0\n","Positive precision: 82.6316  recall: 91.2791\n","Positive sensitivity: 91.2791  specificity: 90.0602\n","Positive FPR: 9.9398  NPV: 95.2229\n","Positive TP: 157.0\n","Positive TN: 299.0\n","Positive FP: 33.0\n","Positive FN: 15.0\n","\n","\n","\n","Epoch 17/50\n","----------\n","Epoch: 17     train index of 50 minibatch: 1      time used: 51.34918832778931\n","minibatch AVG loss: 2.008664021845907\n","Epoch: 17     train index of 50 minibatch: 2      time used: 50.89084219932556\n","minibatch AVG loss: 1.312670847494155\n","Epoch: 17     train index of 50 minibatch: 3      time used: 50.72199058532715\n","minibatch AVG loss: 1.699093279966619\n","Epoch: 17     train index of 50 minibatch: 4      time used: 50.874648094177246\n","minibatch AVG loss: 1.5164127642568201\n","Epoch: 17     train index of 50 minibatch: 5      time used: 50.79085946083069\n","minibatch AVG loss: 2.194258599355817\n","Epoch: 17     train index of 50 minibatch: 6      time used: 50.73529577255249\n","minibatch AVG loss: 1.7860960276424884\n","Epoch: 17     train index of 50 minibatch: 7      time used: 50.717324018478394\n","minibatch AVG loss: 1.589508810332045\n","Epoch: 17     train index of 50 minibatch: 8      time used: 50.72259211540222\n","minibatch AVG loss: 1.760515269897878\n","\n","Epoch: 17  train \n","Loss: 1.7717  Acc: 90.5136\n","\n","Epoch: 17, Fix_position_ratio: 0.6120000000000001, Puzzle_patch_size: 96\n","Negative precision: 92.1086  recall: 93.5776\n","Negative sensitivity: 93.5776  specificity: 85.0000\n","Negative FPR: 15.0000  NPV: 87.6143\n","Negative TP: 2171.0\n","Negative TN: 1054.0\n","Negative FP: 186.0\n","Negative FN: 149.0\n","Positive precision: 87.6143  recall: 85.0000\n","Positive sensitivity: 85.0000  specificity: 93.5776\n","Positive FPR: 6.4224  NPV: 92.1086\n","Positive TP: 1054.0\n","Positive TN: 2171.0\n","Positive FP: 149.0\n","Positive FN: 186.0\n","\n","\n","Epoch: 17     val index of 50 minibatch: 1      time used: 19.30656909942627\n","minibatch AVG loss: 1.6511523618752835\n","\n","Epoch: 17  val \n","Loss: 1.9590  Acc: 89.9804\n","Negative precision: 95.5414  recall: 90.3614\n","Negative sensitivity: 90.3614  specificity: 91.8605\n","Negative FPR: 8.1395  NPV: 83.1579\n","Negative TP: 300.0\n","Negative TN: 158.0\n","Negative FP: 14.0\n","Negative FN: 32.0\n","Positive precision: 83.1579  recall: 91.8605\n","Positive sensitivity: 91.8605  specificity: 90.3614\n","Positive FPR: 9.6386  NPV: 95.5414\n","Positive TP: 158.0\n","Positive TN: 300.0\n","Positive FP: 32.0\n","Positive FN: 14.0\n","\n","\n","\n","Epoch 18/50\n","----------\n","Epoch: 18     train index of 50 minibatch: 1      time used: 51.22336721420288\n","minibatch AVG loss: 1.5427701695263385\n","Epoch: 18     train index of 50 minibatch: 2      time used: 50.701536417007446\n","minibatch AVG loss: 2.3761433478072287\n","Epoch: 18     train index of 50 minibatch: 3      time used: 50.71378421783447\n","minibatch AVG loss: 1.7408623223588802\n","Epoch: 18     train index of 50 minibatch: 4      time used: 50.73584318161011\n","minibatch AVG loss: 1.7636721562966704\n","Epoch: 18     train index of 50 minibatch: 5      time used: 50.64304828643799\n","minibatch AVG loss: 2.050118139386177\n","Epoch: 18     train index of 50 minibatch: 6      time used: 50.63107466697693\n","minibatch AVG loss: 1.765870390338823\n","Epoch: 18     train index of 50 minibatch: 7      time used: 50.69184327125549\n","minibatch AVG loss: 1.8212151507847012\n","Epoch: 18     train index of 50 minibatch: 8      time used: 50.76247525215149\n","minibatch AVG loss: 1.61813676180318\n","\n","Epoch: 18  train \n","Loss: 1.8287  Acc: 90.9065\n","\n","Epoch: 18, Fix_position_ratio: 0.5940000000000001, Puzzle_patch_size: 96\n","Negative precision: 92.5437  recall: 93.7015\n","Negative sensitivity: 93.7015  specificity: 85.9098\n","Negative FPR: 14.0902  NPV: 87.9637\n","Negative TP: 2172.0\n","Negative TN: 1067.0\n","Negative FP: 175.0\n","Negative FN: 146.0\n","Positive precision: 87.9637  recall: 85.9098\n","Positive sensitivity: 85.9098  specificity: 93.7015\n","Positive FPR: 6.2985  NPV: 92.5437\n","Positive TP: 1067.0\n","Positive TN: 2172.0\n","Positive FP: 146.0\n","Positive FN: 175.0\n","\n","\n","Epoch: 18     val index of 50 minibatch: 1      time used: 19.39049482345581\n","minibatch AVG loss: 1.1701673588820267\n","\n","Epoch: 18  val \n","Loss: 2.2651  Acc: 91.5521\n","Negative precision: 94.0120  recall: 94.5783\n","Negative sensitivity: 94.5783  specificity: 88.3721\n","Negative FPR: 11.6279  NPV: 89.4118\n","Negative TP: 314.0\n","Negative TN: 152.0\n","Negative FP: 20.0\n","Negative FN: 18.0\n","Positive precision: 89.4118  recall: 88.3721\n","Positive sensitivity: 88.3721  specificity: 94.5783\n","Positive FPR: 5.4217  NPV: 94.0120\n","Positive TP: 152.0\n","Positive TN: 314.0\n","Positive FP: 18.0\n","Positive FN: 20.0\n","\n","\n","\n","Epoch 19/50\n","----------\n","Epoch: 19     train index of 50 minibatch: 1      time used: 51.23278021812439\n","minibatch AVG loss: 1.9476416505128145\n","Epoch: 19     train index of 50 minibatch: 2      time used: 50.80012655258179\n","minibatch AVG loss: 1.6636027265246958\n","Epoch: 19     train index of 50 minibatch: 3      time used: 50.57990574836731\n","minibatch AVG loss: 1.7322091077361257\n","Epoch: 19     train index of 50 minibatch: 4      time used: 50.51689291000366\n","minibatch AVG loss: 2.3474892215803265\n","Epoch: 19     train index of 50 minibatch: 5      time used: 50.98585820198059\n","minibatch AVG loss: 1.7455882867518813\n","Epoch: 19     train index of 50 minibatch: 6      time used: 50.82146883010864\n","minibatch AVG loss: 1.683009644029662\n","Epoch: 19     train index of 50 minibatch: 7      time used: 50.698575496673584\n","minibatch AVG loss: 1.5772648358810692\n","Epoch: 19     train index of 50 minibatch: 8      time used: 50.636492013931274\n","minibatch AVG loss: 1.9003820282965898\n","\n","Epoch: 19  train \n","Loss: 1.8335  Acc: 89.9523\n","\n","Epoch: 19, Fix_position_ratio: 0.5760000000000001, Puzzle_patch_size: 96\n","Negative precision: 91.6102  recall: 93.2298\n","Negative sensitivity: 93.2298  specificity: 84.0451\n","Negative FPR: 15.9549  NPV: 86.9167\n","Negative TP: 2162.0\n","Negative TN: 1043.0\n","Negative FP: 198.0\n","Negative FN: 157.0\n","Positive precision: 86.9167  recall: 84.0451\n","Positive sensitivity: 84.0451  specificity: 93.2298\n","Positive FPR: 6.7702  NPV: 91.6102\n","Positive TP: 1043.0\n","Positive TN: 2162.0\n","Positive FP: 157.0\n","Positive FN: 198.0\n","\n","\n","Epoch: 19     val index of 50 minibatch: 1      time used: 19.379345893859863\n","minibatch AVG loss: 1.5624680538475513\n","\n","Epoch: 19  val \n","Loss: 2.0292  Acc: 89.9804\n","Negative precision: 92.5595  recall: 93.6747\n","Negative sensitivity: 93.6747  specificity: 85.4651\n","Negative FPR: 14.5349  NPV: 87.5000\n","Negative TP: 311.0\n","Negative TN: 147.0\n","Negative FP: 25.0\n","Negative FN: 21.0\n","Positive precision: 87.5000  recall: 85.4651\n","Positive sensitivity: 85.4651  specificity: 93.6747\n","Positive FPR: 6.3253  NPV: 92.5595\n","Positive TP: 147.0\n","Positive TN: 311.0\n","Positive FP: 21.0\n","Positive FN: 25.0\n","\n","\n","\n","Epoch 20/50\n","----------\n","Epoch: 20     train index of 50 minibatch: 1      time used: 51.5589542388916\n","minibatch AVG loss: 1.6652518244553358\n","Epoch: 20     train index of 50 minibatch: 2      time used: 51.19943809509277\n","minibatch AVG loss: 2.103398960744962\n","Epoch: 20     train index of 50 minibatch: 3      time used: 51.14236092567444\n","minibatch AVG loss: 1.7139758093841373\n","Epoch: 20     train index of 50 minibatch: 4      time used: 50.68183374404907\n","minibatch AVG loss: 1.6789318311633543\n","Epoch: 20     train index of 50 minibatch: 5      time used: 50.911508560180664\n","minibatch AVG loss: 1.952717207930982\n","Epoch: 20     train index of 50 minibatch: 6      time used: 51.01758432388306\n","minibatch AVG loss: 1.782621723236516\n","Epoch: 20     train index of 50 minibatch: 7      time used: 50.82773685455322\n","minibatch AVG loss: 1.9152700628899038\n","Epoch: 20     train index of 50 minibatch: 8      time used: 50.66125011444092\n","minibatch AVG loss: 1.583939818846993\n","\n","Epoch: 20  train \n","Loss: 1.8254  Acc: 89.2226\n","\n","Epoch: 20, Fix_position_ratio: 0.558, Puzzle_patch_size: 96\n","Negative precision: 98.6814  recall: 86.8914\n","Negative sensitivity: 86.8914  specificity: 96.5169\n","Negative FPR: 3.4831  NPV: 71.0505\n","Negative TP: 2320.0\n","Negative TN: 859.0\n","Negative FP: 31.0\n","Negative FN: 350.0\n","Positive precision: 71.0505  recall: 96.5169\n","Positive sensitivity: 96.5169  specificity: 86.8914\n","Positive FPR: 13.1086  NPV: 98.6814\n","Positive TP: 859.0\n","Positive TN: 2320.0\n","Positive FP: 350.0\n","Positive FN: 31.0\n","\n","\n","Epoch: 20     val index of 50 minibatch: 1      time used: 19.250495433807373\n","minibatch AVG loss: 1.0511164833768272\n","\n","Epoch: 20  val \n","Loss: 2.0735  Acc: 90.7662\n","Negative precision: 91.9075  recall: 95.7831\n","Negative sensitivity: 95.7831  specificity: 83.7209\n","Negative FPR: 16.2791  NPV: 91.1392\n","Negative TP: 318.0\n","Negative TN: 144.0\n","Negative FP: 28.0\n","Negative FN: 14.0\n","Positive precision: 91.1392  recall: 83.7209\n","Positive sensitivity: 83.7209  specificity: 95.7831\n","Positive FPR: 4.2169  NPV: 91.9075\n","Positive TP: 144.0\n","Positive TN: 318.0\n","Positive FP: 14.0\n","Positive FN: 28.0\n","\n","\n","\n","Epoch 21/50\n","----------\n","Epoch: 21     train index of 50 minibatch: 1      time used: 51.25115132331848\n","minibatch AVG loss: 2.043387390845455\n","Epoch: 21     train index of 50 minibatch: 2      time used: 50.899237871170044\n","minibatch AVG loss: 1.8917421174328775\n","Epoch: 21     train index of 50 minibatch: 3      time used: 50.95687937736511\n","minibatch AVG loss: 1.3202763964433688\n","Epoch: 21     train index of 50 minibatch: 4      time used: 50.57677483558655\n","minibatch AVG loss: 1.149046990484203\n","Epoch: 21     train index of 50 minibatch: 5      time used: 50.548922538757324\n","minibatch AVG loss: 2.3411120542883874\n","Epoch: 21     train index of 50 minibatch: 6      time used: 50.750518560409546\n","minibatch AVG loss: 1.7540857025235892\n","Epoch: 21     train index of 50 minibatch: 7      time used: 50.97785544395447\n","minibatch AVG loss: 1.9375075540249236\n","Epoch: 21     train index of 50 minibatch: 8      time used: 50.78267312049866\n","minibatch AVG loss: 1.6306683515571059\n","\n","Epoch: 21  train \n","Loss: 1.7833  Acc: 88.9419\n","\n","Epoch: 21, Fix_position_ratio: 0.54, Puzzle_patch_size: 96\n","Negative precision: 98.8432  recall: 86.3721\n","Negative sensitivity: 86.3721  specificity: 96.9629\n","Negative FPR: 3.0371  NPV: 70.3100\n","Negative TP: 2307.0\n","Negative TN: 862.0\n","Negative FP: 27.0\n","Negative FN: 364.0\n","Positive precision: 70.3100  recall: 96.9629\n","Positive sensitivity: 96.9629  specificity: 86.3721\n","Positive FPR: 13.6279  NPV: 98.8432\n","Positive TP: 862.0\n","Positive TN: 2307.0\n","Positive FP: 364.0\n","Positive FN: 27.0\n","\n","\n","Epoch: 21     val index of 50 minibatch: 1      time used: 19.3108332157135\n","minibatch AVG loss: 1.0188266315544023\n","\n","Epoch: 21  val \n","Loss: 1.6697  Acc: 91.3556\n","Negative precision: 92.9619  recall: 95.4819\n","Negative sensitivity: 95.4819  specificity: 86.0465\n","Negative FPR: 13.9535  NPV: 90.7975\n","Negative TP: 317.0\n","Negative TN: 148.0\n","Negative FP: 24.0\n","Negative FN: 15.0\n","Positive precision: 90.7975  recall: 86.0465\n","Positive sensitivity: 86.0465  specificity: 95.4819\n","Positive FPR: 4.5181  NPV: 92.9619\n","Positive TP: 148.0\n","Positive TN: 317.0\n","Positive FP: 15.0\n","Positive FN: 24.0\n","\n","\n","\n","Epoch 22/50\n","----------\n","Epoch: 22     train index of 50 minibatch: 1      time used: 51.473995208740234\n","minibatch AVG loss: 1.631967675902415\n","Epoch: 22     train index of 50 minibatch: 2      time used: 50.70018291473389\n","minibatch AVG loss: 1.907366319131106\n","Epoch: 22     train index of 50 minibatch: 3      time used: 50.69478726387024\n","minibatch AVG loss: 1.9201250093476847\n","Epoch: 22     train index of 50 minibatch: 4      time used: 50.72738862037659\n","minibatch AVG loss: 1.552481371462345\n","Epoch: 22     train index of 50 minibatch: 5      time used: 50.73737931251526\n","minibatch AVG loss: 2.153783263544319\n","Epoch: 22     train index of 50 minibatch: 6      time used: 50.7856547832489\n","minibatch AVG loss: 1.8591772452183069\n","Epoch: 22     train index of 50 minibatch: 7      time used: 50.7751305103302\n","minibatch AVG loss: 1.7391645301226526\n","Epoch: 22     train index of 50 minibatch: 8      time used: 50.749693632125854\n","minibatch AVG loss: 1.1388916865899228\n","\n","Epoch: 22  train \n","Loss: 1.7711  Acc: 88.9138\n","\n","Epoch: 22, Fix_position_ratio: 0.522, Puzzle_patch_size: 96\n","Negative precision: 99.2694  recall: 86.0335\n","Negative sensitivity: 86.0335  specificity: 98.0571\n","Negative FPR: 1.9429  NPV: 69.5864\n","Negative TP: 2310.0\n","Negative TN: 858.0\n","Negative FP: 17.0\n","Negative FN: 375.0\n","Positive precision: 69.5864  recall: 98.0571\n","Positive sensitivity: 98.0571  specificity: 86.0335\n","Positive FPR: 13.9665  NPV: 99.2694\n","Positive TP: 858.0\n","Positive TN: 2310.0\n","Positive FP: 375.0\n","Positive FN: 17.0\n","\n","\n","Epoch: 22     val index of 50 minibatch: 1      time used: 19.36342191696167\n","minibatch AVG loss: 1.037416994869709\n","\n","Epoch: 22  val \n","Loss: 1.6057  Acc: 91.3556\n","Negative precision: 94.2598  recall: 93.9759\n","Negative sensitivity: 93.9759  specificity: 88.9535\n","Negative FPR: 11.0465  NPV: 88.4393\n","Negative TP: 312.0\n","Negative TN: 153.0\n","Negative FP: 19.0\n","Negative FN: 20.0\n","Positive precision: 88.4393  recall: 88.9535\n","Positive sensitivity: 88.9535  specificity: 93.9759\n","Positive FPR: 6.0241  NPV: 94.2598\n","Positive TP: 153.0\n","Positive TN: 312.0\n","Positive FP: 20.0\n","Positive FN: 19.0\n","\n","\n","\n","Epoch 23/50\n","----------\n","Epoch: 23     train index of 50 minibatch: 1      time used: 51.42105841636658\n","minibatch AVG loss: 1.6110480677538725\n","Epoch: 23     train index of 50 minibatch: 2      time used: 50.7037398815155\n","minibatch AVG loss: 2.029779341481626\n","Epoch: 23     train index of 50 minibatch: 3      time used: 50.653258323669434\n","minibatch AVG loss: 1.824179633948952\n","Epoch: 23     train index of 50 minibatch: 4      time used: 50.97550415992737\n","minibatch AVG loss: 1.5849496874772013\n","Epoch: 23     train index of 50 minibatch: 5      time used: 50.71539640426636\n","minibatch AVG loss: 1.6367549324035644\n","Epoch: 23     train index of 50 minibatch: 6      time used: 50.61248445510864\n","minibatch AVG loss: 1.6420534338150174\n","Epoch: 23     train index of 50 minibatch: 7      time used: 50.68589377403259\n","minibatch AVG loss: 1.5870411667693407\n","Epoch: 23     train index of 50 minibatch: 8      time used: 50.753392457962036\n","minibatch AVG loss: 2.0246342665096746\n","\n","Epoch: 23  train \n","Loss: 1.7149  Acc: 90.0084\n","\n","Epoch: 23, Fix_position_ratio: 0.5040000000000001, Puzzle_patch_size: 64\n","Negative precision: 98.7691  recall: 87.7782\n","Negative sensitivity: 87.7782  specificity: 96.8097\n","Negative FPR: 3.1903  NPV: 73.0897\n","Negative TP: 2327.0\n","Negative TN: 880.0\n","Negative FP: 29.0\n","Negative FN: 324.0\n","Positive precision: 73.0897  recall: 96.8097\n","Positive sensitivity: 96.8097  specificity: 87.7782\n","Positive FPR: 12.2218  NPV: 98.7691\n","Positive TP: 880.0\n","Positive TN: 2327.0\n","Positive FP: 324.0\n","Positive FN: 29.0\n","\n","\n","Epoch: 23     val index of 50 minibatch: 1      time used: 19.34077215194702\n","minibatch AVG loss: 1.6902911637269427\n","\n","Epoch: 23  val \n","Loss: 2.0113  Acc: 91.1591\n","Negative precision: 95.3416  recall: 92.4699\n","Negative sensitivity: 92.4699  specificity: 91.2791\n","Negative FPR: 8.7209  NPV: 86.2637\n","Negative TP: 307.0\n","Negative TN: 157.0\n","Negative FP: 15.0\n","Negative FN: 25.0\n","Positive precision: 86.2637  recall: 91.2791\n","Positive sensitivity: 91.2791  specificity: 92.4699\n","Positive FPR: 7.5301  NPV: 95.3416\n","Positive TP: 157.0\n","Positive TN: 307.0\n","Positive FP: 25.0\n","Positive FN: 15.0\n","\n","\n","\n","Epoch 24/50\n","----------\n","Epoch: 24     train index of 50 minibatch: 1      time used: 51.24550724029541\n","minibatch AVG loss: 1.1707991676195524\n","Epoch: 24     train index of 50 minibatch: 2      time used: 50.81783699989319\n","minibatch AVG loss: 1.4018911895900965\n","Epoch: 24     train index of 50 minibatch: 3      time used: 50.80362677574158\n","minibatch AVG loss: 1.9616018043272196\n","Epoch: 24     train index of 50 minibatch: 4      time used: 50.80394983291626\n","minibatch AVG loss: 1.3105056109838187\n","Epoch: 24     train index of 50 minibatch: 5      time used: 50.81173777580261\n","minibatch AVG loss: 1.6530866344319657\n","Epoch: 24     train index of 50 minibatch: 6      time used: 50.81207823753357\n","minibatch AVG loss: 1.4799325107480399\n","Epoch: 24     train index of 50 minibatch: 7      time used: 50.88293671607971\n","minibatch AVG loss: 1.6306061410624535\n","Epoch: 24     train index of 50 minibatch: 8      time used: 50.812588930130005\n","minibatch AVG loss: 1.6623045212007128\n","\n","Epoch: 24  train \n","Loss: 1.5072  Acc: 90.7662\n","\n","Epoch: 24, Fix_position_ratio: 0.48600000000000004, Puzzle_patch_size: 64\n","Negative precision: 92.6068  recall: 93.4052\n","Negative sensitivity: 93.4052  specificity: 86.0484\n","Negative FPR: 13.9516  NPV: 87.4590\n","Negative TP: 2167.0\n","Negative TN: 1067.0\n","Negative FP: 173.0\n","Negative FN: 153.0\n","Positive precision: 87.4590  recall: 86.0484\n","Positive sensitivity: 86.0484  specificity: 93.4052\n","Positive FPR: 6.5948  NPV: 92.6068\n","Positive TP: 1067.0\n","Positive TN: 2167.0\n","Positive FP: 153.0\n","Positive FN: 173.0\n","\n","\n","Epoch: 24     val index of 50 minibatch: 1      time used: 18.972649335861206\n","minibatch AVG loss: 1.832116567241901\n","\n","Epoch: 24  val \n","Loss: 2.2457  Acc: 91.7485\n","Negative precision: 95.9502  recall: 92.7711\n","Negative sensitivity: 92.7711  specificity: 92.4419\n","Negative FPR: 7.5581  NPV: 86.8852\n","Negative TP: 308.0\n","Negative TN: 159.0\n","Negative FP: 13.0\n","Negative FN: 24.0\n","Positive precision: 86.8852  recall: 92.4419\n","Positive sensitivity: 92.4419  specificity: 92.7711\n","Positive FPR: 7.2289  NPV: 95.9502\n","Positive TP: 159.0\n","Positive TN: 308.0\n","Positive FP: 24.0\n","Positive FN: 13.0\n","\n","\n","\n","Epoch 25/50\n","----------\n","Epoch: 25     train index of 50 minibatch: 1      time used: 50.36345291137695\n","minibatch AVG loss: 1.4586718836962245\n","Epoch: 25     train index of 50 minibatch: 2      time used: 49.739362716674805\n","minibatch AVG loss: 1.6103816843684762\n","Epoch: 25     train index of 50 minibatch: 3      time used: 49.62404417991638\n","minibatch AVG loss: 1.7267056450620293\n","Epoch: 25     train index of 50 minibatch: 4      time used: 49.51250386238098\n","minibatch AVG loss: 1.8870201468351298\n","Epoch: 25     train index of 50 minibatch: 5      time used: 49.55832052230835\n","minibatch AVG loss: 1.9119431422278286\n","Epoch: 25     train index of 50 minibatch: 6      time used: 49.37591791152954\n","minibatch AVG loss: 1.8547100556525402\n","Epoch: 25     train index of 50 minibatch: 7      time used: 49.2782940864563\n","minibatch AVG loss: 1.7497179494285957\n","Epoch: 25     train index of 50 minibatch: 8      time used: 49.479371547698975\n","minibatch AVG loss: 1.8181638634600676\n","\n","Epoch: 25  train \n","Loss: 1.7722  Acc: 90.0084\n","\n","Epoch: 25, Fix_position_ratio: 0.468, Puzzle_patch_size: 64\n","Negative precision: 92.0805  recall: 92.7555\n","Negative sensitivity: 92.7555  specificity: 85.0927\n","Negative FPR: 14.9073  NPV: 86.2745\n","Negative TP: 2151.0\n","Negative TN: 1056.0\n","Negative FP: 185.0\n","Negative FN: 168.0\n","Positive precision: 86.2745  recall: 85.0927\n","Positive sensitivity: 85.0927  specificity: 92.7555\n","Positive FPR: 7.2445  NPV: 92.0805\n","Positive TP: 1056.0\n","Positive TN: 2151.0\n","Positive FP: 168.0\n","Positive FN: 185.0\n","\n","\n","Epoch: 25     val index of 50 minibatch: 1      time used: 18.65476965904236\n","minibatch AVG loss: 1.2927195923234103\n","\n","Epoch: 25  val \n","Loss: 2.0032  Acc: 90.5697\n","Negative precision: 92.3754  recall: 94.8795\n","Negative sensitivity: 94.8795  specificity: 84.8837\n","Negative FPR: 15.1163  NPV: 89.5706\n","Negative TP: 315.0\n","Negative TN: 146.0\n","Negative FP: 26.0\n","Negative FN: 17.0\n","Positive precision: 89.5706  recall: 84.8837\n","Positive sensitivity: 84.8837  specificity: 94.8795\n","Positive FPR: 5.1205  NPV: 92.3754\n","Positive TP: 146.0\n","Positive TN: 315.0\n","Positive FP: 17.0\n","Positive FN: 26.0\n","\n","\n","\n","Epoch 26/50\n","----------\n","Epoch: 26     train index of 50 minibatch: 1      time used: 51.88351106643677\n","minibatch AVG loss: 2.1188649278273806\n","Epoch: 26     train index of 50 minibatch: 2      time used: 50.59282684326172\n","minibatch AVG loss: 1.6394517655763776\n","Epoch: 26     train index of 50 minibatch: 3      time used: 50.96510148048401\n","minibatch AVG loss: 1.3039361537550576\n","Epoch: 26     train index of 50 minibatch: 4      time used: 50.73973059654236\n","minibatch AVG loss: 1.7984248045831919\n","Epoch: 26     train index of 50 minibatch: 5      time used: 50.624327182769775\n","minibatch AVG loss: 1.2929815597273409\n","Epoch: 26     train index of 50 minibatch: 6      time used: 50.80759358406067\n","minibatch AVG loss: 1.4573627491015941\n","Epoch: 26     train index of 50 minibatch: 7      time used: 50.89703631401062\n","minibatch AVG loss: 1.4045540655497462\n","Epoch: 26     train index of 50 minibatch: 8      time used: 50.814192056655884\n","minibatch AVG loss: 1.752406782474136\n","\n","Epoch: 26  train \n","Loss: 1.6028  Acc: 91.3837\n","\n","Epoch: 26, Fix_position_ratio: 0.45, Puzzle_patch_size: 64\n","Negative precision: 93.0740  recall: 93.8767\n","Negative sensitivity: 93.8767  specificity: 86.9460\n","Negative FPR: 13.0540  NPV: 88.3702\n","Negative TP: 2177.0\n","Negative TN: 1079.0\n","Negative FP: 162.0\n","Negative FN: 142.0\n","Positive precision: 88.3702  recall: 86.9460\n","Positive sensitivity: 86.9460  specificity: 93.8767\n","Positive FPR: 6.1233  NPV: 93.0740\n","Positive TP: 1079.0\n","Positive TN: 2177.0\n","Positive FP: 142.0\n","Positive FN: 162.0\n","\n","\n","Epoch: 26     val index of 50 minibatch: 1      time used: 19.34030246734619\n","minibatch AVG loss: 0.7790658537345007\n","\n","Epoch: 26  val \n","Loss: 1.6633  Acc: 93.3202\n","Negative precision: 94.6903  recall: 96.6867\n","Negative sensitivity: 96.6867  specificity: 89.5349\n","Negative FPR: 10.4651  NPV: 93.3333\n","Negative TP: 321.0\n","Negative TN: 154.0\n","Negative FP: 18.0\n","Negative FN: 11.0\n","Positive precision: 93.3333  recall: 89.5349\n","Positive sensitivity: 89.5349  specificity: 96.6867\n","Positive FPR: 3.3133  NPV: 94.6903\n","Positive TP: 154.0\n","Positive TN: 321.0\n","Positive FP: 11.0\n","Positive FN: 18.0\n","\n","\n","\n","Epoch 27/50\n","----------\n","Epoch: 27     train index of 50 minibatch: 1      time used: 51.30336546897888\n","minibatch AVG loss: 1.3839610258163884\n","Epoch: 27     train index of 50 minibatch: 2      time used: 50.89459204673767\n","minibatch AVG loss: 2.0253125997004098\n","Epoch: 27     train index of 50 minibatch: 3      time used: 50.819849491119385\n","minibatch AVG loss: 2.361116040945053\n","Epoch: 27     train index of 50 minibatch: 4      time used: 50.85889434814453\n","minibatch AVG loss: 1.6825286575034262\n","Epoch: 27     train index of 50 minibatch: 5      time used: 50.576796531677246\n","minibatch AVG loss: 1.7110353881679474\n","Epoch: 27     train index of 50 minibatch: 6      time used: 50.0594265460968\n","minibatch AVG loss: 1.6832073398726062\n","Epoch: 27     train index of 50 minibatch: 7      time used: 49.676180601119995\n","minibatch AVG loss: 2.0675236986856906\n","Epoch: 27     train index of 50 minibatch: 8      time used: 49.633418798446655\n","minibatch AVG loss: 1.7543762592831627\n","\n","Epoch: 27  train \n","Loss: 1.8559  Acc: 90.2610\n","\n","Epoch: 27, Fix_position_ratio: 0.432, Puzzle_patch_size: 64\n","Negative precision: 92.0750  recall: 93.1867\n","Negative sensitivity: 93.1867  specificity: 85.0121\n","Negative FPR: 14.9879  NPV: 86.9744\n","Negative TP: 2161.0\n","Negative TN: 1055.0\n","Negative FP: 186.0\n","Negative FN: 158.0\n","Positive precision: 86.9744  recall: 85.0121\n","Positive sensitivity: 85.0121  specificity: 93.1867\n","Positive FPR: 6.8133  NPV: 92.0750\n","Positive TP: 1055.0\n","Positive TN: 2161.0\n","Positive FP: 158.0\n","Positive FN: 186.0\n","\n","\n","Epoch: 27     val index of 50 minibatch: 1      time used: 18.81824040412903\n","minibatch AVG loss: 1.5278422325733119\n","\n","Epoch: 27  val \n","Loss: 1.9991  Acc: 90.7662\n","Negative precision: 95.5975  recall: 91.5663\n","Negative sensitivity: 91.5663  specificity: 91.8605\n","Negative FPR: 8.1395  NPV: 84.9462\n","Negative TP: 304.0\n","Negative TN: 158.0\n","Negative FP: 14.0\n","Negative FN: 28.0\n","Positive precision: 84.9462  recall: 91.8605\n","Positive sensitivity: 91.8605  specificity: 91.5663\n","Positive FPR: 8.4337  NPV: 95.5975\n","Positive TP: 158.0\n","Positive TN: 304.0\n","Positive FP: 28.0\n","Positive FN: 14.0\n","\n","\n","\n","Epoch 28/50\n","----------\n","Epoch: 28     train index of 50 minibatch: 1      time used: 50.069697856903076\n","minibatch AVG loss: 1.809655828648247\n","Epoch: 28     train index of 50 minibatch: 2      time used: 49.25661039352417\n","minibatch AVG loss: 1.0422614279272966\n","Epoch: 28     train index of 50 minibatch: 3      time used: 49.513020277023315\n","minibatch AVG loss: 1.8462567622913049\n","Epoch: 28     train index of 50 minibatch: 4      time used: 51.20542597770691\n","minibatch AVG loss: 1.8561777235660701\n","Epoch: 28     train index of 50 minibatch: 5      time used: 50.63210391998291\n","minibatch AVG loss: 1.8876316113420761\n","Epoch: 28     train index of 50 minibatch: 6      time used: 50.90934681892395\n","minibatch AVG loss: 1.9219811878789914\n","Epoch: 28     train index of 50 minibatch: 7      time used: 50.77950406074524\n","minibatch AVG loss: 1.855210472289473\n","Epoch: 28     train index of 50 minibatch: 8      time used: 50.689136266708374\n","minibatch AVG loss: 1.199964834903367\n","\n","Epoch: 28  train \n","Loss: 1.6863  Acc: 92.6186\n","\n","Epoch: 28, Fix_position_ratio: 0.41400000000000003, Puzzle_patch_size: 64\n","Negative precision: 93.8645  recall: 94.9978\n","Negative sensitivity: 94.9978  specificity: 88.3965\n","Negative FPR: 11.6035  NPV: 90.4369\n","Negative TP: 2203.0\n","Negative TN: 1097.0\n","Negative FP: 144.0\n","Negative FN: 116.0\n","Positive precision: 90.4369  recall: 88.3965\n","Positive sensitivity: 88.3965  specificity: 94.9978\n","Positive FPR: 5.0022  NPV: 93.8645\n","Positive TP: 1097.0\n","Positive TN: 2203.0\n","Positive FP: 116.0\n","Positive FN: 144.0\n","\n","\n","Epoch: 28     val index of 50 minibatch: 1      time used: 19.326208114624023\n","minibatch AVG loss: 1.1292936937091873\n","\n","Epoch: 28  val \n","Loss: 1.9536  Acc: 91.3556\n","Negative precision: 94.2598  recall: 93.9759\n","Negative sensitivity: 93.9759  specificity: 88.9535\n","Negative FPR: 11.0465  NPV: 88.4393\n","Negative TP: 312.0\n","Negative TN: 153.0\n","Negative FP: 19.0\n","Negative FN: 20.0\n","Positive precision: 88.4393  recall: 88.9535\n","Positive sensitivity: 88.9535  specificity: 93.9759\n","Positive FPR: 6.0241  NPV: 94.2598\n","Positive TP: 153.0\n","Positive TN: 312.0\n","Positive FP: 20.0\n","Positive FN: 19.0\n","\n","\n","\n","Epoch 29/50\n","----------\n","Epoch: 29     train index of 50 minibatch: 1      time used: 51.40764284133911\n","minibatch AVG loss: 1.5050994569342584\n","Epoch: 29     train index of 50 minibatch: 2      time used: 50.78940773010254\n","minibatch AVG loss: 1.5245817570970395\n","Epoch: 29     train index of 50 minibatch: 3      time used: 50.73513388633728\n","minibatch AVG loss: 1.7633377730287612\n","Epoch: 29     train index of 50 minibatch: 4      time used: 50.81679821014404\n","minibatch AVG loss: 1.2279380584240425\n","Epoch: 29     train index of 50 minibatch: 5      time used: 51.009583711624146\n","minibatch AVG loss: 1.585766189323622\n","Epoch: 29     train index of 50 minibatch: 6      time used: 50.9265673160553\n","minibatch AVG loss: 1.6404379974643235\n","Epoch: 29     train index of 50 minibatch: 7      time used: 50.78383922576904\n","minibatch AVG loss: 1.7354532562196254\n","Epoch: 29     train index of 50 minibatch: 8      time used: 50.741493225097656\n","minibatch AVG loss: 1.6244016263494268\n","\n","Epoch: 29  train \n","Loss: 1.6104  Acc: 93.3764\n","\n","Epoch: 29, Fix_position_ratio: 0.396, Puzzle_patch_size: 64\n","Negative precision: 94.5346  recall: 95.4722\n","Negative sensitivity: 95.4722  specificity: 89.6857\n","Negative FPR: 10.3143  NPV: 91.3793\n","Negative TP: 2214.0\n","Negative TN: 1113.0\n","Negative FP: 128.0\n","Negative FN: 105.0\n","Positive precision: 91.3793  recall: 89.6857\n","Positive sensitivity: 89.6857  specificity: 95.4722\n","Positive FPR: 4.5278  NPV: 94.5346\n","Positive TP: 1113.0\n","Positive TN: 2214.0\n","Positive FP: 105.0\n","Positive FN: 128.0\n","\n","\n","Epoch: 29     val index of 50 minibatch: 1      time used: 19.335094928741455\n","minibatch AVG loss: 0.996613205889007\n","\n","Epoch: 29  val \n","Loss: 1.9693  Acc: 92.3379\n","Negative precision: 93.8235  recall: 96.0843\n","Negative sensitivity: 96.0843  specificity: 87.7907\n","Negative FPR: 12.2093  NPV: 92.0732\n","Negative TP: 319.0\n","Negative TN: 151.0\n","Negative FP: 21.0\n","Negative FN: 13.0\n","Positive precision: 92.0732  recall: 87.7907\n","Positive sensitivity: 87.7907  specificity: 96.0843\n","Positive FPR: 3.9157  NPV: 93.8235\n","Positive TP: 151.0\n","Positive TN: 319.0\n","Positive FP: 13.0\n","Positive FN: 21.0\n","\n","\n","\n","Epoch 30/50\n","----------\n","Epoch: 30     train index of 50 minibatch: 1      time used: 51.349605083465576\n","minibatch AVG loss: 1.3164611166110263\n","Epoch: 30     train index of 50 minibatch: 2      time used: 50.78899788856506\n","minibatch AVG loss: 1.3608538252909057\n","Epoch: 30     train index of 50 minibatch: 3      time used: 50.707512617111206\n","minibatch AVG loss: 1.2826487470412393\n","Epoch: 30     train index of 50 minibatch: 4      time used: 50.71807146072388\n","minibatch AVG loss: 1.475980694576283\n","Epoch: 30     train index of 50 minibatch: 5      time used: 50.667479038238525\n","minibatch AVG loss: 1.862356091113761\n","Epoch: 30     train index of 50 minibatch: 6      time used: 50.634214639663696\n","minibatch AVG loss: 1.6265879996842705\n","Epoch: 30     train index of 50 minibatch: 7      time used: 50.62203001976013\n","minibatch AVG loss: 1.5809582392993615\n","Epoch: 30     train index of 50 minibatch: 8      time used: 50.73704290390015\n","minibatch AVG loss: 1.1358276333694812\n","\n","Epoch: 30  train \n","Loss: 1.4612  Acc: 94.0219\n","\n","Epoch: 30, Fix_position_ratio: 0.378, Puzzle_patch_size: 48\n","Negative precision: 94.6232  recall: 96.4193\n","Negative sensitivity: 96.4193  specificity: 89.7746\n","Negative FPR: 10.2254  NPV: 93.0718\n","Negative TP: 2235.0\n","Negative TN: 1115.0\n","Negative FP: 127.0\n","Negative FN: 83.0\n","Positive precision: 93.0718  recall: 89.7746\n","Positive sensitivity: 89.7746  specificity: 96.4193\n","Positive FPR: 3.5807  NPV: 94.6232\n","Positive TP: 1115.0\n","Positive TN: 2235.0\n","Positive FP: 83.0\n","Positive FN: 127.0\n","\n","\n","Epoch: 30     val index of 50 minibatch: 1      time used: 19.37870740890503\n","minibatch AVG loss: 2.5916760104856804\n","\n","Epoch: 30  val \n","Loss: 2.5700  Acc: 90.3733\n","Negative precision: 96.1538  recall: 90.3614\n","Negative sensitivity: 90.3614  specificity: 93.0233\n","Negative FPR: 6.9767  NPV: 83.3333\n","Negative TP: 300.0\n","Negative TN: 160.0\n","Negative FP: 12.0\n","Negative FN: 32.0\n","Positive precision: 83.3333  recall: 93.0233\n","Positive sensitivity: 93.0233  specificity: 90.3614\n","Positive FPR: 9.6386  NPV: 96.1538\n","Positive TP: 160.0\n","Positive TN: 300.0\n","Positive FP: 32.0\n","Positive FN: 12.0\n","\n","\n","\n","Epoch 31/50\n","----------\n","Epoch: 31     train index of 50 minibatch: 1      time used: 51.24273920059204\n","minibatch AVG loss: 1.462078945018875\n","Epoch: 31     train index of 50 minibatch: 2      time used: 50.75117635726929\n","minibatch AVG loss: 1.6123993294686079\n","Epoch: 31     train index of 50 minibatch: 3      time used: 50.73741960525513\n","minibatch AVG loss: 1.8264568957849405\n","Epoch: 31     train index of 50 minibatch: 4      time used: 50.63113570213318\n","minibatch AVG loss: 1.0858423565689008\n","Epoch: 31     train index of 50 minibatch: 5      time used: 51.076621770858765\n","minibatch AVG loss: 1.4553137439739658\n","Epoch: 31     train index of 50 minibatch: 6      time used: 50.9725239276886\n","minibatch AVG loss: 1.5668979675904848\n","Epoch: 31     train index of 50 minibatch: 7      time used: 50.77667546272278\n","minibatch AVG loss: 1.1398190637072547\n","Epoch: 31     train index of 50 minibatch: 8      time used: 50.6847505569458\n","minibatch AVG loss: 1.4841940400993918\n","\n","Epoch: 31  train \n","Loss: 1.4379  Acc: 94.8358\n","\n","Epoch: 31, Fix_position_ratio: 0.36000000000000004, Puzzle_patch_size: 48\n","Negative precision: 95.7656  recall: 96.4670\n","Negative sensitivity: 96.4670  specificity: 92.0097\n","Negative FPR: 7.9903  NPV: 93.2897\n","Negative TP: 2239.0\n","Negative TN: 1140.0\n","Negative FP: 99.0\n","Negative FN: 82.0\n","Positive precision: 93.2897  recall: 92.0097\n","Positive sensitivity: 92.0097  specificity: 96.4670\n","Positive FPR: 3.5330  NPV: 95.7656\n","Positive TP: 1140.0\n","Positive TN: 2239.0\n","Positive FP: 82.0\n","Positive FN: 99.0\n","\n","\n","Epoch: 31     val index of 50 minibatch: 1      time used: 19.2444806098938\n","minibatch AVG loss: 1.7185135062987684\n","\n","Epoch: 31  val \n","Loss: 2.4188  Acc: 90.7662\n","Negative precision: 93.9394  recall: 93.3735\n","Negative sensitivity: 93.3735  specificity: 88.3721\n","Negative FPR: 11.6279  NPV: 87.3563\n","Negative TP: 310.0\n","Negative TN: 152.0\n","Negative FP: 20.0\n","Negative FN: 22.0\n","Positive precision: 87.3563  recall: 88.3721\n","Positive sensitivity: 88.3721  specificity: 93.3735\n","Positive FPR: 6.6265  NPV: 93.9394\n","Positive TP: 152.0\n","Positive TN: 310.0\n","Positive FP: 22.0\n","Positive FN: 20.0\n","\n","\n","\n","Epoch 32/50\n","----------\n","Epoch: 32     train index of 50 minibatch: 1      time used: 51.358227014541626\n","minibatch AVG loss: 1.7719631426827982\n","Epoch: 32     train index of 50 minibatch: 2      time used: 50.63254380226135\n","minibatch AVG loss: 1.6741135732713155\n","Epoch: 32     train index of 50 minibatch: 3      time used: 50.68374419212341\n","minibatch AVG loss: 1.0847256842777278\n","Epoch: 32     train index of 50 minibatch: 4      time used: 50.84097409248352\n","minibatch AVG loss: 1.6571363002847648\n","Epoch: 32     train index of 50 minibatch: 5      time used: 50.56440544128418\n","minibatch AVG loss: 1.183021653843898\n","Epoch: 32     train index of 50 minibatch: 6      time used: 50.95563244819641\n","minibatch AVG loss: 1.4845621253037826\n","Epoch: 32     train index of 50 minibatch: 7      time used: 51.05220603942871\n","minibatch AVG loss: 1.5312402932858094\n","Epoch: 32     train index of 50 minibatch: 8      time used: 50.87219953536987\n","minibatch AVG loss: 1.4468600097333546\n","\n","Epoch: 32  train \n","Loss: 1.4867  Acc: 94.8919\n","\n","Epoch: 32, Fix_position_ratio: 0.342, Puzzle_patch_size: 48\n","Negative precision: 95.9227  recall: 96.3777\n","Negative sensitivity: 96.3777  specificity: 92.3449\n","Negative FPR: 7.6551  NPV: 93.1707\n","Negative TP: 2235.0\n","Negative TN: 1146.0\n","Negative FP: 95.0\n","Negative FN: 84.0\n","Positive precision: 93.1707  recall: 92.3449\n","Positive sensitivity: 92.3449  specificity: 96.3777\n","Positive FPR: 3.6223  NPV: 95.9227\n","Positive TP: 1146.0\n","Positive TN: 2235.0\n","Positive FP: 84.0\n","Positive FN: 95.0\n","\n","\n","Epoch: 32     val index of 50 minibatch: 1      time used: 19.294583797454834\n","minibatch AVG loss: 1.4686234866938321\n","\n","Epoch: 32  val \n","Loss: 2.2046  Acc: 91.1591\n","Negative precision: 94.7853  recall: 93.0723\n","Negative sensitivity: 93.0723  specificity: 90.1163\n","Negative FPR: 9.8837  NPV: 87.0787\n","Negative TP: 309.0\n","Negative TN: 155.0\n","Negative FP: 17.0\n","Negative FN: 23.0\n","Positive precision: 87.0787  recall: 90.1163\n","Positive sensitivity: 90.1163  specificity: 93.0723\n","Positive FPR: 6.9277  NPV: 94.7853\n","Positive TP: 155.0\n","Positive TN: 309.0\n","Positive FP: 23.0\n","Positive FN: 17.0\n","\n","\n","\n","Epoch 33/50\n","----------\n","Epoch: 33     train index of 50 minibatch: 1      time used: 51.22035026550293\n","minibatch AVG loss: 1.4416541448887437\n","Epoch: 33     train index of 50 minibatch: 2      time used: 50.3455753326416\n","minibatch AVG loss: 1.0682981125457445\n","Epoch: 33     train index of 50 minibatch: 3      time used: 49.936190605163574\n","minibatch AVG loss: 1.6541505096270703\n","Epoch: 33     train index of 50 minibatch: 4      time used: 49.96999192237854\n","minibatch AVG loss: 1.6924094443162903\n","Epoch: 33     train index of 50 minibatch: 5      time used: 50.22988700866699\n","minibatch AVG loss: 1.3748232945334167\n","Epoch: 33     train index of 50 minibatch: 6      time used: 50.8627872467041\n","minibatch AVG loss: 1.744042259149719\n","Epoch: 33     train index of 50 minibatch: 7      time used: 50.767743825912476\n","minibatch AVG loss: 1.7394350743759424\n","Epoch: 33     train index of 50 minibatch: 8      time used: 50.928839921951294\n","minibatch AVG loss: 1.0772619791823672\n","\n","Epoch: 33  train \n","Loss: 1.4466  Acc: 96.5198\n","\n","Epoch: 33, Fix_position_ratio: 0.324, Puzzle_patch_size: 48\n","Negative precision: 97.1674  recall: 97.6283\n","Negative sensitivity: 97.6283  specificity: 94.6817\n","Negative FPR: 5.3183  NPV: 95.5285\n","Negative TP: 2264.0\n","Negative TN: 1175.0\n","Negative FP: 66.0\n","Negative FN: 55.0\n","Positive precision: 95.5285  recall: 94.6817\n","Positive sensitivity: 94.6817  specificity: 97.6283\n","Positive FPR: 2.3717  NPV: 97.1674\n","Positive TP: 1175.0\n","Positive TN: 2264.0\n","Positive FP: 55.0\n","Positive FN: 66.0\n","\n","\n","Epoch: 33     val index of 50 minibatch: 1      time used: 19.2624294757843\n","minibatch AVG loss: 1.4240980403593857\n","\n","Epoch: 33  val \n","Loss: 2.5440  Acc: 91.5521\n","Negative precision: 94.0120  recall: 94.5783\n","Negative sensitivity: 94.5783  specificity: 88.3721\n","Negative FPR: 11.6279  NPV: 89.4118\n","Negative TP: 314.0\n","Negative TN: 152.0\n","Negative FP: 20.0\n","Negative FN: 18.0\n","Positive precision: 89.4118  recall: 88.3721\n","Positive sensitivity: 88.3721  specificity: 94.5783\n","Positive FPR: 5.4217  NPV: 94.0120\n","Positive TP: 152.0\n","Positive TN: 314.0\n","Positive FP: 18.0\n","Positive FN: 20.0\n","\n","\n","\n","Epoch 34/50\n","----------\n","Epoch: 34     train index of 50 minibatch: 1      time used: 51.37437200546265\n","minibatch AVG loss: 1.0912729693076109\n","Epoch: 34     train index of 50 minibatch: 2      time used: 50.662782192230225\n","minibatch AVG loss: 1.1857229215692495\n","Epoch: 34     train index of 50 minibatch: 3      time used: 50.598763942718506\n","minibatch AVG loss: 0.9783738316799281\n","Epoch: 34     train index of 50 minibatch: 4      time used: 50.84070658683777\n","minibatch AVG loss: 1.4489596613690083\n","Epoch: 34     train index of 50 minibatch: 5      time used: 50.827048540115356\n","minibatch AVG loss: 1.3294914861110738\n","Epoch: 34     train index of 50 minibatch: 6      time used: 50.737396240234375\n","minibatch AVG loss: 1.701049504172406\n","Epoch: 34     train index of 50 minibatch: 7      time used: 50.68473505973816\n","minibatch AVG loss: 1.0041733449551975\n","Epoch: 34     train index of 50 minibatch: 8      time used: 50.69022011756897\n","minibatch AVG loss: 1.8601052350693499\n","\n","Epoch: 34  train \n","Loss: 1.3613  Acc: 96.8285\n","\n","Epoch: 34, Fix_position_ratio: 0.30600000000000005, Puzzle_patch_size: 48\n","Negative precision: 97.2234  recall: 98.0612\n","Negative sensitivity: 98.0612  specificity: 94.7538\n","Negative FPR: 5.2462  NPV: 96.3084\n","Negative TP: 2276.0\n","Negative TN: 1174.0\n","Negative FP: 65.0\n","Negative FN: 45.0\n","Positive precision: 96.3084  recall: 94.7538\n","Positive sensitivity: 94.7538  specificity: 98.0612\n","Positive FPR: 1.9388  NPV: 97.2234\n","Positive TP: 1174.0\n","Positive TN: 2276.0\n","Positive FP: 45.0\n","Positive FN: 65.0\n","\n","\n","Epoch: 34     val index of 50 minibatch: 1      time used: 19.270143270492554\n","minibatch AVG loss: 1.336454580265563\n","\n","Epoch: 34  val \n","Loss: 2.1154  Acc: 91.7485\n","Negative precision: 94.8328  recall: 93.9759\n","Negative sensitivity: 93.9759  specificity: 90.1163\n","Negative FPR: 9.8837  NPV: 88.5714\n","Negative TP: 312.0\n","Negative TN: 155.0\n","Negative FP: 17.0\n","Negative FN: 20.0\n","Positive precision: 88.5714  recall: 90.1163\n","Positive sensitivity: 90.1163  specificity: 93.9759\n","Positive FPR: 6.0241  NPV: 94.8328\n","Positive TP: 155.0\n","Positive TN: 312.0\n","Positive FP: 20.0\n","Positive FN: 17.0\n","\n","\n","\n","Epoch 35/50\n","----------\n","Epoch: 35     train index of 50 minibatch: 1      time used: 51.197741985321045\n","minibatch AVG loss: 1.4477764094236774\n","Epoch: 35     train index of 50 minibatch: 2      time used: 50.92429208755493\n","minibatch AVG loss: 1.2050294389924965\n","Epoch: 35     train index of 50 minibatch: 3      time used: 50.90215349197388\n","minibatch AVG loss: 1.2130779813742265\n","Epoch: 35     train index of 50 minibatch: 4      time used: 50.88753414154053\n","minibatch AVG loss: 1.438763281715801\n","Epoch: 35     train index of 50 minibatch: 5      time used: 50.815536975860596\n","minibatch AVG loss: 1.5328092767321504\n","Epoch: 35     train index of 50 minibatch: 6      time used: 50.54886293411255\n","minibatch AVG loss: 1.2861219083654578\n","Epoch: 35     train index of 50 minibatch: 7      time used: 50.56292462348938\n","minibatch AVG loss: 1.14595473308731\n","Epoch: 35     train index of 50 minibatch: 8      time used: 50.62118411064148\n","minibatch AVG loss: 1.4427437866420951\n","\n","Epoch: 35  train \n","Loss: 1.3022  Acc: 97.7547\n","\n","Epoch: 35, Fix_position_ratio: 0.28800000000000003, Puzzle_patch_size: 48\n","Negative precision: 98.1116  recall: 98.5770\n","Negative sensitivity: 98.5770  specificity: 96.4545\n","Negative FPR: 3.5455  NPV: 97.3171\n","Negative TP: 2286.0\n","Negative TN: 1197.0\n","Negative FP: 44.0\n","Negative FN: 33.0\n","Positive precision: 97.3171  recall: 96.4545\n","Positive sensitivity: 96.4545  specificity: 98.5770\n","Positive FPR: 1.4230  NPV: 98.1116\n","Positive TP: 1197.0\n","Positive TN: 2286.0\n","Positive FP: 33.0\n","Positive FN: 44.0\n","\n","\n","Epoch: 35     val index of 50 minibatch: 1      time used: 19.213542461395264\n","minibatch AVG loss: 1.3308593860421387\n","\n","Epoch: 35  val \n","Loss: 2.0707  Acc: 91.5521\n","Negative precision: 95.0920  recall: 93.3735\n","Negative sensitivity: 93.3735  specificity: 90.6977\n","Negative FPR: 9.3023  NPV: 87.6404\n","Negative TP: 310.0\n","Negative TN: 156.0\n","Negative FP: 16.0\n","Negative FN: 22.0\n","Positive precision: 87.6404  recall: 90.6977\n","Positive sensitivity: 90.6977  specificity: 93.3735\n","Positive FPR: 6.6265  NPV: 95.0920\n","Positive TP: 156.0\n","Positive TN: 310.0\n","Positive FP: 22.0\n","Positive FN: 16.0\n","\n","\n","\n","Epoch 36/50\n","----------\n","Epoch: 36     train index of 50 minibatch: 1      time used: 51.16218328475952\n","minibatch AVG loss: 1.1636471312888899\n","Epoch: 36     train index of 50 minibatch: 2      time used: 50.73873972892761\n","minibatch AVG loss: 1.5729573104082375\n","Epoch: 36     train index of 50 minibatch: 3      time used: 50.77945256233215\n","minibatch AVG loss: 1.4019030046951957\n","Epoch: 36     train index of 50 minibatch: 4      time used: 50.759822607040405\n","minibatch AVG loss: 1.6464599383360474\n","Epoch: 36     train index of 50 minibatch: 5      time used: 50.80569410324097\n","minibatch AVG loss: 1.4026586270052939\n","Epoch: 36     train index of 50 minibatch: 6      time used: 50.79535222053528\n","minibatch AVG loss: 1.4321154197577561\n","Epoch: 36     train index of 50 minibatch: 7      time used: 50.7614803314209\n","minibatch AVG loss: 1.0076630666729762\n","Epoch: 36     train index of 50 minibatch: 8      time used: 50.79053997993469\n","minibatch AVG loss: 1.2263683378446149\n","\n","Epoch: 36  train \n","Loss: 1.3658  Acc: 97.6986\n","\n","Epoch: 36, Fix_position_ratio: 0.27, Puzzle_patch_size: 48\n","Negative precision: 97.8623  recall: 98.7489\n","Negative sensitivity: 98.7489  specificity: 95.9742\n","Negative FPR: 4.0258  NPV: 97.6249\n","Negative TP: 2289.0\n","Negative TN: 1192.0\n","Negative FP: 50.0\n","Negative FN: 29.0\n","Positive precision: 97.6249  recall: 95.9742\n","Positive sensitivity: 95.9742  specificity: 98.7489\n","Positive FPR: 1.2511  NPV: 97.8623\n","Positive TP: 1192.0\n","Positive TN: 2289.0\n","Positive FP: 29.0\n","Positive FN: 50.0\n","\n","\n","Epoch: 36     val index of 50 minibatch: 1      time used: 19.34675908088684\n","minibatch AVG loss: 2.80290596441715\n","\n","Epoch: 36  val \n","Loss: 2.7149  Acc: 90.3733\n","Negative precision: 95.8599  recall: 90.6627\n","Negative sensitivity: 90.6627  specificity: 92.4419\n","Negative FPR: 7.5581  NPV: 83.6842\n","Negative TP: 301.0\n","Negative TN: 159.0\n","Negative FP: 13.0\n","Negative FN: 31.0\n","Positive precision: 83.6842  recall: 92.4419\n","Positive sensitivity: 92.4419  specificity: 90.6627\n","Positive FPR: 9.3373  NPV: 95.8599\n","Positive TP: 159.0\n","Positive TN: 301.0\n","Positive FP: 31.0\n","Positive FN: 13.0\n","\n","\n","\n","Epoch 37/50\n","----------\n","Epoch: 37     train index of 50 minibatch: 1      time used: 51.27158546447754\n","minibatch AVG loss: 1.449090523943305\n","Epoch: 37     train index of 50 minibatch: 2      time used: 50.78460335731506\n","minibatch AVG loss: 1.2872466193768195\n","Epoch: 37     train index of 50 minibatch: 3      time used: 50.781343936920166\n","minibatch AVG loss: 1.4401666796696373\n","Epoch: 37     train index of 50 minibatch: 4      time used: 50.59407663345337\n","minibatch AVG loss: 1.2956480614934116\n","Epoch: 37     train index of 50 minibatch: 5      time used: 50.67462992668152\n","minibatch AVG loss: 1.4235784462746233\n","Epoch: 37     train index of 50 minibatch: 6      time used: 50.98654246330261\n","minibatch AVG loss: 0.915133403922664\n","Epoch: 37     train index of 50 minibatch: 7      time used: 50.820863485336304\n","minibatch AVG loss: 1.2146989396517165\n","Epoch: 37     train index of 50 minibatch: 8      time used: 50.765217304229736\n","minibatch AVG loss: 1.3285965040326118\n","\n","Epoch: 37  train \n","Loss: 1.3015  Acc: 97.7547\n","\n","Epoch: 37, Fix_position_ratio: 0.25200000000000006, Puzzle_patch_size: 32\n","Negative precision: 98.0283  recall: 98.6626\n","Negative sensitivity: 98.6626  specificity: 96.2963\n","Negative FPR: 3.7037  NPV: 97.4735\n","Negative TP: 2287.0\n","Negative TN: 1196.0\n","Negative FP: 46.0\n","Negative FN: 31.0\n","Positive precision: 97.4735  recall: 96.2963\n","Positive sensitivity: 96.2963  specificity: 98.6626\n","Positive FPR: 1.3374  NPV: 98.0283\n","Positive TP: 1196.0\n","Positive TN: 2287.0\n","Positive FP: 31.0\n","Positive FN: 46.0\n","\n","\n","Epoch: 37     val index of 50 minibatch: 1      time used: 19.25008487701416\n","minibatch AVG loss: 1.3633802772592754\n","\n","Epoch: 37  val \n","Loss: 2.0191  Acc: 90.5697\n","Negative precision: 93.6556  recall: 93.3735\n","Negative sensitivity: 93.3735  specificity: 87.7907\n","Negative FPR: 12.2093  NPV: 87.2832\n","Negative TP: 310.0\n","Negative TN: 151.0\n","Negative FP: 21.0\n","Negative FN: 22.0\n","Positive precision: 87.2832  recall: 87.7907\n","Positive sensitivity: 87.7907  specificity: 93.3735\n","Positive FPR: 6.6265  NPV: 93.6556\n","Positive TP: 151.0\n","Positive TN: 310.0\n","Positive FP: 22.0\n","Positive FN: 21.0\n","\n","\n","\n","Epoch 38/50\n","----------\n","Epoch: 38     train index of 50 minibatch: 1      time used: 51.50367188453674\n","minibatch AVG loss: 1.282906475104137\n","Epoch: 38     train index of 50 minibatch: 2      time used: 50.48327374458313\n","minibatch AVG loss: 1.188375155851245\n","Epoch: 38     train index of 50 minibatch: 3      time used: 50.69889569282532\n","minibatch AVG loss: 0.9413917329424294\n","Epoch: 38     train index of 50 minibatch: 4      time used: 50.69216060638428\n","minibatch AVG loss: 1.069926743635442\n","Epoch: 38     train index of 50 minibatch: 5      time used: 50.6893253326416\n","minibatch AVG loss: 1.1510573446191847\n","Epoch: 38     train index of 50 minibatch: 6      time used: 50.693482875823975\n","minibatch AVG loss: 1.383199292817735\n","Epoch: 38     train index of 50 minibatch: 7      time used: 50.994335412979126\n","minibatch AVG loss: 1.1416418709834397\n","Epoch: 38     train index of 50 minibatch: 8      time used: 50.68654799461365\n","minibatch AVG loss: 1.2333495296142063\n","\n","Epoch: 38  train \n","Loss: 1.1509  Acc: 98.2599\n","\n","Epoch: 38, Fix_position_ratio: 0.25, Puzzle_patch_size: 32\n","Negative precision: 98.4147  recall: 99.0513\n","Negative sensitivity: 99.0513  specificity: 97.0185\n","Negative FPR: 2.9815  NPV: 98.2055\n","Negative TP: 2297.0\n","Negative TN: 1204.0\n","Negative FP: 37.0\n","Negative FN: 22.0\n","Positive precision: 98.2055  recall: 97.0185\n","Positive sensitivity: 97.0185  specificity: 99.0513\n","Positive FPR: 0.9487  NPV: 98.4147\n","Positive TP: 1204.0\n","Positive TN: 2297.0\n","Positive FP: 22.0\n","Positive FN: 37.0\n","\n","\n","Epoch: 38     val index of 50 minibatch: 1      time used: 19.373236894607544\n","minibatch AVG loss: 0.7415975805792914\n","\n","Epoch: 38  val \n","Loss: 2.8871  Acc: 91.9450\n","Negative precision: 91.5730  recall: 98.1928\n","Negative sensitivity: 98.1928  specificity: 82.5581\n","Negative FPR: 17.4419  NPV: 95.9459\n","Negative TP: 326.0\n","Negative TN: 142.0\n","Negative FP: 30.0\n","Negative FN: 6.0\n","Positive precision: 95.9459  recall: 82.5581\n","Positive sensitivity: 82.5581  specificity: 98.1928\n","Positive FPR: 1.8072  NPV: 91.5730\n","Positive TP: 142.0\n","Positive TN: 326.0\n","Positive FP: 6.0\n","Positive FN: 30.0\n","\n","\n","\n","Epoch 39/50\n","----------\n","Epoch: 39     train index of 50 minibatch: 1      time used: 51.413307666778564\n","minibatch AVG loss: 1.2850938164821128\n","Epoch: 39     train index of 50 minibatch: 2      time used: 50.60805821418762\n","minibatch AVG loss: 1.112673375417653\n","Epoch: 39     train index of 50 minibatch: 3      time used: 50.62842130661011\n","minibatch AVG loss: 1.2438717282260767\n","Epoch: 39     train index of 50 minibatch: 4      time used: 50.703314781188965\n","minibatch AVG loss: 1.3704559553065336\n","Epoch: 39     train index of 50 minibatch: 5      time used: 50.661376953125\n","minibatch AVG loss: 0.889490721829061\n","Epoch: 39     train index of 50 minibatch: 6      time used: 50.650094747543335\n","minibatch AVG loss: 1.197428759485483\n","Epoch: 39     train index of 50 minibatch: 7      time used: 50.858866691589355\n","minibatch AVG loss: 1.2282260118913837\n","Epoch: 39     train index of 50 minibatch: 8      time used: 50.658605098724365\n","minibatch AVG loss: 1.198159623904503\n","\n","Epoch: 39  train \n","Loss: 1.1956  Acc: 98.1476\n","\n","Epoch: 39, Fix_position_ratio: 0.25, Puzzle_patch_size: 32\n","Negative precision: 98.3705  recall: 98.9219\n","Negative sensitivity: 98.9219  specificity: 96.9380\n","Negative FPR: 3.0620  NPV: 97.9642\n","Negative TP: 2294.0\n","Negative TN: 1203.0\n","Negative FP: 38.0\n","Negative FN: 25.0\n","Positive precision: 97.9642  recall: 96.9380\n","Positive sensitivity: 96.9380  specificity: 98.9219\n","Positive FPR: 1.0781  NPV: 98.3705\n","Positive TP: 1203.0\n","Positive TN: 2294.0\n","Positive FP: 25.0\n","Positive FN: 38.0\n","\n","\n","Epoch: 39     val index of 50 minibatch: 1      time used: 19.330958366394043\n","minibatch AVG loss: 1.8792822624585823\n","\n","Epoch: 39  val \n","Loss: 2.2980  Acc: 91.5521\n","Negative precision: 95.3704  recall: 93.0723\n","Negative sensitivity: 93.0723  specificity: 91.2791\n","Negative FPR: 8.7209  NPV: 87.2222\n","Negative TP: 309.0\n","Negative TN: 157.0\n","Negative FP: 15.0\n","Negative FN: 23.0\n","Positive precision: 87.2222  recall: 91.2791\n","Positive sensitivity: 91.2791  specificity: 93.0723\n","Positive FPR: 6.9277  NPV: 95.3704\n","Positive TP: 157.0\n","Positive TN: 309.0\n","Positive FP: 23.0\n","Positive FN: 15.0\n","\n","\n","\n","Epoch 40/50\n","----------\n","Epoch: 40     train index of 50 minibatch: 1      time used: 51.30052161216736\n","minibatch AVG loss: 1.1613462818891276\n","Epoch: 40     train index of 50 minibatch: 2      time used: 50.97969388961792\n","minibatch AVG loss: 1.0718417318261344\n","Epoch: 40     train index of 50 minibatch: 3      time used: 50.77048373222351\n","minibatch AVG loss: 1.68829200754466\n","Epoch: 40     train index of 50 minibatch: 4      time used: 50.65909171104431\n","minibatch AVG loss: 1.3387663629022426\n","Epoch: 40     train index of 50 minibatch: 5      time used: 50.777931928634644\n","minibatch AVG loss: 1.1853483457065885\n","Epoch: 40     train index of 50 minibatch: 6      time used: 51.00832986831665\n","minibatch AVG loss: 1.2985740378173067\n","Epoch: 40     train index of 50 minibatch: 7      time used: 50.75320100784302\n","minibatch AVG loss: 1.0833961810421897\n","Epoch: 40     train index of 50 minibatch: 8      time used: 50.55413746833801\n","minibatch AVG loss: 1.1710945975477807\n","\n","Epoch: 40  train \n","Loss: 1.2852  Acc: 98.5406\n","\n","Epoch: 40, Fix_position_ratio: 0.25, Puzzle_patch_size: 32\n","Negative precision: 99.0069  recall: 98.8788\n","Negative sensitivity: 98.8788  specificity: 98.1467\n","Negative FPR: 1.8533  NPV: 97.9100\n","Negative TP: 2293.0\n","Negative TN: 1218.0\n","Negative FP: 23.0\n","Negative FN: 26.0\n","Positive precision: 97.9100  recall: 98.1467\n","Positive sensitivity: 98.1467  specificity: 98.8788\n","Positive FPR: 1.1212  NPV: 99.0069\n","Positive TP: 1218.0\n","Positive TN: 2293.0\n","Positive FP: 26.0\n","Positive FN: 23.0\n","\n","\n","Epoch: 40     val index of 50 minibatch: 1      time used: 19.196932077407837\n","minibatch AVG loss: 1.5820125363080297\n","\n","Epoch: 40  val \n","Loss: 2.1815  Acc: 91.9450\n","Negative precision: 95.6790  recall: 93.3735\n","Negative sensitivity: 93.3735  specificity: 91.8605\n","Negative FPR: 8.1395  NPV: 87.7778\n","Negative TP: 310.0\n","Negative TN: 158.0\n","Negative FP: 14.0\n","Negative FN: 22.0\n","Positive precision: 87.7778  recall: 91.8605\n","Positive sensitivity: 91.8605  specificity: 93.3735\n","Positive FPR: 6.6265  NPV: 95.6790\n","Positive TP: 158.0\n","Positive TN: 310.0\n","Positive FP: 22.0\n","Positive FN: 14.0\n","\n","\n","\n","Epoch 41/50\n","----------\n","Epoch: 41     train index of 50 minibatch: 1      time used: 51.45366311073303\n","minibatch AVG loss: 1.132694879465853\n","Epoch: 41     train index of 50 minibatch: 2      time used: 50.50027394294739\n","minibatch AVG loss: 1.108555265768664\n","Epoch: 41     train index of 50 minibatch: 3      time used: 50.85461711883545\n","minibatch AVG loss: 0.9556137777754339\n","Epoch: 41     train index of 50 minibatch: 4      time used: 50.63646149635315\n","minibatch AVG loss: 1.2314736648387044\n","Epoch: 41     train index of 50 minibatch: 5      time used: 50.673656940460205\n","minibatch AVG loss: 1.5008323618213764\n","Epoch: 41     train index of 50 minibatch: 6      time used: 50.78139853477478\n","minibatch AVG loss: 1.3924945344170556\n","Epoch: 41     train index of 50 minibatch: 7      time used: 50.87507081031799\n","minibatch AVG loss: 1.1402462723269127\n","Epoch: 41     train index of 50 minibatch: 8      time used: 50.61486554145813\n","minibatch AVG loss: 1.395311184436432\n","\n","Epoch: 41  train \n","Loss: 1.2268  Acc: 98.4564\n","\n","Epoch: 41, Fix_position_ratio: 0.25, Puzzle_patch_size: 32\n","Negative precision: 98.8372  recall: 98.9224\n","Negative sensitivity: 98.9224  specificity: 97.8226\n","Negative FPR: 2.1774  NPV: 97.9806\n","Negative TP: 2295.0\n","Negative TN: 1213.0\n","Negative FP: 27.0\n","Negative FN: 25.0\n","Positive precision: 97.9806  recall: 97.8226\n","Positive sensitivity: 97.8226  specificity: 98.9224\n","Positive FPR: 1.0776  NPV: 98.8372\n","Positive TP: 1213.0\n","Positive TN: 2295.0\n","Positive FP: 25.0\n","Positive FN: 27.0\n","\n","\n","Epoch: 41     val index of 50 minibatch: 1      time used: 19.423834562301636\n","minibatch AVG loss: 1.7882817678817082\n","\n","Epoch: 41  val \n","Loss: 2.5848  Acc: 91.7485\n","Negative precision: 94.8328  recall: 93.9759\n","Negative sensitivity: 93.9759  specificity: 90.1163\n","Negative FPR: 9.8837  NPV: 88.5714\n","Negative TP: 312.0\n","Negative TN: 155.0\n","Negative FP: 17.0\n","Negative FN: 20.0\n","Positive precision: 88.5714  recall: 90.1163\n","Positive sensitivity: 90.1163  specificity: 93.9759\n","Positive FPR: 6.0241  NPV: 94.8328\n","Positive TP: 155.0\n","Positive TN: 312.0\n","Positive FP: 20.0\n","Positive FN: 17.0\n","\n","\n","\n","Epoch 42/50\n","----------\n","Epoch: 42     train index of 50 minibatch: 1      time used: 51.41133904457092\n","minibatch AVG loss: 1.2311387213537819\n","Epoch: 42     train index of 50 minibatch: 2      time used: 50.677703857421875\n","minibatch AVG loss: 1.432213318576105\n","Epoch: 42     train index of 50 minibatch: 3      time used: 50.55340027809143\n","minibatch AVG loss: 1.1908107840956654\n","Epoch: 42     train index of 50 minibatch: 4      time used: 50.70480537414551\n","minibatch AVG loss: 1.3016314523901382\n","Epoch: 42     train index of 50 minibatch: 5      time used: 50.86804556846619\n","minibatch AVG loss: 1.170392400736164\n","Epoch: 42     train index of 50 minibatch: 6      time used: 50.76863360404968\n","minibatch AVG loss: 1.2643217180401551\n","Epoch: 42     train index of 50 minibatch: 7      time used: 50.608545541763306\n","minibatch AVG loss: 1.4332740427879616\n","Epoch: 42     train index of 50 minibatch: 8      time used: 50.666826248168945\n","minibatch AVG loss: 1.2450764495297335\n","\n","Epoch: 42  train \n","Loss: 1.3017  Acc: 98.0915\n","\n","Epoch: 42, Fix_position_ratio: 0.25, Puzzle_patch_size: 32\n","Negative precision: 98.4516  recall: 98.7489\n","Negative sensitivity: 98.7489  specificity: 97.1014\n","Negative FPR: 2.8986  NPV: 97.6518\n","Negative TP: 2289.0\n","Negative TN: 1206.0\n","Negative FP: 36.0\n","Negative FN: 29.0\n","Positive precision: 97.6518  recall: 97.1014\n","Positive sensitivity: 97.1014  specificity: 98.7489\n","Positive FPR: 1.2511  NPV: 98.4516\n","Positive TP: 1206.0\n","Positive TN: 2289.0\n","Positive FP: 29.0\n","Positive FN: 36.0\n","\n","\n","Epoch: 42     val index of 50 minibatch: 1      time used: 19.21182894706726\n","minibatch AVG loss: 1.2456003971933387\n","\n","Epoch: 42  val \n","Loss: 2.4708  Acc: 91.1591\n","Negative precision: 93.4524  recall: 94.5783\n","Negative sensitivity: 94.5783  specificity: 87.2093\n","Negative FPR: 12.7907  NPV: 89.2857\n","Negative TP: 314.0\n","Negative TN: 150.0\n","Negative FP: 22.0\n","Negative FN: 18.0\n","Positive precision: 89.2857  recall: 87.2093\n","Positive sensitivity: 87.2093  specificity: 94.5783\n","Positive FPR: 5.4217  NPV: 93.4524\n","Positive TP: 150.0\n","Positive TN: 314.0\n","Positive FP: 18.0\n","Positive FN: 22.0\n","\n","\n","\n","Epoch 43/50\n","----------\n","Epoch: 43     train index of 50 minibatch: 1      time used: 51.409255266189575\n","minibatch AVG loss: 1.1679683520935942\n","Epoch: 43     train index of 50 minibatch: 2      time used: 50.64373803138733\n","minibatch AVG loss: 1.2577272306702798\n","Epoch: 43     train index of 50 minibatch: 3      time used: 50.67211413383484\n","minibatch AVG loss: 0.9646158137661405\n","Epoch: 43     train index of 50 minibatch: 4      time used: 50.7842583656311\n","minibatch AVG loss: 1.3946914501552237\n","Epoch: 43     train index of 50 minibatch: 5      time used: 50.67464756965637\n","minibatch AVG loss: 1.068867593134637\n","Epoch: 43     train index of 50 minibatch: 6      time used: 50.65300512313843\n","minibatch AVG loss: 1.1787242393183988\n","Epoch: 43     train index of 50 minibatch: 7      time used: 50.635942459106445\n","minibatch AVG loss: 1.4348474533855915\n","Epoch: 43     train index of 50 minibatch: 8      time used: 50.631277322769165\n","minibatch AVG loss: 1.121825836437638\n","\n","Epoch: 43  train \n","Loss: 1.2256  Acc: 98.2880\n","\n","Epoch: 43, Fix_position_ratio: 0.25, Puzzle_patch_size: 32\n","Negative precision: 98.7075  recall: 98.7926\n","Negative sensitivity: 98.7926  specificity: 97.5826\n","Negative FPR: 2.4174  NPV: 97.7401\n","Negative TP: 2291.0\n","Negative TN: 1211.0\n","Negative FP: 30.0\n","Negative FN: 28.0\n","Positive precision: 97.7401  recall: 97.5826\n","Positive sensitivity: 97.5826  specificity: 98.7926\n","Positive FPR: 1.2074  NPV: 98.7075\n","Positive TP: 1211.0\n","Positive TN: 2291.0\n","Positive FP: 28.0\n","Positive FN: 30.0\n","\n","\n","Epoch: 43     val index of 50 minibatch: 1      time used: 19.360327005386353\n","minibatch AVG loss: 1.5073749835975467\n","\n","Epoch: 43  val \n","Loss: 2.2550  Acc: 90.3733\n","Negative precision: 94.1718  recall: 92.4699\n","Negative sensitivity: 92.4699  specificity: 88.9535\n","Negative FPR: 11.0465  NPV: 85.9551\n","Negative TP: 307.0\n","Negative TN: 153.0\n","Negative FP: 19.0\n","Negative FN: 25.0\n","Positive precision: 85.9551  recall: 88.9535\n","Positive sensitivity: 88.9535  specificity: 92.4699\n","Positive FPR: 7.5301  NPV: 94.1718\n","Positive TP: 153.0\n","Positive TN: 307.0\n","Positive FP: 25.0\n","Positive FN: 19.0\n","\n","\n","\n","Epoch 44/50\n","----------\n","Epoch: 44     train index of 50 minibatch: 1      time used: 51.35483431816101\n","minibatch AVG loss: 1.5117391171219061\n","Epoch: 44     train index of 50 minibatch: 2      time used: 50.80431032180786\n","minibatch AVG loss: 1.061978038160596\n","Epoch: 44     train index of 50 minibatch: 3      time used: 50.44543719291687\n","minibatch AVG loss: 1.06265716697264\n","Epoch: 44     train index of 50 minibatch: 4      time used: 50.60022687911987\n","minibatch AVG loss: 1.3993214631988666\n","Epoch: 44     train index of 50 minibatch: 5      time used: 50.81369686126709\n","minibatch AVG loss: 1.343306392376544\n","Epoch: 44     train index of 50 minibatch: 6      time used: 50.58560919761658\n","minibatch AVG loss: 1.004024473737518\n","Epoch: 44     train index of 50 minibatch: 7      time used: 50.55343270301819\n","minibatch AVG loss: 1.0860703338224267\n","Epoch: 44     train index of 50 minibatch: 8      time used: 50.73824691772461\n","minibatch AVG loss: 1.4573572555929422\n","\n","Epoch: 44  train \n","Loss: 1.1934  Acc: 98.7932\n","\n","Epoch: 44, Fix_position_ratio: 0.25, Puzzle_patch_size: 16\n","Negative precision: 99.1379  recall: 99.1379\n","Negative sensitivity: 99.1379  specificity: 98.3871\n","Negative FPR: 1.6129  NPV: 98.3871\n","Negative TP: 2300.0\n","Negative TN: 1220.0\n","Negative FP: 20.0\n","Negative FN: 20.0\n","Positive precision: 98.3871  recall: 98.3871\n","Positive sensitivity: 98.3871  specificity: 99.1379\n","Positive FPR: 0.8621  NPV: 99.1379\n","Positive TP: 1220.0\n","Positive TN: 2300.0\n","Positive FP: 20.0\n","Positive FN: 20.0\n","\n","\n","Epoch: 44     val index of 50 minibatch: 1      time used: 19.190549612045288\n","minibatch AVG loss: 1.6500045598713768\n","\n","Epoch: 44  val \n","Loss: 2.6284  Acc: 91.5521\n","Negative precision: 94.2771  recall: 94.2771\n","Negative sensitivity: 94.2771  specificity: 88.9535\n","Negative FPR: 11.0465  NPV: 88.9535\n","Negative TP: 313.0\n","Negative TN: 153.0\n","Negative FP: 19.0\n","Negative FN: 19.0\n","Positive precision: 88.9535  recall: 88.9535\n","Positive sensitivity: 88.9535  specificity: 94.2771\n","Positive FPR: 5.7229  NPV: 94.2771\n","Positive TP: 153.0\n","Positive TN: 313.0\n","Positive FP: 19.0\n","Positive FN: 19.0\n","\n","\n","\n","Epoch 45/50\n","----------\n","Epoch: 45     train index of 50 minibatch: 1      time used: 51.346134424209595\n","minibatch AVG loss: 0.7608457035559695\n","Epoch: 45     train index of 50 minibatch: 2      time used: 50.910151720047\n","minibatch AVG loss: 1.1101421384443528\n","Epoch: 45     train index of 50 minibatch: 3      time used: 50.73428702354431\n","minibatch AVG loss: 1.2667238327780797\n","Epoch: 45     train index of 50 minibatch: 4      time used: 50.66732144355774\n","minibatch AVG loss: 1.2694470173011358\n","Epoch: 45     train index of 50 minibatch: 5      time used: 50.73570203781128\n","minibatch AVG loss: 1.1748406988679199\n","Epoch: 45     train index of 50 minibatch: 6      time used: 50.78749656677246\n","minibatch AVG loss: 0.9903607940739312\n","Epoch: 45     train index of 50 minibatch: 7      time used: 50.70382237434387\n","minibatch AVG loss: 0.9963739537147922\n","Epoch: 45     train index of 50 minibatch: 8      time used: 50.61807560920715\n","minibatch AVG loss: 1.3692055991175585\n","\n","Epoch: 45  train \n","Loss: 1.1514  Acc: 98.7932\n","\n","Epoch: 45, Fix_position_ratio: 0.25, Puzzle_patch_size: 16\n","Negative precision: 98.9686  recall: 99.3100\n","Negative sensitivity: 99.3100  specificity: 98.0661\n","Negative FPR: 1.9339  NPV: 98.7024\n","Negative TP: 2303.0\n","Negative TN: 1217.0\n","Negative FP: 24.0\n","Negative FN: 16.0\n","Positive precision: 98.7024  recall: 98.0661\n","Positive sensitivity: 98.0661  specificity: 99.3100\n","Positive FPR: 0.6900  NPV: 98.9686\n","Positive TP: 1217.0\n","Positive TN: 2303.0\n","Positive FP: 16.0\n","Positive FN: 24.0\n","\n","\n","Epoch: 45     val index of 50 minibatch: 1      time used: 19.171121835708618\n","minibatch AVG loss: 2.0824092164748436\n","\n","Epoch: 45  val \n","Loss: 2.9241  Acc: 91.5521\n","Negative precision: 94.5455  recall: 93.9759\n","Negative sensitivity: 93.9759  specificity: 89.5349\n","Negative FPR: 10.4651  NPV: 88.5057\n","Negative TP: 312.0\n","Negative TN: 154.0\n","Negative FP: 18.0\n","Negative FN: 20.0\n","Positive precision: 88.5057  recall: 89.5349\n","Positive sensitivity: 89.5349  specificity: 93.9759\n","Positive FPR: 6.0241  NPV: 94.5455\n","Positive TP: 154.0\n","Positive TN: 312.0\n","Positive FP: 20.0\n","Positive FN: 18.0\n","\n","\n","\n","Epoch 46/50\n","----------\n","Epoch: 46     train index of 50 minibatch: 1      time used: 51.50564527511597\n","minibatch AVG loss: 1.0023774033086374\n","Epoch: 46     train index of 50 minibatch: 2      time used: 50.50875759124756\n","minibatch AVG loss: 1.3364067528911254\n","Epoch: 46     train index of 50 minibatch: 3      time used: 50.90469002723694\n","minibatch AVG loss: 1.5814476287539583\n","Epoch: 46     train index of 50 minibatch: 4      time used: 50.58528184890747\n","minibatch AVG loss: 1.1366859560867306\n","Epoch: 46     train index of 50 minibatch: 5      time used: 50.48105001449585\n","minibatch AVG loss: 0.9474295146687655\n","Epoch: 46     train index of 50 minibatch: 6      time used: 50.92631220817566\n","minibatch AVG loss: 1.2118124060338595\n","Epoch: 46     train index of 50 minibatch: 7      time used: 50.632325649261475\n","minibatch AVG loss: 1.201657779579982\n","Epoch: 46     train index of 50 minibatch: 8      time used: 50.67388415336609\n","minibatch AVG loss: 1.015156401071581\n","\n","Epoch: 46  train \n","Loss: 1.2132  Acc: 98.8212\n","\n","Epoch: 46, Fix_position_ratio: 0.25, Puzzle_patch_size: 16\n","Negative precision: 98.8851  recall: 99.4394\n","Negative sensitivity: 99.4394  specificity: 97.9049\n","Negative FPR: 2.0951  NPV: 98.9414\n","Negative TP: 2306.0\n","Negative TN: 1215.0\n","Negative FP: 26.0\n","Negative FN: 13.0\n","Positive precision: 98.9414  recall: 97.9049\n","Positive sensitivity: 97.9049  specificity: 99.4394\n","Positive FPR: 0.5606  NPV: 98.8851\n","Positive TP: 1215.0\n","Positive TN: 2306.0\n","Positive FP: 13.0\n","Positive FN: 26.0\n","\n","\n","Epoch: 46     val index of 50 minibatch: 1      time used: 19.257391214370728\n","minibatch AVG loss: 1.2184784220019356\n","\n","Epoch: 46  val \n","Loss: 2.2626  Acc: 91.1591\n","Negative precision: 93.1953  recall: 94.8795\n","Negative sensitivity: 94.8795  specificity: 86.6279\n","Negative FPR: 13.3721  NPV: 89.7590\n","Negative TP: 315.0\n","Negative TN: 149.0\n","Negative FP: 23.0\n","Negative FN: 17.0\n","Positive precision: 89.7590  recall: 86.6279\n","Positive sensitivity: 86.6279  specificity: 94.8795\n","Positive FPR: 5.1205  NPV: 93.1953\n","Positive TP: 149.0\n","Positive TN: 315.0\n","Positive FP: 17.0\n","Positive FN: 23.0\n","\n","\n","\n","Epoch 47/50\n","----------\n","Epoch: 47     train index of 50 minibatch: 1      time used: 51.42943549156189\n","minibatch AVG loss: 1.2874094452668214\n","Epoch: 47     train index of 50 minibatch: 2      time used: 50.731552839279175\n","minibatch AVG loss: 1.0396590880176517\n","Epoch: 47     train index of 50 minibatch: 3      time used: 50.9536395072937\n","minibatch AVG loss: 1.146105906123994\n","Epoch: 47     train index of 50 minibatch: 4      time used: 50.5546760559082\n","minibatch AVG loss: 1.3261624343355651\n","Epoch: 47     train index of 50 minibatch: 5      time used: 50.92388463020325\n","minibatch AVG loss: 0.8138786725327373\n","Epoch: 47     train index of 50 minibatch: 6      time used: 50.56838035583496\n","minibatch AVG loss: 0.8961126191643416\n","Epoch: 47     train index of 50 minibatch: 7      time used: 50.48134684562683\n","minibatch AVG loss: 1.1859598631756672\n","Epoch: 47     train index of 50 minibatch: 8      time used: 50.381306648254395\n","minibatch AVG loss: 1.1207401377242059\n","\n","Epoch: 47  train \n","Loss: 1.0977  Acc: 99.2422\n","\n","Epoch: 47, Fix_position_ratio: 0.25, Puzzle_patch_size: 16\n","Negative precision: 99.3546  recall: 99.6117\n","Negative sensitivity: 99.6117  specificity: 98.7923\n","Negative FPR: 1.2077  NPV: 99.2718\n","Negative TP: 2309.0\n","Negative TN: 1227.0\n","Negative FP: 15.0\n","Negative FN: 9.0\n","Positive precision: 99.2718  recall: 98.7923\n","Positive sensitivity: 98.7923  specificity: 99.6117\n","Positive FPR: 0.3883  NPV: 99.3546\n","Positive TP: 1227.0\n","Positive TN: 2309.0\n","Positive FP: 9.0\n","Positive FN: 15.0\n","\n","\n","Epoch: 47     val index of 50 minibatch: 1      time used: 19.062488317489624\n","minibatch AVG loss: 1.3466646759330616\n","\n","Epoch: 47  val \n","Loss: 3.0038  Acc: 91.9450\n","Negative precision: 93.7870  recall: 95.4819\n","Negative sensitivity: 95.4819  specificity: 87.7907\n","Negative FPR: 12.2093  NPV: 90.9639\n","Negative TP: 317.0\n","Negative TN: 151.0\n","Negative FP: 21.0\n","Negative FN: 15.0\n","Positive precision: 90.9639  recall: 87.7907\n","Positive sensitivity: 87.7907  specificity: 95.4819\n","Positive FPR: 4.5181  NPV: 93.7870\n","Positive TP: 151.0\n","Positive TN: 317.0\n","Positive FP: 15.0\n","Positive FN: 21.0\n","\n","\n","\n","Epoch 48/50\n","----------\n","Epoch: 48     train index of 50 minibatch: 1      time used: 50.76463222503662\n","minibatch AVG loss: 1.1676085918022727\n","Epoch: 48     train index of 50 minibatch: 2      time used: 50.29669523239136\n","minibatch AVG loss: 1.3949558468462784\n","Epoch: 48     train index of 50 minibatch: 3      time used: 49.99006247520447\n","minibatch AVG loss: 1.110769966680091\n","Epoch: 48     train index of 50 minibatch: 4      time used: 51.090232610702515\n","minibatch AVG loss: 1.1220009538775775\n","Epoch: 48     train index of 50 minibatch: 5      time used: 50.55596303939819\n","minibatch AVG loss: 1.0620490302226973\n","Epoch: 48     train index of 50 minibatch: 6      time used: 50.70570707321167\n","minibatch AVG loss: 1.2099393556662834\n","Epoch: 48     train index of 50 minibatch: 7      time used: 50.86947274208069\n","minibatch AVG loss: 0.9328090179455466\n","Epoch: 48     train index of 50 minibatch: 8      time used: 50.539528131484985\n","minibatch AVG loss: 1.1854970362473978\n","\n","Epoch: 48  train \n","Loss: 1.1688  Acc: 98.7651\n","\n","Epoch: 48, Fix_position_ratio: 0.25, Puzzle_patch_size: 16\n","Negative precision: 98.9257  recall: 99.3097\n","Negative sensitivity: 99.3097  specificity: 97.9871\n","Negative FPR: 2.0129  NPV: 98.7024\n","Negative TP: 2302.0\n","Negative TN: 1217.0\n","Negative FP: 25.0\n","Negative FN: 16.0\n","Positive precision: 98.7024  recall: 97.9871\n","Positive sensitivity: 97.9871  specificity: 99.3097\n","Positive FPR: 0.6903  NPV: 98.9257\n","Positive TP: 1217.0\n","Positive TN: 2302.0\n","Positive FP: 16.0\n","Positive FN: 25.0\n","\n","\n","Epoch: 48     val index of 50 minibatch: 1      time used: 19.17984700202942\n","minibatch AVG loss: 1.7119313614303246\n","\n","Epoch: 48  val \n","Loss: 2.4230  Acc: 90.3733\n","Negative precision: 93.9024  recall: 92.7711\n","Negative sensitivity: 92.7711  specificity: 88.3721\n","Negative FPR: 11.6279  NPV: 86.3636\n","Negative TP: 308.0\n","Negative TN: 152.0\n","Negative FP: 20.0\n","Negative FN: 24.0\n","Positive precision: 86.3636  recall: 88.3721\n","Positive sensitivity: 88.3721  specificity: 92.7711\n","Positive FPR: 7.2289  NPV: 93.9024\n","Positive TP: 152.0\n","Positive TN: 308.0\n","Positive FP: 24.0\n","Positive FN: 20.0\n","\n","\n","\n","Epoch 49/50\n","----------\n","Epoch: 49     train index of 50 minibatch: 1      time used: 51.00017523765564\n","minibatch AVG loss: 1.2414347299809014\n","Epoch: 49     train index of 50 minibatch: 2      time used: 50.38045310974121\n","minibatch AVG loss: 1.2635771530569764\n","Epoch: 49     train index of 50 minibatch: 3      time used: 50.44844651222229\n","minibatch AVG loss: 0.8829093714634655\n","Epoch: 49     train index of 50 minibatch: 4      time used: 50.8961923122406\n","minibatch AVG loss: 1.3833531226553897\n","Epoch: 49     train index of 50 minibatch: 5      time used: 50.58358287811279\n","minibatch AVG loss: 1.2271275021322072\n","Epoch: 49     train index of 50 minibatch: 6      time used: 50.73688268661499\n","minibatch AVG loss: 0.9393903343734564\n","Epoch: 49     train index of 50 minibatch: 7      time used: 50.721413373947144\n","minibatch AVG loss: 1.1867588570562657\n","Epoch: 49     train index of 50 minibatch: 8      time used: 50.75823998451233\n","minibatch AVG loss: 1.0486857761006103\n","\n","Epoch: 49  train \n","Loss: 1.1561  Acc: 98.9054\n","\n","Epoch: 49, Fix_position_ratio: 0.25, Puzzle_patch_size: 16\n","Negative precision: 99.1390  recall: 99.3100\n","Negative sensitivity: 99.3100  specificity: 98.3884\n","Negative FPR: 1.6116  NPV: 98.7065\n","Negative TP: 2303.0\n","Negative TN: 1221.0\n","Negative FP: 20.0\n","Negative FN: 16.0\n","Positive precision: 98.7065  recall: 98.3884\n","Positive sensitivity: 98.3884  specificity: 99.3100\n","Positive FPR: 0.6900  NPV: 99.1390\n","Positive TP: 1221.0\n","Positive TN: 2303.0\n","Positive FP: 16.0\n","Positive FN: 20.0\n","\n","\n","Epoch: 49     val index of 50 minibatch: 1      time used: 19.293535232543945\n","minibatch AVG loss: 1.5393077701213769\n","\n","Epoch: 49  val \n","Loss: 2.7372  Acc: 90.7662\n","Negative precision: 93.4132  recall: 93.9759\n","Negative sensitivity: 93.9759  specificity: 87.2093\n","Negative FPR: 12.7907  NPV: 88.2353\n","Negative TP: 312.0\n","Negative TN: 150.0\n","Negative FP: 22.0\n","Negative FN: 20.0\n","Positive precision: 88.2353  recall: 87.2093\n","Positive sensitivity: 87.2093  specificity: 93.9759\n","Positive FPR: 6.0241  NPV: 93.4132\n","Positive TP: 150.0\n","Positive TN: 312.0\n","Positive FP: 20.0\n","Positive FN: 22.0\n","\n","\n","\n","Epoch 50/50\n","----------\n","Epoch: 50     train index of 50 minibatch: 1      time used: 51.31463885307312\n","minibatch AVG loss: 1.0631818605439185\n","Epoch: 50     train index of 50 minibatch: 2      time used: 50.53064584732056\n","minibatch AVG loss: 1.2905708435256384\n","Epoch: 50     train index of 50 minibatch: 3      time used: 50.902414083480835\n","minibatch AVG loss: 1.0076191103860037\n","Epoch: 50     train index of 50 minibatch: 4      time used: 50.61581516265869\n","minibatch AVG loss: 1.011322858978092\n","Epoch: 50     train index of 50 minibatch: 5      time used: 50.535457611083984\n","minibatch AVG loss: 1.136011060255114\n","Epoch: 50     train index of 50 minibatch: 6      time used: 50.79529333114624\n","minibatch AVG loss: 1.3296026766960858\n","Epoch: 50     train index of 50 minibatch: 7      time used: 50.53225517272949\n","minibatch AVG loss: 0.9620674602054351\n","Epoch: 50     train index of 50 minibatch: 8      time used: 50.738929271698\n","minibatch AVG loss: 0.9602087258978281\n","\n","Epoch: 50  train \n","Loss: 1.1313  Acc: 98.9054\n","\n","Epoch: 50, Fix_position_ratio: 0.25, Puzzle_patch_size: 16\n","Negative precision: 99.0964  recall: 99.3529\n","Negative sensitivity: 99.3529  specificity: 98.3092\n","Negative FPR: 1.6908  NPV: 98.7864\n","Negative TP: 2303.0\n","Negative TN: 1221.0\n","Negative FP: 21.0\n","Negative FN: 15.0\n","Positive precision: 98.7864  recall: 98.3092\n","Positive sensitivity: 98.3092  specificity: 99.3529\n","Positive FPR: 0.6471  NPV: 99.0964\n","Positive TP: 1221.0\n","Positive TN: 2303.0\n","Positive FP: 15.0\n","Positive FN: 21.0\n","\n","\n","Epoch: 50     val index of 50 minibatch: 1      time used: 19.213886260986328\n","minibatch AVG loss: 1.1918853623566248\n","\n","Epoch: 50  val \n","Loss: 3.2047  Acc: 91.7485\n","Negative precision: 93.5103  recall: 95.4819\n","Negative sensitivity: 95.4819  specificity: 87.2093\n","Negative FPR: 12.7907  NPV: 90.9091\n","Negative TP: 317.0\n","Negative TN: 150.0\n","Negative FP: 22.0\n","Negative FN: 15.0\n","Positive precision: 90.9091  recall: 87.2093\n","Positive sensitivity: 87.2093  specificity: 95.4819\n","Positive FPR: 4.5181  NPV: 93.5103\n","Positive TP: 150.0\n","Positive TN: 317.0\n","Positive FP: 15.0\n","Positive FN: 22.0\n","\n","\n","\n","Training complete in 396m 42s\n","Best epoch idx:  26\n","Best epoch train Acc: 91.383665\n","Best epoch val Acc: 93.320236\n","Negative precision: 94.6903  recall: 96.6867\n","Negative sensitivity: 96.6867  specificity: 89.5349\n","Negative FPR: 10.4651  NPV: 93.3333\n","Positive precision: 93.3333  recall: 89.5349\n","Positive sensitivity: 89.5349  specificity: 96.6867\n","Positive FPR: 3.3133  NPV: 94.6903\n","model trained by GPU (idx:0) has been saved at  /home/Pathology_Experiment/saved_models/CLS_ViT_384_401_PT_lf25_b8_ROSE_CellMix_Group_CLS.pth\n"]}],"source":["!python Train.py --model_idx ViT_384_401_PT_lf25_b8_ROSE_CellMix_Group_CLS --augmentation_name CellMix-Group --patch_strategy loss_hold --ratio_strategy loss_hold --enable_tensorboard --edge_size 384 --data_augmentation_mode 0 --lr 0.00001 --lrf 0.25 --dataroot /data/Pathology_Experiment/dataset/ROSE_CLS --model_path /home/Pathology_Experiment/saved_models --draw_root /home/Pathology_Experiment/runs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"dar2Vtms2H4-","outputId":"be32001d-56e4-4263-cb6e-52885ba19ad3"},"outputs":[{"name":"stdout","output_type":"stream","text":["class_names: ['Negative', 'Positive']\n","['convit_base',\n"," 'convit_small',\n"," 'convit_tiny',\n"," 'crossvit_9_240',\n"," 'crossvit_9_dagger_240',\n"," 'crossvit_15_240',\n"," 'crossvit_15_dagger_240',\n"," 'crossvit_15_dagger_408',\n"," 'crossvit_18_240',\n"," 'crossvit_18_dagger_240',\n"," 'crossvit_18_dagger_408',\n"," 'crossvit_base_240',\n"," 'crossvit_small_240',\n"," 'crossvit_tiny_240',\n"," 'gcvit_base',\n"," 'gcvit_small',\n"," 'gcvit_tiny',\n"," 'gcvit_xtiny',\n"," 'gcvit_xxtiny',\n"," 'levit_128',\n"," 'levit_128s',\n"," 'levit_192',\n"," 'levit_256',\n"," 'levit_256d',\n"," 'levit_384',\n"," 'maxvit_base_224',\n"," 'maxvit_large_224',\n"," 'maxvit_nano_rw_256',\n"," 'maxvit_pico_rw_256',\n"," 'maxvit_rmlp_nano_rw_256',\n"," 'maxvit_rmlp_pico_rw_256',\n"," 'maxvit_rmlp_small_rw_224',\n"," 'maxvit_rmlp_small_rw_256',\n"," 'maxvit_rmlp_tiny_rw_256',\n"," 'maxvit_small_224',\n"," 'maxvit_tiny_224',\n"," 'maxvit_tiny_pm_256',\n"," 'maxvit_tiny_rw_224',\n"," 'maxvit_tiny_rw_256',\n"," 'maxvit_xlarge_224',\n"," 'maxxvit_rmlp_nano_rw_256',\n"," 'maxxvit_rmlp_small_rw_256',\n"," 'maxxvit_rmlp_tiny_rw_256',\n"," 'mobilevit_s',\n"," 'mobilevit_xs',\n"," 'mobilevit_xxs',\n"," 'mobilevitv2_050',\n"," 'mobilevitv2_075',\n"," 'mobilevitv2_100',\n"," 'mobilevitv2_125',\n"," 'mobilevitv2_150',\n"," 'mobilevitv2_150_384_in22ft1k',\n"," 'mobilevitv2_150_in22ft1k',\n"," 'mobilevitv2_175',\n"," 'mobilevitv2_175_384_in22ft1k',\n"," 'mobilevitv2_175_in22ft1k',\n"," 'mobilevitv2_200',\n"," 'mobilevitv2_200_384_in22ft1k',\n"," 'mobilevitv2_200_in22ft1k',\n"," 'mvitv2_base',\n"," 'mvitv2_large',\n"," 'mvitv2_small',\n"," 'mvitv2_small_cls',\n"," 'mvitv2_tiny',\n"," 'semobilevit_s',\n"," 'vit_base_patch8_224',\n"," 'vit_base_patch8_224_dino',\n"," 'vit_base_patch8_224_in21k',\n"," 'vit_base_patch16_18x2_224',\n"," 'vit_base_patch16_224',\n"," 'vit_base_patch16_224_dino',\n"," 'vit_base_patch16_224_in21k',\n"," 'vit_base_patch16_224_miil',\n"," 'vit_base_patch16_224_miil_in21k',\n"," 'vit_base_patch16_224_sam',\n"," 'vit_base_patch16_384',\n"," 'vit_base_patch16_plus_240',\n"," 'vit_base_patch16_rpn_224',\n"," 'vit_base_patch32_224',\n"," 'vit_base_patch32_224_clip_laion2b',\n"," 'vit_base_patch32_224_in21k',\n"," 'vit_base_patch32_224_sam',\n"," 'vit_base_patch32_384',\n"," 'vit_base_patch32_plus_256',\n"," 'vit_base_r26_s32_224',\n"," 'vit_base_r50_s16_224',\n"," 'vit_base_r50_s16_224_in21k',\n"," 'vit_base_r50_s16_384',\n"," 'vit_base_resnet26d_224',\n"," 'vit_base_resnet50_224_in21k',\n"," 'vit_base_resnet50_384',\n"," 'vit_base_resnet50d_224',\n"," 'vit_giant_patch14_224',\n"," 'vit_giant_patch14_224_clip_laion2b',\n"," 'vit_gigantic_patch14_224',\n"," 'vit_huge_patch14_224',\n"," 'vit_huge_patch14_224_clip_laion2b',\n"," 'vit_huge_patch14_224_in21k',\n"," 'vit_large_patch14_224',\n"," 'vit_large_patch14_224_clip_laion2b',\n"," 'vit_large_patch16_224',\n"," 'vit_large_patch16_224_in21k',\n"," 'vit_large_patch16_384',\n"," 'vit_large_patch32_224',\n"," 'vit_large_patch32_224_in21k',\n"," 'vit_large_patch32_384',\n"," 'vit_large_r50_s32_224',\n"," 'vit_large_r50_s32_224_in21k',\n"," 'vit_large_r50_s32_384',\n"," 'vit_relpos_base_patch16_224',\n"," 'vit_relpos_base_patch16_cls_224',\n"," 'vit_relpos_base_patch16_clsgap_224',\n"," 'vit_relpos_base_patch16_plus_240',\n"," 'vit_relpos_base_patch16_rpn_224',\n"," 'vit_relpos_base_patch32_plus_rpn_256',\n"," 'vit_relpos_medium_patch16_224',\n"," 'vit_relpos_medium_patch16_cls_224',\n"," 'vit_relpos_medium_patch16_rpn_224',\n"," 'vit_relpos_small_patch16_224',\n"," 'vit_relpos_small_patch16_rpn_224',\n"," 'vit_small_patch8_224_dino',\n"," 'vit_small_patch16_18x2_224',\n"," 'vit_small_patch16_36x1_224',\n"," 'vit_small_patch16_224',\n"," 'vit_small_patch16_224_dino',\n"," 'vit_small_patch16_224_in21k',\n"," 'vit_small_patch16_384',\n"," 'vit_small_patch32_224',\n"," 'vit_small_patch32_224_in21k',\n"," 'vit_small_patch32_384',\n"," 'vit_small_r26_s32_224',\n"," 'vit_small_r26_s32_224_in21k',\n"," 'vit_small_r26_s32_384',\n"," 'vit_small_resnet26d_224',\n"," 'vit_small_resnet50d_s16_224',\n"," 'vit_srelpos_medium_patch16_224',\n"," 'vit_srelpos_small_patch16_224',\n"," 'vit_tiny_patch16_224',\n"," 'vit_tiny_patch16_224_in21k',\n"," 'vit_tiny_patch16_384',\n"," 'vit_tiny_r_s16_p8_224',\n"," 'vit_tiny_r_s16_p8_224_in21k',\n"," 'vit_tiny_r_s16_p8_384']\n","test model output： tensor([[0.6112, 1.0066]], grad_fn=<AddmmBackward0>)\n","model is ready now!\n","model loaded\n","model : ViT_384_401_PT_lf25_b8_ROSE_CellMix_Group_CLS\n","*********************************setting*************************************\n","Namespace(Pre_Trained_model_path=None, PromptTuning=None, PromptUnFreeze=False, Prompt_Token_num=20, att_module='SimAM', attn_drop_rate=0.0, batch_size=1, check_minibatch=None, cls_token_off=False, data_augmentation_mode=0, dataroot='/data/Pathology_Experiment/dataset/ROSE_CLS', draw_root='/home/Pathology_Experiment/runs', drop_path_rate=0.0, drop_rate=0.0, edge_size=384, enable_attention_check=True, enable_notify=False, enable_tensorboard=False, enable_visualize_check=False, gpu_idx=0, model_idx='ViT_384_401_PT_lf25_b8_ROSE_CellMix_Group_CLS', model_path='/home/Pathology_Experiment/saved_models', model_path_by_hand=None, num_classes=0, paint=True, pos_embedding_off=False)\n","Epoch: Test\n","----------\n","Epoch: test     test index of 50 minibatch: 1      time used: 2.4498026371002197\n","minibatch AVG loss: 0.10132327654894255\n","/home/Pathology_Experiment/code/utils/visual_usage.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  return sof(x)\n","Epoch: test     test index of 50 minibatch: 2      time used: 2.283017158508301\n","minibatch AVG loss: 0.014440536737416777\n","Epoch: test     test index of 50 minibatch: 3      time used: 2.312039375305176\n","minibatch AVG loss: 0.02750119430647416\n","Epoch: test     test index of 50 minibatch: 4      time used: 2.3575520515441895\n","minibatch AVG loss: 0.006932987944679923\n","Epoch: test     test index of 50 minibatch: 5      time used: 2.375516176223755\n","minibatch AVG loss: 0.00293071386760289\n","Epoch: test     test index of 50 minibatch: 6      time used: 2.409331798553467\n","minibatch AVG loss: 0.022552871149351575\n","Epoch: test     test index of 50 minibatch: 7      time used: 2.435734272003174\n","minibatch AVG loss: 0.0089617076322088\n","Epoch: test     test index of 50 minibatch: 8      time used: 2.465919017791748\n","minibatch AVG loss: 0.2534850567838264\n","Epoch: test     test index of 50 minibatch: 9      time used: 2.4829559326171875\n","minibatch AVG loss: 0.005483666921271606\n","Epoch: test     test index of 50 minibatch: 10      time used: 2.4767603874206543\n","minibatch AVG loss: 0.1205746545063704\n","Epoch: test     test index of 50 minibatch: 11      time used: 2.4645442962646484\n","minibatch AVG loss: 0.41479935630839465\n","Epoch: test     test index of 50 minibatch: 12      time used: 2.428060531616211\n","minibatch AVG loss: 0.1820563829112642\n","Epoch: test     test index of 50 minibatch: 13      time used: 2.3980374336242676\n","minibatch AVG loss: 0.08101703966089957\n","Epoch: test     test index of 50 minibatch: 14      time used: 2.3780953884124756\n","minibatch AVG loss: 0.33669396879413055\n","Epoch: test     test index of 50 minibatch: 15      time used: 2.3681225776672363\n","minibatch AVG loss: 0.15940625292620098\n","Epoch: test     test index of 50 minibatch: 16      time used: 2.3589026927948\n","minibatch AVG loss: 0.21212149207365655\n","Epoch: test     test index of 50 minibatch: 17      time used: 2.3207030296325684\n","minibatch AVG loss: 0.8718600633782626\n","Epoch: test     test index of 50 minibatch: 18      time used: 2.3346621990203857\n","minibatch AVG loss: 0.5010196139828713\n","Epoch: test     test index of 50 minibatch: 19      time used: 2.3229613304138184\n","minibatch AVG loss: 0.8148550533809794\n","Epoch: test     test index of 50 minibatch: 20      time used: 2.339517831802368\n","minibatch AVG loss: 0.11643636667533429\n","\n","Epoch:  test \n","Loss: 0.2112  Acc: 93.3071\n","Negative precision: 93.5484  recall: 96.3746\n","Negative sensitivity: 96.3746  specificity: 87.5706\n","Negative FPR: 12.4294  NPV: 92.8144\n","Negative TP: 638.0\n","Negative TN: 310.0\n","Negative FP: 44.0\n","Negative FN: 24.0\n","Positive precision: 92.8144  recall: 87.5706\n","Positive sensitivity: 87.5706  specificity: 96.3746\n","Positive FPR: 3.6254  NPV: 93.5484\n","Positive TP: 310.0\n","Positive TN: 638.0\n","Positive FP: 24.0\n","Positive FN: 44.0\n","\n","\n","Testing complete in 1m 20s\n"]}],"source":["!python Test.py --model_idx ViT_384_401_PT_lf25_b8_ROSE_CellMix_Group_CLS --enable_attention_check --edge_size 384 --data_augmentation_mode 0 --dataroot /data/Pathology_Experiment/dataset/ROSE_CLS --model_path /home/Pathology_Experiment/saved_models --draw_root /home/Pathology_Experiment/runs"]},{"cell_type":"markdown","metadata":{"id":"8BlOMfZ_3ROk"},"source":["# visulizations"]},{"cell_type":"markdown","metadata":{"id":"6gHOMtB4af5R"},"source":["check cam on shuffled samples, from patch size 16 to 192. the fixposition ratio is 0.5\n","\n","--fix_position_ratio 0.5 stands for using 50% of patches fixed, the remaining shuffled\n","\n","--puzzle_patch_size 16 stands for using the patch size of 16\n","\n","--batch_size 4 stands for using the batch size of 4 images\n","\n","--enable_attention_check stands for using Grad-CAM to visulize the attention\n","\n","--shuffle_dataloader stands for using the shuffled test dataloader instead of test dataloader with same image taking order\n","\n","--draw_root the output path to store the images "]},{"cell_type":"markdown","metadata":{"id":"43WA9MN_W5Rj"},"source":["## ViT"]},{"cell_type":"markdown","source":["--fix_position_ratio 0.5 --puzzle_patch_size 16 --batch_size 4 --enable_attention_check --shuffle_dataloader"],"metadata":{"id":"GFCXMCP18oPk"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":222747,"status":"ok","timestamp":1670906424624,"user":{"displayName":"Rush MSHT","userId":"17678018738220178064"},"user_tz":-480},"id":"ts4x-ue23Tty","outputId":"4f099a31-f6c7-4354-e9c5-2be0b0516cd2"},"outputs":[{"name":"stdout","output_type":"stream","text":["class_names: ['Negative', 'Positive']\n","['convit_base',\n"," 'convit_small',\n"," 'convit_tiny',\n"," 'crossvit_9_240',\n"," 'crossvit_9_dagger_240',\n"," 'crossvit_15_240',\n"," 'crossvit_15_dagger_240',\n"," 'crossvit_15_dagger_408',\n"," 'crossvit_18_240',\n"," 'crossvit_18_dagger_240',\n"," 'crossvit_18_dagger_408',\n"," 'crossvit_base_240',\n"," 'crossvit_small_240',\n"," 'crossvit_tiny_240',\n"," 'gcvit_base',\n"," 'gcvit_small',\n"," 'gcvit_tiny',\n"," 'gcvit_xtiny',\n"," 'gcvit_xxtiny',\n"," 'levit_128',\n"," 'levit_128s',\n"," 'levit_192',\n"," 'levit_256',\n"," 'levit_256d',\n"," 'levit_384',\n"," 'maxvit_base_224',\n"," 'maxvit_large_224',\n"," 'maxvit_nano_rw_256',\n"," 'maxvit_pico_rw_256',\n"," 'maxvit_rmlp_nano_rw_256',\n"," 'maxvit_rmlp_pico_rw_256',\n"," 'maxvit_rmlp_small_rw_224',\n"," 'maxvit_rmlp_small_rw_256',\n"," 'maxvit_rmlp_tiny_rw_256',\n"," 'maxvit_small_224',\n"," 'maxvit_tiny_224',\n"," 'maxvit_tiny_pm_256',\n"," 'maxvit_tiny_rw_224',\n"," 'maxvit_tiny_rw_256',\n"," 'maxvit_xlarge_224',\n"," 'maxxvit_rmlp_nano_rw_256',\n"," 'maxxvit_rmlp_small_rw_256',\n"," 'maxxvit_rmlp_tiny_rw_256',\n"," 'mobilevit_s',\n"," 'mobilevit_xs',\n"," 'mobilevit_xxs',\n"," 'mobilevitv2_050',\n"," 'mobilevitv2_075',\n"," 'mobilevitv2_100',\n"," 'mobilevitv2_125',\n"," 'mobilevitv2_150',\n"," 'mobilevitv2_150_384_in22ft1k',\n"," 'mobilevitv2_150_in22ft1k',\n"," 'mobilevitv2_175',\n"," 'mobilevitv2_175_384_in22ft1k',\n"," 'mobilevitv2_175_in22ft1k',\n"," 'mobilevitv2_200',\n"," 'mobilevitv2_200_384_in22ft1k',\n"," 'mobilevitv2_200_in22ft1k',\n"," 'mvitv2_base',\n"," 'mvitv2_large',\n"," 'mvitv2_small',\n"," 'mvitv2_small_cls',\n"," 'mvitv2_tiny',\n"," 'semobilevit_s',\n"," 'vit_base_patch8_224',\n"," 'vit_base_patch8_224_dino',\n"," 'vit_base_patch8_224_in21k',\n"," 'vit_base_patch16_18x2_224',\n"," 'vit_base_patch16_224',\n"," 'vit_base_patch16_224_dino',\n"," 'vit_base_patch16_224_in21k',\n"," 'vit_base_patch16_224_miil',\n"," 'vit_base_patch16_224_miil_in21k',\n"," 'vit_base_patch16_224_sam',\n"," 'vit_base_patch16_384',\n"," 'vit_base_patch16_plus_240',\n"," 'vit_base_patch16_rpn_224',\n"," 'vit_base_patch32_224',\n"," 'vit_base_patch32_224_clip_laion2b',\n"," 'vit_base_patch32_224_in21k',\n"," 'vit_base_patch32_224_sam',\n"," 'vit_base_patch32_384',\n"," 'vit_base_patch32_plus_256',\n"," 'vit_base_r26_s32_224',\n"," 'vit_base_r50_s16_224',\n"," 'vit_base_r50_s16_224_in21k',\n"," 'vit_base_r50_s16_384',\n"," 'vit_base_resnet26d_224',\n"," 'vit_base_resnet50_224_in21k',\n"," 'vit_base_resnet50_384',\n"," 'vit_base_resnet50d_224',\n"," 'vit_giant_patch14_224',\n"," 'vit_giant_patch14_224_clip_laion2b',\n"," 'vit_gigantic_patch14_224',\n"," 'vit_huge_patch14_224',\n"," 'vit_huge_patch14_224_clip_laion2b',\n"," 'vit_huge_patch14_224_in21k',\n"," 'vit_large_patch14_224',\n"," 'vit_large_patch14_224_clip_laion2b',\n"," 'vit_large_patch16_224',\n"," 'vit_large_patch16_224_in21k',\n"," 'vit_large_patch16_384',\n"," 'vit_large_patch32_224',\n"," 'vit_large_patch32_224_in21k',\n"," 'vit_large_patch32_384',\n"," 'vit_large_r50_s32_224',\n"," 'vit_large_r50_s32_224_in21k',\n"," 'vit_large_r50_s32_384',\n"," 'vit_relpos_base_patch16_224',\n"," 'vit_relpos_base_patch16_cls_224',\n"," 'vit_relpos_base_patch16_clsgap_224',\n"," 'vit_relpos_base_patch16_plus_240',\n"," 'vit_relpos_base_patch16_rpn_224',\n"," 'vit_relpos_base_patch32_plus_rpn_256',\n"," 'vit_relpos_medium_patch16_224',\n"," 'vit_relpos_medium_patch16_cls_224',\n"," 'vit_relpos_medium_patch16_rpn_224',\n"," 'vit_relpos_small_patch16_224',\n"," 'vit_relpos_small_patch16_rpn_224',\n"," 'vit_small_patch8_224_dino',\n"," 'vit_small_patch16_18x2_224',\n"," 'vit_small_patch16_36x1_224',\n"," 'vit_small_patch16_224',\n"," 'vit_small_patch16_224_dino',\n"," 'vit_small_patch16_224_in21k',\n"," 'vit_small_patch16_384',\n"," 'vit_small_patch32_224',\n"," 'vit_small_patch32_224_in21k',\n"," 'vit_small_patch32_384',\n"," 'vit_small_r26_s32_224',\n"," 'vit_small_r26_s32_224_in21k',\n"," 'vit_small_r26_s32_384',\n"," 'vit_small_resnet26d_224',\n"," 'vit_small_resnet50d_s16_224',\n"," 'vit_srelpos_medium_patch16_224',\n"," 'vit_srelpos_small_patch16_224',\n"," 'vit_tiny_patch16_224',\n"," 'vit_tiny_patch16_224_in21k',\n"," 'vit_tiny_patch16_384',\n"," 'vit_tiny_r_s16_p8_224',\n"," 'vit_tiny_r_s16_p8_224_in21k',\n"," 'vit_tiny_r_s16_p8_384']\n","test model output： tensor([[0.1346, 0.2750]], grad_fn=<AddmmBackward0>)\n","model is ready now!\n","model loaded\n","model : ViT_384_401_PT_lf25_b8_ROSE_CLS\n","*********************************setting*************************************\n","Namespace(Pre_Trained_model_path=None, PromptTuning=None, PromptUnFreeze=False, Prompt_Token_num=10, att_module='SimAM', attn_drop_rate=0.0, augmentation_name='CellMix-Group', batch_size=4, check_minibatch=None, cls_token_off=False, data_augmentation_mode=0, dataroot='/data/Pathology_Experiment/dataset/ROSE_CLS', draw_root='/home/Pathology_Experiment/imaging_results', drop_path_rate=0.0, drop_rate=0.0, edge_size=384, enable_attention_check=True, enable_notify=False, enable_tensorboard=False, enable_visualize_check=True, fix_position_ratio=0.5, gpu_idx=0, model_idx='ViT_384_401_PT_lf25_b8_ROSE_CLS', model_path='/home/Pathology_Experiment/saved_models', model_path_by_hand=None, num_classes=0, paint=True, pos_embedding_off=False, puzzle_patch_size=16, shuffle_dataloader=True)\n","Epoch: Test\n","\n","useing  CellMix-Group \n","\n","----------\n","Epoch: test     test index of 12 minibatch: 1      time used: 2.173732042312622\n","minibatch AVG loss: 0.10095895839428219\n","/home/Pathology_Experiment/code/utils/visual_usage.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  return sof(x)\n","Epoch: test     test index of 12 minibatch: 2      time used: 1.9129743576049805\n","minibatch AVG loss: 0.5227400246658362\n","Epoch: test     test index of 12 minibatch: 3      time used: 1.904266595840454\n","minibatch AVG loss: 0.6402737141349159\n","Epoch: test     test index of 12 minibatch: 4      time used: 1.9336657524108887\n","minibatch AVG loss: 0.22796573498635553\n","Epoch: test     test index of 12 minibatch: 5      time used: 1.9433348178863525\n","minibatch AVG loss: 0.25045292063926655\n","Epoch: test     test index of 12 minibatch: 6      time used: 1.966949224472046\n","minibatch AVG loss: 0.40121959351624054\n","Epoch: test     test index of 12 minibatch: 7      time used: 1.974672555923462\n","minibatch AVG loss: 0.10792955060120828\n","Epoch: test     test index of 12 minibatch: 8      time used: 1.9873361587524414\n","minibatch AVG loss: 0.21031249617226422\n","Epoch: test     test index of 12 minibatch: 9      time used: 2.0064120292663574\n","minibatch AVG loss: 0.3289572678040713\n","Epoch: test     test index of 12 minibatch: 10      time used: 2.0070273876190186\n","minibatch AVG loss: 0.10323853466737394\n","Epoch: test     test index of 12 minibatch: 11      time used: 2.0118024349212646\n","minibatch AVG loss: 0.19763181632273094\n","Epoch: test     test index of 12 minibatch: 12      time used: 2.030963659286499\n","minibatch AVG loss: 0.3217632390054253\n","Epoch: test     test index of 12 minibatch: 13      time used: 2.0665488243103027\n","minibatch AVG loss: 0.21779309737030417\n","Epoch: test     test index of 12 minibatch: 14      time used: 2.10323166847229\n","minibatch AVG loss: 0.19210775469158156\n","Epoch: test     test index of 12 minibatch: 15      time used: 2.1368696689605713\n","minibatch AVG loss: 0.20879621134372428\n","Epoch: test     test index of 12 minibatch: 16      time used: 2.179636001586914\n","minibatch AVG loss: 0.17760690161958337\n","Epoch: test     test index of 12 minibatch: 17      time used: 2.2143232822418213\n","minibatch AVG loss: 0.28505344115546905\n","Epoch: test     test index of 12 minibatch: 18      time used: 2.2079176902770996\n","minibatch AVG loss: 0.1278369447294002\n","Epoch: test     test index of 12 minibatch: 19      time used: 2.264630079269409\n","minibatch AVG loss: 0.25933648612893495\n","Epoch: test     test index of 12 minibatch: 20      time used: 2.314201593399048\n","minibatch AVG loss: 0.07252912996530843\n","Epoch: test     test index of 12 minibatch: 21      time used: 2.366443157196045\n","minibatch AVG loss: 0.22887962736422196\n","\n","Epoch:  test \n","Loss: 0.2456  Acc: 91.2402\n","Negative precision: 91.1047  recall: 95.9215\n","Negative sensitivity: 95.9215  specificity: 82.4859\n","Negative FPR: 17.5141  NPV: 91.5361\n","Negative TP: 635.0\n","Negative TN: 292.0\n","Negative FP: 62.0\n","Negative FN: 27.0\n","Positive precision: 91.5361  recall: 82.4859\n","Positive sensitivity: 82.4859  specificity: 95.9215\n","Positive FPR: 4.0785  NPV: 91.1047\n","Positive TP: 292.0\n","Positive TN: 635.0\n","Positive FP: 27.0\n","Positive FN: 62.0\n","\n","\n","Testing complete in 3m 33s\n"]}],"source":["!python CellMix_test.py --model_idx ViT_384_401_PT_lf25_b8_ROSE_CLS --gpu_idx 0 --enable_visualize_check --edge_size 384 --data_augmentation_mode 0 --augmentation_name CellMix-Group --fix_position_ratio 0.5 --puzzle_patch_size 16 --batch_size 4 --enable_attention_check --shuffle_dataloader --dataroot /data/Pathology_Experiment/dataset/ROSE_CLS --model_path /home/Pathology_Experiment/saved_models --draw_root /home/Pathology_Experiment/imaging_results"]},{"cell_type":"markdown","source":["--fix_position_ratio 0.5 --puzzle_patch_size 32 --batch_size 4 --enable_attention_check --shuffle_dataloader"],"metadata":{"id":"kWiNnIFg8tmy"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"6xxvfTS9Yxb3","outputId":"feb0b5e2-1379-46a4-9d00-7c69d9e49133"},"outputs":[{"name":"stdout","output_type":"stream","text":["class_names: ['Negative', 'Positive']\n","['convit_base',\n"," 'convit_small',\n"," 'convit_tiny',\n"," 'crossvit_9_240',\n"," 'crossvit_9_dagger_240',\n"," 'crossvit_15_240',\n"," 'crossvit_15_dagger_240',\n"," 'crossvit_15_dagger_408',\n"," 'crossvit_18_240',\n"," 'crossvit_18_dagger_240',\n"," 'crossvit_18_dagger_408',\n"," 'crossvit_base_240',\n"," 'crossvit_small_240',\n"," 'crossvit_tiny_240',\n"," 'gcvit_base',\n"," 'gcvit_small',\n"," 'gcvit_tiny',\n"," 'gcvit_xtiny',\n"," 'gcvit_xxtiny',\n"," 'levit_128',\n"," 'levit_128s',\n"," 'levit_192',\n"," 'levit_256',\n"," 'levit_256d',\n"," 'levit_384',\n"," 'maxvit_base_224',\n"," 'maxvit_large_224',\n"," 'maxvit_nano_rw_256',\n"," 'maxvit_pico_rw_256',\n"," 'maxvit_rmlp_nano_rw_256',\n"," 'maxvit_rmlp_pico_rw_256',\n"," 'maxvit_rmlp_small_rw_224',\n"," 'maxvit_rmlp_small_rw_256',\n"," 'maxvit_rmlp_tiny_rw_256',\n"," 'maxvit_small_224',\n"," 'maxvit_tiny_224',\n"," 'maxvit_tiny_pm_256',\n"," 'maxvit_tiny_rw_224',\n"," 'maxvit_tiny_rw_256',\n"," 'maxvit_xlarge_224',\n"," 'maxxvit_rmlp_nano_rw_256',\n"," 'maxxvit_rmlp_small_rw_256',\n"," 'maxxvit_rmlp_tiny_rw_256',\n"," 'mobilevit_s',\n"," 'mobilevit_xs',\n"," 'mobilevit_xxs',\n"," 'mobilevitv2_050',\n"," 'mobilevitv2_075',\n"," 'mobilevitv2_100',\n"," 'mobilevitv2_125',\n"," 'mobilevitv2_150',\n"," 'mobilevitv2_150_384_in22ft1k',\n"," 'mobilevitv2_150_in22ft1k',\n"," 'mobilevitv2_175',\n"," 'mobilevitv2_175_384_in22ft1k',\n"," 'mobilevitv2_175_in22ft1k',\n"," 'mobilevitv2_200',\n"," 'mobilevitv2_200_384_in22ft1k',\n"," 'mobilevitv2_200_in22ft1k',\n"," 'mvitv2_base',\n"," 'mvitv2_large',\n"," 'mvitv2_small',\n"," 'mvitv2_small_cls',\n"," 'mvitv2_tiny',\n"," 'semobilevit_s',\n"," 'vit_base_patch8_224',\n"," 'vit_base_patch8_224_dino',\n"," 'vit_base_patch8_224_in21k',\n"," 'vit_base_patch16_18x2_224',\n"," 'vit_base_patch16_224',\n"," 'vit_base_patch16_224_dino',\n"," 'vit_base_patch16_224_in21k',\n"," 'vit_base_patch16_224_miil',\n"," 'vit_base_patch16_224_miil_in21k',\n"," 'vit_base_patch16_224_sam',\n"," 'vit_base_patch16_384',\n"," 'vit_base_patch16_plus_240',\n"," 'vit_base_patch16_rpn_224',\n"," 'vit_base_patch32_224',\n"," 'vit_base_patch32_224_clip_laion2b',\n"," 'vit_base_patch32_224_in21k',\n"," 'vit_base_patch32_224_sam',\n"," 'vit_base_patch32_384',\n"," 'vit_base_patch32_plus_256',\n"," 'vit_base_r26_s32_224',\n"," 'vit_base_r50_s16_224',\n"," 'vit_base_r50_s16_224_in21k',\n"," 'vit_base_r50_s16_384',\n"," 'vit_base_resnet26d_224',\n"," 'vit_base_resnet50_224_in21k',\n"," 'vit_base_resnet50_384',\n"," 'vit_base_resnet50d_224',\n"," 'vit_giant_patch14_224',\n"," 'vit_giant_patch14_224_clip_laion2b',\n"," 'vit_gigantic_patch14_224',\n"," 'vit_huge_patch14_224',\n"," 'vit_huge_patch14_224_clip_laion2b',\n"," 'vit_huge_patch14_224_in21k',\n"," 'vit_large_patch14_224',\n"," 'vit_large_patch14_224_clip_laion2b',\n"," 'vit_large_patch16_224',\n"," 'vit_large_patch16_224_in21k',\n"," 'vit_large_patch16_384',\n"," 'vit_large_patch32_224',\n"," 'vit_large_patch32_224_in21k',\n"," 'vit_large_patch32_384',\n"," 'vit_large_r50_s32_224',\n"," 'vit_large_r50_s32_224_in21k',\n"," 'vit_large_r50_s32_384',\n"," 'vit_relpos_base_patch16_224',\n"," 'vit_relpos_base_patch16_cls_224',\n"," 'vit_relpos_base_patch16_clsgap_224',\n"," 'vit_relpos_base_patch16_plus_240',\n"," 'vit_relpos_base_patch16_rpn_224',\n"," 'vit_relpos_base_patch32_plus_rpn_256',\n"," 'vit_relpos_medium_patch16_224',\n"," 'vit_relpos_medium_patch16_cls_224',\n"," 'vit_relpos_medium_patch16_rpn_224',\n"," 'vit_relpos_small_patch16_224',\n"," 'vit_relpos_small_patch16_rpn_224',\n"," 'vit_small_patch8_224_dino',\n"," 'vit_small_patch16_18x2_224',\n"," 'vit_small_patch16_36x1_224',\n"," 'vit_small_patch16_224',\n"," 'vit_small_patch16_224_dino',\n"," 'vit_small_patch16_224_in21k',\n"," 'vit_small_patch16_384',\n"," 'vit_small_patch32_224',\n"," 'vit_small_patch32_224_in21k',\n"," 'vit_small_patch32_384',\n"," 'vit_small_r26_s32_224',\n"," 'vit_small_r26_s32_224_in21k',\n"," 'vit_small_r26_s32_384',\n"," 'vit_small_resnet26d_224',\n"," 'vit_small_resnet50d_s16_224',\n"," 'vit_srelpos_medium_patch16_224',\n"," 'vit_srelpos_small_patch16_224',\n"," 'vit_tiny_patch16_224',\n"," 'vit_tiny_patch16_224_in21k',\n"," 'vit_tiny_patch16_384',\n"," 'vit_tiny_r_s16_p8_224',\n"," 'vit_tiny_r_s16_p8_224_in21k',\n"," 'vit_tiny_r_s16_p8_384']\n","test model output： tensor([[ 0.0044, -0.2469]], grad_fn=<AddmmBackward0>)\n","model is ready now!\n","model loaded\n","model : ViT_384_401_PT_lf25_b8_ROSE_CLS\n","*********************************setting*************************************\n","Namespace(Pre_Trained_model_path=None, PromptTuning=None, PromptUnFreeze=False, Prompt_Token_num=10, att_module='SimAM', attn_drop_rate=0.0, augmentation_name='CellMix-Group', batch_size=4, check_minibatch=None, cls_token_off=False, data_augmentation_mode=0, dataroot='/data/Pathology_Experiment/dataset/ROSE_CLS', draw_root='/home/Pathology_Experiment/imaging_results', drop_path_rate=0.0, drop_rate=0.0, edge_size=384, enable_attention_check=True, enable_notify=False, enable_tensorboard=False, enable_visualize_check=True, fix_position_ratio=0.5, gpu_idx=0, model_idx='ViT_384_401_PT_lf25_b8_ROSE_CLS', model_path='/home/Pathology_Experiment/saved_models', model_path_by_hand=None, num_classes=0, paint=True, pos_embedding_off=False, puzzle_patch_size=32, shuffle_dataloader=True)\n","Epoch: Test\n","\n","useing  CellMix-Group \n","\n","----------\n","Epoch: test     test index of 12 minibatch: 1      time used: 2.606926918029785\n","minibatch AVG loss: 0.12998147593073858\n","/home/Pathology_Experiment/code/utils/visual_usage.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  return sof(x)\n","Epoch: test     test index of 12 minibatch: 2      time used: 2.4267778396606445\n","minibatch AVG loss: 0.20599896530620754\n","Epoch: test     test index of 12 minibatch: 3      time used: 2.4816834926605225\n","minibatch AVG loss: 0.1939630751645988\n","Epoch: test     test index of 12 minibatch: 4      time used: 2.418707847595215\n","minibatch AVG loss: 0.16103375850555798\n","Epoch: test     test index of 12 minibatch: 5      time used: 2.3682215213775635\n","minibatch AVG loss: 0.48524316536835005\n","Epoch: test     test index of 12 minibatch: 6      time used: 2.3472225666046143\n","minibatch AVG loss: 0.24148745928444745\n","Epoch: test     test index of 12 minibatch: 7      time used: 2.3560245037078857\n","minibatch AVG loss: 0.33926400492782705\n","Epoch: test     test index of 12 minibatch: 8      time used: 2.3538551330566406\n","minibatch AVG loss: 0.41764963245077524\n","Epoch: test     test index of 12 minibatch: 9      time used: 2.392070770263672\n","minibatch AVG loss: 0.440933258117487\n","Epoch: test     test index of 12 minibatch: 10      time used: 2.425840139389038\n","minibatch AVG loss: 0.4150401456669594\n","Epoch: test     test index of 12 minibatch: 11      time used: 2.4492099285125732\n","minibatch AVG loss: 0.3412133388046641\n","Epoch: test     test index of 12 minibatch: 12      time used: 2.394298553466797\n","minibatch AVG loss: 0.24049141640231633\n","Epoch: test     test index of 12 minibatch: 13      time used: 2.342724561691284\n","minibatch AVG loss: 0.1121382273704512\n","Epoch: test     test index of 12 minibatch: 14      time used: 2.367361307144165\n","minibatch AVG loss: 0.3093149267369881\n","Epoch: test     test index of 12 minibatch: 15      time used: 2.4000191688537598\n","minibatch AVG loss: 0.18135355801011124\n","Epoch: test     test index of 12 minibatch: 16      time used: 2.370535373687744\n","minibatch AVG loss: 0.24797966197517476\n","Epoch: test     test index of 12 minibatch: 17      time used: 2.432602882385254\n","minibatch AVG loss: 0.23583092976089878\n","Epoch: test     test index of 12 minibatch: 18      time used: 2.3797686100006104\n","minibatch AVG loss: 0.19870770305472737\n","Epoch: test     test index of 12 minibatch: 19      time used: 2.409609079360962\n","minibatch AVG loss: 0.037444509134123415\n","Epoch: test     test index of 12 minibatch: 20      time used: 2.3613715171813965\n","minibatch AVG loss: 0.08256332110613585\n","Epoch: test     test index of 12 minibatch: 21      time used: 2.39664363861084\n","minibatch AVG loss: 0.1769632441767802\n","\n","Epoch:  test \n","Loss: 0.2456  Acc: 91.2402\n","Negative precision: 91.1047  recall: 95.9215\n","Negative sensitivity: 95.9215  specificity: 82.4859\n","Negative FPR: 17.5141  NPV: 91.5361\n","Negative TP: 635.0\n","Negative TN: 292.0\n","Negative FP: 62.0\n","Negative FN: 27.0\n","Positive precision: 91.5361  recall: 82.4859\n","Positive sensitivity: 82.4859  specificity: 95.9215\n","Positive FPR: 4.0785  NPV: 91.1047\n","Positive TP: 292.0\n","Positive TN: 635.0\n","Positive FP: 27.0\n","Positive FN: 62.0\n","\n","\n","Testing complete in 3m 45s\n"]}],"source":["!python CellMix_test.py --model_idx ViT_384_401_PT_lf25_b8_ROSE_CLS --gpu_idx 0 --enable_visualize_check --edge_size 384 --data_augmentation_mode 0 --augmentation_name CellMix-Group --fix_position_ratio 0.5 --puzzle_patch_size 32 --batch_size 4 --enable_attention_check --shuffle_dataloader --dataroot /data/Pathology_Experiment/dataset/ROSE_CLS --model_path /home/Pathology_Experiment/saved_models --draw_root /home/Pathology_Experiment/imaging_results"]},{"cell_type":"markdown","source":["--fix_position_ratio 0.5 --puzzle_patch_size 48 --batch_size 4 --enable_attention_check --shuffle_dataloader"],"metadata":{"id":"jJt_2a1V8xtZ"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"id3FNwdsY12s","outputId":"dfe40688-3cb7-4a68-edb2-66c224d064b8"},"outputs":[{"name":"stdout","output_type":"stream","text":["class_names: ['Negative', 'Positive']\n","['convit_base',\n"," 'convit_small',\n"," 'convit_tiny',\n"," 'crossvit_9_240',\n"," 'crossvit_9_dagger_240',\n"," 'crossvit_15_240',\n"," 'crossvit_15_dagger_240',\n"," 'crossvit_15_dagger_408',\n"," 'crossvit_18_240',\n"," 'crossvit_18_dagger_240',\n"," 'crossvit_18_dagger_408',\n"," 'crossvit_base_240',\n"," 'crossvit_small_240',\n"," 'crossvit_tiny_240',\n"," 'gcvit_base',\n"," 'gcvit_small',\n"," 'gcvit_tiny',\n"," 'gcvit_xtiny',\n"," 'gcvit_xxtiny',\n"," 'levit_128',\n"," 'levit_128s',\n"," 'levit_192',\n"," 'levit_256',\n"," 'levit_256d',\n"," 'levit_384',\n"," 'maxvit_base_224',\n"," 'maxvit_large_224',\n"," 'maxvit_nano_rw_256',\n"," 'maxvit_pico_rw_256',\n"," 'maxvit_rmlp_nano_rw_256',\n"," 'maxvit_rmlp_pico_rw_256',\n"," 'maxvit_rmlp_small_rw_224',\n"," 'maxvit_rmlp_small_rw_256',\n"," 'maxvit_rmlp_tiny_rw_256',\n"," 'maxvit_small_224',\n"," 'maxvit_tiny_224',\n"," 'maxvit_tiny_pm_256',\n"," 'maxvit_tiny_rw_224',\n"," 'maxvit_tiny_rw_256',\n"," 'maxvit_xlarge_224',\n"," 'maxxvit_rmlp_nano_rw_256',\n"," 'maxxvit_rmlp_small_rw_256',\n"," 'maxxvit_rmlp_tiny_rw_256',\n"," 'mobilevit_s',\n"," 'mobilevit_xs',\n"," 'mobilevit_xxs',\n"," 'mobilevitv2_050',\n"," 'mobilevitv2_075',\n"," 'mobilevitv2_100',\n"," 'mobilevitv2_125',\n"," 'mobilevitv2_150',\n"," 'mobilevitv2_150_384_in22ft1k',\n"," 'mobilevitv2_150_in22ft1k',\n"," 'mobilevitv2_175',\n"," 'mobilevitv2_175_384_in22ft1k',\n"," 'mobilevitv2_175_in22ft1k',\n"," 'mobilevitv2_200',\n"," 'mobilevitv2_200_384_in22ft1k',\n"," 'mobilevitv2_200_in22ft1k',\n"," 'mvitv2_base',\n"," 'mvitv2_large',\n"," 'mvitv2_small',\n"," 'mvitv2_small_cls',\n"," 'mvitv2_tiny',\n"," 'semobilevit_s',\n"," 'vit_base_patch8_224',\n"," 'vit_base_patch8_224_dino',\n"," 'vit_base_patch8_224_in21k',\n"," 'vit_base_patch16_18x2_224',\n"," 'vit_base_patch16_224',\n"," 'vit_base_patch16_224_dino',\n"," 'vit_base_patch16_224_in21k',\n"," 'vit_base_patch16_224_miil',\n"," 'vit_base_patch16_224_miil_in21k',\n"," 'vit_base_patch16_224_sam',\n"," 'vit_base_patch16_384',\n"," 'vit_base_patch16_plus_240',\n"," 'vit_base_patch16_rpn_224',\n"," 'vit_base_patch32_224',\n"," 'vit_base_patch32_224_clip_laion2b',\n"," 'vit_base_patch32_224_in21k',\n"," 'vit_base_patch32_224_sam',\n"," 'vit_base_patch32_384',\n"," 'vit_base_patch32_plus_256',\n"," 'vit_base_r26_s32_224',\n"," 'vit_base_r50_s16_224',\n"," 'vit_base_r50_s16_224_in21k',\n"," 'vit_base_r50_s16_384',\n"," 'vit_base_resnet26d_224',\n"," 'vit_base_resnet50_224_in21k',\n"," 'vit_base_resnet50_384',\n"," 'vit_base_resnet50d_224',\n"," 'vit_giant_patch14_224',\n"," 'vit_giant_patch14_224_clip_laion2b',\n"," 'vit_gigantic_patch14_224',\n"," 'vit_huge_patch14_224',\n"," 'vit_huge_patch14_224_clip_laion2b',\n"," 'vit_huge_patch14_224_in21k',\n"," 'vit_large_patch14_224',\n"," 'vit_large_patch14_224_clip_laion2b',\n"," 'vit_large_patch16_224',\n"," 'vit_large_patch16_224_in21k',\n"," 'vit_large_patch16_384',\n"," 'vit_large_patch32_224',\n"," 'vit_large_patch32_224_in21k',\n"," 'vit_large_patch32_384',\n"," 'vit_large_r50_s32_224',\n"," 'vit_large_r50_s32_224_in21k',\n"," 'vit_large_r50_s32_384',\n"," 'vit_relpos_base_patch16_224',\n"," 'vit_relpos_base_patch16_cls_224',\n"," 'vit_relpos_base_patch16_clsgap_224',\n"," 'vit_relpos_base_patch16_plus_240',\n"," 'vit_relpos_base_patch16_rpn_224',\n"," 'vit_relpos_base_patch32_plus_rpn_256',\n"," 'vit_relpos_medium_patch16_224',\n"," 'vit_relpos_medium_patch16_cls_224',\n"," 'vit_relpos_medium_patch16_rpn_224',\n"," 'vit_relpos_small_patch16_224',\n"," 'vit_relpos_small_patch16_rpn_224',\n"," 'vit_small_patch8_224_dino',\n"," 'vit_small_patch16_18x2_224',\n"," 'vit_small_patch16_36x1_224',\n"," 'vit_small_patch16_224',\n"," 'vit_small_patch16_224_dino',\n"," 'vit_small_patch16_224_in21k',\n"," 'vit_small_patch16_384',\n"," 'vit_small_patch32_224',\n"," 'vit_small_patch32_224_in21k',\n"," 'vit_small_patch32_384',\n"," 'vit_small_r26_s32_224',\n"," 'vit_small_r26_s32_224_in21k',\n"," 'vit_small_r26_s32_384',\n"," 'vit_small_resnet26d_224',\n"," 'vit_small_resnet50d_s16_224',\n"," 'vit_srelpos_medium_patch16_224',\n"," 'vit_srelpos_small_patch16_224',\n"," 'vit_tiny_patch16_224',\n"," 'vit_tiny_patch16_224_in21k',\n"," 'vit_tiny_patch16_384',\n"," 'vit_tiny_r_s16_p8_224',\n"," 'vit_tiny_r_s16_p8_224_in21k',\n"," 'vit_tiny_r_s16_p8_384']\n","test model output： tensor([[-0.5797, -0.3861]], grad_fn=<AddmmBackward0>)\n","model is ready now!\n","model loaded\n","model : ViT_384_401_PT_lf25_b8_ROSE_CLS\n","*********************************setting*************************************\n","Namespace(Pre_Trained_model_path=None, PromptTuning=None, PromptUnFreeze=False, Prompt_Token_num=10, att_module='SimAM', attn_drop_rate=0.0, augmentation_name='CellMix-Group', batch_size=4, check_minibatch=None, cls_token_off=False, data_augmentation_mode=0, dataroot='/data/Pathology_Experiment/dataset/ROSE_CLS', draw_root='/home/Pathology_Experiment/imaging_results', drop_path_rate=0.0, drop_rate=0.0, edge_size=384, enable_attention_check=True, enable_notify=False, enable_tensorboard=False, enable_visualize_check=True, fix_position_ratio=0.5, gpu_idx=0, model_idx='ViT_384_401_PT_lf25_b8_ROSE_CLS', model_path='/home/Pathology_Experiment/saved_models', model_path_by_hand=None, num_classes=0, paint=True, pos_embedding_off=False, puzzle_patch_size=48, shuffle_dataloader=True)\n","Epoch: Test\n","\n","useing  CellMix-Group \n","\n","----------\n","Epoch: test     test index of 12 minibatch: 1      time used: 2.5529799461364746\n","minibatch AVG loss: 0.1781290905782953\n","/home/Pathology_Experiment/code/utils/visual_usage.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  return sof(x)\n","Epoch: test     test index of 12 minibatch: 2      time used: 2.3758466243743896\n","minibatch AVG loss: 0.21572278876556084\n","Epoch: test     test index of 12 minibatch: 3      time used: 2.4753835201263428\n","minibatch AVG loss: 0.2878675001265947\n","Epoch: test     test index of 12 minibatch: 4      time used: 2.452096700668335\n","minibatch AVG loss: 0.22518392563749026\n","Epoch: test     test index of 12 minibatch: 5      time used: 2.3915934562683105\n","minibatch AVG loss: 0.053315803864582755\n","Epoch: test     test index of 12 minibatch: 6      time used: 2.3839612007141113\n","minibatch AVG loss: 0.42972345689243713\n","Epoch: test     test index of 12 minibatch: 7      time used: 2.3487792015075684\n","minibatch AVG loss: 0.29949725229137886\n","Epoch: test     test index of 12 minibatch: 8      time used: 2.3621957302093506\n","minibatch AVG loss: 0.10161117235838901\n","Epoch: test     test index of 12 minibatch: 9      time used: 2.4116711616516113\n","minibatch AVG loss: 0.39782905464138213\n","Epoch: test     test index of 12 minibatch: 10      time used: 2.4159505367279053\n","minibatch AVG loss: 0.27528235869976925\n","Epoch: test     test index of 12 minibatch: 11      time used: 2.4152026176452637\n","minibatch AVG loss: 0.22828346432652324\n","Epoch: test     test index of 12 minibatch: 12      time used: 2.380755662918091\n","minibatch AVG loss: 0.4082139243376635\n","Epoch: test     test index of 12 minibatch: 13      time used: 2.368082046508789\n","minibatch AVG loss: 0.22536437541324025\n","Epoch: test     test index of 12 minibatch: 14      time used: 2.3974196910858154\n","minibatch AVG loss: 0.23295326868537813\n","Epoch: test     test index of 12 minibatch: 15      time used: 2.4082281589508057\n","minibatch AVG loss: 0.23701329642062774\n","Epoch: test     test index of 12 minibatch: 16      time used: 2.3855764865875244\n","minibatch AVG loss: 0.18534628597747846\n","Epoch: test     test index of 12 minibatch: 17      time used: 2.395610809326172\n","minibatch AVG loss: 0.14379625850900388\n","Epoch: test     test index of 12 minibatch: 18      time used: 2.429797887802124\n","minibatch AVG loss: 0.19762371962618394\n","Epoch: test     test index of 12 minibatch: 19      time used: 2.396550416946411\n","minibatch AVG loss: 0.25143147172639146\n","Epoch: test     test index of 12 minibatch: 20      time used: 2.3742902278900146\n","minibatch AVG loss: 0.3968624476498614\n","Epoch: test     test index of 12 minibatch: 21      time used: 2.364445447921753\n","minibatch AVG loss: 0.206552774955829\n","\n","Epoch:  test \n","Loss: 0.2456  Acc: 91.2402\n","Negative precision: 91.1047  recall: 95.9215\n","Negative sensitivity: 95.9215  specificity: 82.4859\n","Negative FPR: 17.5141  NPV: 91.5361\n","Negative TP: 635.0\n","Negative TN: 292.0\n","Negative FP: 62.0\n","Negative FN: 27.0\n","Positive precision: 91.5361  recall: 82.4859\n","Positive sensitivity: 82.4859  specificity: 95.9215\n","Positive FPR: 4.0785  NPV: 91.1047\n","Positive TP: 292.0\n","Positive TN: 635.0\n","Positive FP: 27.0\n","Positive FN: 62.0\n","\n","\n","Testing complete in 3m 45s\n"]}],"source":["!python CellMix_test.py --model_idx ViT_384_401_PT_lf25_b8_ROSE_CLS --gpu_idx 0 --enable_visualize_check --edge_size 384 --data_augmentation_mode 0 --augmentation_name CellMix-Group --fix_position_ratio 0.5 --puzzle_patch_size 48 --batch_size 4 --enable_attention_check --shuffle_dataloader --dataroot /data/Pathology_Experiment/dataset/ROSE_CLS --model_path /home/Pathology_Experiment/saved_models --draw_root /home/Pathology_Experiment/imaging_results"]},{"cell_type":"markdown","source":["--fix_position_ratio 0.5 --puzzle_patch_size 64 --batch_size 4 --enable_attention_check --shuffle_dataloader"],"metadata":{"id":"brqd_3Gx831f"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"gGjKETPBY3Zf","outputId":"d4f8c975-d319-4603-d1d7-e0514c812dfd"},"outputs":[{"name":"stdout","output_type":"stream","text":["class_names: ['Negative', 'Positive']\n","['convit_base',\n"," 'convit_small',\n"," 'convit_tiny',\n"," 'crossvit_9_240',\n"," 'crossvit_9_dagger_240',\n"," 'crossvit_15_240',\n"," 'crossvit_15_dagger_240',\n"," 'crossvit_15_dagger_408',\n"," 'crossvit_18_240',\n"," 'crossvit_18_dagger_240',\n"," 'crossvit_18_dagger_408',\n"," 'crossvit_base_240',\n"," 'crossvit_small_240',\n"," 'crossvit_tiny_240',\n"," 'gcvit_base',\n"," 'gcvit_small',\n"," 'gcvit_tiny',\n"," 'gcvit_xtiny',\n"," 'gcvit_xxtiny',\n"," 'levit_128',\n"," 'levit_128s',\n"," 'levit_192',\n"," 'levit_256',\n"," 'levit_256d',\n"," 'levit_384',\n"," 'maxvit_base_224',\n"," 'maxvit_large_224',\n"," 'maxvit_nano_rw_256',\n"," 'maxvit_pico_rw_256',\n"," 'maxvit_rmlp_nano_rw_256',\n"," 'maxvit_rmlp_pico_rw_256',\n"," 'maxvit_rmlp_small_rw_224',\n"," 'maxvit_rmlp_small_rw_256',\n"," 'maxvit_rmlp_tiny_rw_256',\n"," 'maxvit_small_224',\n"," 'maxvit_tiny_224',\n"," 'maxvit_tiny_pm_256',\n"," 'maxvit_tiny_rw_224',\n"," 'maxvit_tiny_rw_256',\n"," 'maxvit_xlarge_224',\n"," 'maxxvit_rmlp_nano_rw_256',\n"," 'maxxvit_rmlp_small_rw_256',\n"," 'maxxvit_rmlp_tiny_rw_256',\n"," 'mobilevit_s',\n"," 'mobilevit_xs',\n"," 'mobilevit_xxs',\n"," 'mobilevitv2_050',\n"," 'mobilevitv2_075',\n"," 'mobilevitv2_100',\n"," 'mobilevitv2_125',\n"," 'mobilevitv2_150',\n"," 'mobilevitv2_150_384_in22ft1k',\n"," 'mobilevitv2_150_in22ft1k',\n"," 'mobilevitv2_175',\n"," 'mobilevitv2_175_384_in22ft1k',\n"," 'mobilevitv2_175_in22ft1k',\n"," 'mobilevitv2_200',\n"," 'mobilevitv2_200_384_in22ft1k',\n"," 'mobilevitv2_200_in22ft1k',\n"," 'mvitv2_base',\n"," 'mvitv2_large',\n"," 'mvitv2_small',\n"," 'mvitv2_small_cls',\n"," 'mvitv2_tiny',\n"," 'semobilevit_s',\n"," 'vit_base_patch8_224',\n"," 'vit_base_patch8_224_dino',\n"," 'vit_base_patch8_224_in21k',\n"," 'vit_base_patch16_18x2_224',\n"," 'vit_base_patch16_224',\n"," 'vit_base_patch16_224_dino',\n"," 'vit_base_patch16_224_in21k',\n"," 'vit_base_patch16_224_miil',\n"," 'vit_base_patch16_224_miil_in21k',\n"," 'vit_base_patch16_224_sam',\n"," 'vit_base_patch16_384',\n"," 'vit_base_patch16_plus_240',\n"," 'vit_base_patch16_rpn_224',\n"," 'vit_base_patch32_224',\n"," 'vit_base_patch32_224_clip_laion2b',\n"," 'vit_base_patch32_224_in21k',\n"," 'vit_base_patch32_224_sam',\n"," 'vit_base_patch32_384',\n"," 'vit_base_patch32_plus_256',\n"," 'vit_base_r26_s32_224',\n"," 'vit_base_r50_s16_224',\n"," 'vit_base_r50_s16_224_in21k',\n"," 'vit_base_r50_s16_384',\n"," 'vit_base_resnet26d_224',\n"," 'vit_base_resnet50_224_in21k',\n"," 'vit_base_resnet50_384',\n"," 'vit_base_resnet50d_224',\n"," 'vit_giant_patch14_224',\n"," 'vit_giant_patch14_224_clip_laion2b',\n"," 'vit_gigantic_patch14_224',\n"," 'vit_huge_patch14_224',\n"," 'vit_huge_patch14_224_clip_laion2b',\n"," 'vit_huge_patch14_224_in21k',\n"," 'vit_large_patch14_224',\n"," 'vit_large_patch14_224_clip_laion2b',\n"," 'vit_large_patch16_224',\n"," 'vit_large_patch16_224_in21k',\n"," 'vit_large_patch16_384',\n"," 'vit_large_patch32_224',\n"," 'vit_large_patch32_224_in21k',\n"," 'vit_large_patch32_384',\n"," 'vit_large_r50_s32_224',\n"," 'vit_large_r50_s32_224_in21k',\n"," 'vit_large_r50_s32_384',\n"," 'vit_relpos_base_patch16_224',\n"," 'vit_relpos_base_patch16_cls_224',\n"," 'vit_relpos_base_patch16_clsgap_224',\n"," 'vit_relpos_base_patch16_plus_240',\n"," 'vit_relpos_base_patch16_rpn_224',\n"," 'vit_relpos_base_patch32_plus_rpn_256',\n"," 'vit_relpos_medium_patch16_224',\n"," 'vit_relpos_medium_patch16_cls_224',\n"," 'vit_relpos_medium_patch16_rpn_224',\n"," 'vit_relpos_small_patch16_224',\n"," 'vit_relpos_small_patch16_rpn_224',\n"," 'vit_small_patch8_224_dino',\n"," 'vit_small_patch16_18x2_224',\n"," 'vit_small_patch16_36x1_224',\n"," 'vit_small_patch16_224',\n"," 'vit_small_patch16_224_dino',\n"," 'vit_small_patch16_224_in21k',\n"," 'vit_small_patch16_384',\n"," 'vit_small_patch32_224',\n"," 'vit_small_patch32_224_in21k',\n"," 'vit_small_patch32_384',\n"," 'vit_small_r26_s32_224',\n"," 'vit_small_r26_s32_224_in21k',\n"," 'vit_small_r26_s32_384',\n"," 'vit_small_resnet26d_224',\n"," 'vit_small_resnet50d_s16_224',\n"," 'vit_srelpos_medium_patch16_224',\n"," 'vit_srelpos_small_patch16_224',\n"," 'vit_tiny_patch16_224',\n"," 'vit_tiny_patch16_224_in21k',\n"," 'vit_tiny_patch16_384',\n"," 'vit_tiny_r_s16_p8_224',\n"," 'vit_tiny_r_s16_p8_224_in21k',\n"," 'vit_tiny_r_s16_p8_384']\n","test model output： tensor([[0.1609, 0.0062]], grad_fn=<AddmmBackward0>)\n","model is ready now!\n","model loaded\n","model : ViT_384_401_PT_lf25_b8_ROSE_CLS\n","*********************************setting*************************************\n","Namespace(Pre_Trained_model_path=None, PromptTuning=None, PromptUnFreeze=False, Prompt_Token_num=10, att_module='SimAM', attn_drop_rate=0.0, augmentation_name='CellMix-Group', batch_size=4, check_minibatch=None, cls_token_off=False, data_augmentation_mode=0, dataroot='/data/Pathology_Experiment/dataset/ROSE_CLS', draw_root='/home/Pathology_Experiment/imaging_results', drop_path_rate=0.0, drop_rate=0.0, edge_size=384, enable_attention_check=True, enable_notify=False, enable_tensorboard=False, enable_visualize_check=True, fix_position_ratio=0.5, gpu_idx=0, model_idx='ViT_384_401_PT_lf25_b8_ROSE_CLS', model_path='/home/Pathology_Experiment/saved_models', model_path_by_hand=None, num_classes=0, paint=True, pos_embedding_off=False, puzzle_patch_size=64, shuffle_dataloader=True)\n","Epoch: Test\n","\n","useing  CellMix-Group \n","\n","----------\n","Epoch: test     test index of 12 minibatch: 1      time used: 2.5714921951293945\n","minibatch AVG loss: 0.19284791499376297\n","/home/Pathology_Experiment/code/utils/visual_usage.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  return sof(x)\n","Epoch: test     test index of 12 minibatch: 2      time used: 2.4156739711761475\n","minibatch AVG loss: 0.2032015186462862\n","Epoch: test     test index of 12 minibatch: 3      time used: 2.4805784225463867\n","minibatch AVG loss: 0.30588703297932324\n","Epoch: test     test index of 12 minibatch: 4      time used: 2.4271767139434814\n","minibatch AVG loss: 0.16178834206463458\n","Epoch: test     test index of 12 minibatch: 5      time used: 2.3673744201660156\n","minibatch AVG loss: 0.31434226300916635\n","Epoch: test     test index of 12 minibatch: 6      time used: 2.3720219135284424\n","minibatch AVG loss: 0.1667063258064445\n","Epoch: test     test index of 12 minibatch: 7      time used: 2.3562583923339844\n","minibatch AVG loss: 0.28920600227138493\n","Epoch: test     test index of 12 minibatch: 8      time used: 2.366992712020874\n","minibatch AVG loss: 0.3028861632580326\n","Epoch: test     test index of 12 minibatch: 9      time used: 2.4021477699279785\n","minibatch AVG loss: 0.2859541432117112\n","Epoch: test     test index of 12 minibatch: 10      time used: 2.409658193588257\n","minibatch AVG loss: 0.3245244803838432\n","Epoch: test     test index of 12 minibatch: 11      time used: 2.386300802230835\n","minibatch AVG loss: 0.20794096428532308\n","Epoch: test     test index of 12 minibatch: 12      time used: 2.382581949234009\n","minibatch AVG loss: 0.3474426355290537\n","Epoch: test     test index of 12 minibatch: 13      time used: 2.398315191268921\n","minibatch AVG loss: 0.08133890645694919\n","Epoch: test     test index of 12 minibatch: 14      time used: 2.418914794921875\n","minibatch AVG loss: 0.10307088394862755\n","Epoch: test     test index of 12 minibatch: 15      time used: 2.3860044479370117\n","minibatch AVG loss: 0.3187797030744453\n","Epoch: test     test index of 12 minibatch: 16      time used: 2.4207212924957275\n","minibatch AVG loss: 0.22301990049891174\n","Epoch: test     test index of 12 minibatch: 17      time used: 2.3935937881469727\n","minibatch AVG loss: 0.28095468739047647\n","Epoch: test     test index of 12 minibatch: 18      time used: 2.370525598526001\n","minibatch AVG loss: 0.45762928125138086\n","Epoch: test     test index of 12 minibatch: 19      time used: 2.369255781173706\n","minibatch AVG loss: 0.10015434640081367\n","Epoch: test     test index of 12 minibatch: 20      time used: 2.436307430267334\n","minibatch AVG loss: 0.1570239260327071\n","Epoch: test     test index of 12 minibatch: 21      time used: 2.415302038192749\n","minibatch AVG loss: 0.3209448068713148\n","\n","Epoch:  test \n","Loss: 0.2456  Acc: 91.2402\n","Negative precision: 91.1047  recall: 95.9215\n","Negative sensitivity: 95.9215  specificity: 82.4859\n","Negative FPR: 17.5141  NPV: 91.5361\n","Negative TP: 635.0\n","Negative TN: 292.0\n","Negative FP: 62.0\n","Negative FN: 27.0\n","Positive precision: 91.5361  recall: 82.4859\n","Positive sensitivity: 82.4859  specificity: 95.9215\n","Positive FPR: 4.0785  NPV: 91.1047\n","Positive TP: 292.0\n","Positive TN: 635.0\n","Positive FP: 27.0\n","Positive FN: 62.0\n","\n","\n","Testing complete in 3m 46s\n"]}],"source":["!python CellMix_test.py --model_idx ViT_384_401_PT_lf25_b8_ROSE_CLS --gpu_idx 0 --enable_visualize_check --edge_size 384 --data_augmentation_mode 0 --augmentation_name CellMix-Group --fix_position_ratio 0.5 --puzzle_patch_size 64 --batch_size 4 --enable_attention_check --shuffle_dataloader --dataroot /data/Pathology_Experiment/dataset/ROSE_CLS --model_path /home/Pathology_Experiment/saved_models --draw_root /home/Pathology_Experiment/imaging_results"]},{"cell_type":"markdown","source":["--fix_position_ratio 0.5 --puzzle_patch_size 96 --batch_size 4 --enable_attention_check --shuffle_dataloader"],"metadata":{"id":"S-xIBbn187e1"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"OPN2zAjVY6oT","outputId":"ed4dda0b-93a9-4462-e4c2-84b5971fe663"},"outputs":[{"name":"stdout","output_type":"stream","text":["class_names: ['Negative', 'Positive']\n","['convit_base',\n"," 'convit_small',\n"," 'convit_tiny',\n"," 'crossvit_9_240',\n"," 'crossvit_9_dagger_240',\n"," 'crossvit_15_240',\n"," 'crossvit_15_dagger_240',\n"," 'crossvit_15_dagger_408',\n"," 'crossvit_18_240',\n"," 'crossvit_18_dagger_240',\n"," 'crossvit_18_dagger_408',\n"," 'crossvit_base_240',\n"," 'crossvit_small_240',\n"," 'crossvit_tiny_240',\n"," 'gcvit_base',\n"," 'gcvit_small',\n"," 'gcvit_tiny',\n"," 'gcvit_xtiny',\n"," 'gcvit_xxtiny',\n"," 'levit_128',\n"," 'levit_128s',\n"," 'levit_192',\n"," 'levit_256',\n"," 'levit_256d',\n"," 'levit_384',\n"," 'maxvit_base_224',\n"," 'maxvit_large_224',\n"," 'maxvit_nano_rw_256',\n"," 'maxvit_pico_rw_256',\n"," 'maxvit_rmlp_nano_rw_256',\n"," 'maxvit_rmlp_pico_rw_256',\n"," 'maxvit_rmlp_small_rw_224',\n"," 'maxvit_rmlp_small_rw_256',\n"," 'maxvit_rmlp_tiny_rw_256',\n"," 'maxvit_small_224',\n"," 'maxvit_tiny_224',\n"," 'maxvit_tiny_pm_256',\n"," 'maxvit_tiny_rw_224',\n"," 'maxvit_tiny_rw_256',\n"," 'maxvit_xlarge_224',\n"," 'maxxvit_rmlp_nano_rw_256',\n"," 'maxxvit_rmlp_small_rw_256',\n"," 'maxxvit_rmlp_tiny_rw_256',\n"," 'mobilevit_s',\n"," 'mobilevit_xs',\n"," 'mobilevit_xxs',\n"," 'mobilevitv2_050',\n"," 'mobilevitv2_075',\n"," 'mobilevitv2_100',\n"," 'mobilevitv2_125',\n"," 'mobilevitv2_150',\n"," 'mobilevitv2_150_384_in22ft1k',\n"," 'mobilevitv2_150_in22ft1k',\n"," 'mobilevitv2_175',\n"," 'mobilevitv2_175_384_in22ft1k',\n"," 'mobilevitv2_175_in22ft1k',\n"," 'mobilevitv2_200',\n"," 'mobilevitv2_200_384_in22ft1k',\n"," 'mobilevitv2_200_in22ft1k',\n"," 'mvitv2_base',\n"," 'mvitv2_large',\n"," 'mvitv2_small',\n"," 'mvitv2_small_cls',\n"," 'mvitv2_tiny',\n"," 'semobilevit_s',\n"," 'vit_base_patch8_224',\n"," 'vit_base_patch8_224_dino',\n"," 'vit_base_patch8_224_in21k',\n"," 'vit_base_patch16_18x2_224',\n"," 'vit_base_patch16_224',\n"," 'vit_base_patch16_224_dino',\n"," 'vit_base_patch16_224_in21k',\n"," 'vit_base_patch16_224_miil',\n"," 'vit_base_patch16_224_miil_in21k',\n"," 'vit_base_patch16_224_sam',\n"," 'vit_base_patch16_384',\n"," 'vit_base_patch16_plus_240',\n"," 'vit_base_patch16_rpn_224',\n"," 'vit_base_patch32_224',\n"," 'vit_base_patch32_224_clip_laion2b',\n"," 'vit_base_patch32_224_in21k',\n"," 'vit_base_patch32_224_sam',\n"," 'vit_base_patch32_384',\n"," 'vit_base_patch32_plus_256',\n"," 'vit_base_r26_s32_224',\n"," 'vit_base_r50_s16_224',\n"," 'vit_base_r50_s16_224_in21k',\n"," 'vit_base_r50_s16_384',\n"," 'vit_base_resnet26d_224',\n"," 'vit_base_resnet50_224_in21k',\n"," 'vit_base_resnet50_384',\n"," 'vit_base_resnet50d_224',\n"," 'vit_giant_patch14_224',\n"," 'vit_giant_patch14_224_clip_laion2b',\n"," 'vit_gigantic_patch14_224',\n"," 'vit_huge_patch14_224',\n"," 'vit_huge_patch14_224_clip_laion2b',\n"," 'vit_huge_patch14_224_in21k',\n"," 'vit_large_patch14_224',\n"," 'vit_large_patch14_224_clip_laion2b',\n"," 'vit_large_patch16_224',\n"," 'vit_large_patch16_224_in21k',\n"," 'vit_large_patch16_384',\n"," 'vit_large_patch32_224',\n"," 'vit_large_patch32_224_in21k',\n"," 'vit_large_patch32_384',\n"," 'vit_large_r50_s32_224',\n"," 'vit_large_r50_s32_224_in21k',\n"," 'vit_large_r50_s32_384',\n"," 'vit_relpos_base_patch16_224',\n"," 'vit_relpos_base_patch16_cls_224',\n"," 'vit_relpos_base_patch16_clsgap_224',\n"," 'vit_relpos_base_patch16_plus_240',\n"," 'vit_relpos_base_patch16_rpn_224',\n"," 'vit_relpos_base_patch32_plus_rpn_256',\n"," 'vit_relpos_medium_patch16_224',\n"," 'vit_relpos_medium_patch16_cls_224',\n"," 'vit_relpos_medium_patch16_rpn_224',\n"," 'vit_relpos_small_patch16_224',\n"," 'vit_relpos_small_patch16_rpn_224',\n"," 'vit_small_patch8_224_dino',\n"," 'vit_small_patch16_18x2_224',\n"," 'vit_small_patch16_36x1_224',\n"," 'vit_small_patch16_224',\n"," 'vit_small_patch16_224_dino',\n"," 'vit_small_patch16_224_in21k',\n"," 'vit_small_patch16_384',\n"," 'vit_small_patch32_224',\n"," 'vit_small_patch32_224_in21k',\n"," 'vit_small_patch32_384',\n"," 'vit_small_r26_s32_224',\n"," 'vit_small_r26_s32_224_in21k',\n"," 'vit_small_r26_s32_384',\n"," 'vit_small_resnet26d_224',\n"," 'vit_small_resnet50d_s16_224',\n"," 'vit_srelpos_medium_patch16_224',\n"," 'vit_srelpos_small_patch16_224',\n"," 'vit_tiny_patch16_224',\n"," 'vit_tiny_patch16_224_in21k',\n"," 'vit_tiny_patch16_384',\n"," 'vit_tiny_r_s16_p8_224',\n"," 'vit_tiny_r_s16_p8_224_in21k',\n"," 'vit_tiny_r_s16_p8_384']\n","test model output： tensor([[0.5620, 0.3805]], grad_fn=<AddmmBackward0>)\n","model is ready now!\n","model loaded\n","model : ViT_384_401_PT_lf25_b8_ROSE_CLS\n","*********************************setting*************************************\n","Namespace(Pre_Trained_model_path=None, PromptTuning=None, PromptUnFreeze=False, Prompt_Token_num=10, att_module='SimAM', attn_drop_rate=0.0, augmentation_name='CellMix-Group', batch_size=4, check_minibatch=None, cls_token_off=False, data_augmentation_mode=0, dataroot='/data/Pathology_Experiment/dataset/ROSE_CLS', draw_root='/home/Pathology_Experiment/imaging_results', drop_path_rate=0.0, drop_rate=0.0, edge_size=384, enable_attention_check=True, enable_notify=False, enable_tensorboard=False, enable_visualize_check=True, fix_position_ratio=0.5, gpu_idx=0, model_idx='ViT_384_401_PT_lf25_b8_ROSE_CLS', model_path='/home/Pathology_Experiment/saved_models', model_path_by_hand=None, num_classes=0, paint=True, pos_embedding_off=False, puzzle_patch_size=96, shuffle_dataloader=True)\n","Epoch: Test\n","\n","useing  CellMix-Group \n","\n","----------\n","Epoch: test     test index of 12 minibatch: 1      time used: 2.5797853469848633\n","minibatch AVG loss: 0.5376251759783676\n","/home/Pathology_Experiment/code/utils/visual_usage.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  return sof(x)\n","Epoch: test     test index of 12 minibatch: 2      time used: 2.3704116344451904\n","minibatch AVG loss: 0.1878514563262191\n","Epoch: test     test index of 12 minibatch: 3      time used: 2.4505772590637207\n","minibatch AVG loss: 0.15701838604096943\n","Epoch: test     test index of 12 minibatch: 4      time used: 2.499171495437622\n","minibatch AVG loss: 0.1487210883606167\n","Epoch: test     test index of 12 minibatch: 5      time used: 2.425961971282959\n","minibatch AVG loss: 0.3672584847469504\n","Epoch: test     test index of 12 minibatch: 6      time used: 2.369743585586548\n","minibatch AVG loss: 0.20693159957772878\n","Epoch: test     test index of 12 minibatch: 7      time used: 2.3710005283355713\n","minibatch AVG loss: 0.20017231116071343\n","Epoch: test     test index of 12 minibatch: 8      time used: 2.3822879791259766\n","minibatch AVG loss: 0.35205558768696693\n","Epoch: test     test index of 12 minibatch: 9      time used: 2.3977630138397217\n","minibatch AVG loss: 0.09750428634470154\n","Epoch: test     test index of 12 minibatch: 10      time used: 2.41796875\n","minibatch AVG loss: 0.17095666820144592\n","Epoch: test     test index of 12 minibatch: 11      time used: 2.3945112228393555\n","minibatch AVG loss: 0.1349477168211403\n","Epoch: test     test index of 12 minibatch: 12      time used: 2.388437271118164\n","minibatch AVG loss: 0.17402352994152656\n","Epoch: test     test index of 12 minibatch: 13      time used: 2.3958687782287598\n","minibatch AVG loss: 0.046755024610320106\n","Epoch: test     test index of 12 minibatch: 14      time used: 2.3661463260650635\n","minibatch AVG loss: 0.22935243362250426\n","Epoch: test     test index of 12 minibatch: 15      time used: 2.378554344177246\n","minibatch AVG loss: 0.29515972463802126\n","Epoch: test     test index of 12 minibatch: 16      time used: 2.424848794937134\n","minibatch AVG loss: 0.37131144093352003\n","Epoch: test     test index of 12 minibatch: 17      time used: 2.4162423610687256\n","minibatch AVG loss: 0.38800133439751033\n","Epoch: test     test index of 12 minibatch: 18      time used: 2.4037179946899414\n","minibatch AVG loss: 0.37533425102204393\n","Epoch: test     test index of 12 minibatch: 19      time used: 2.3986449241638184\n","minibatch AVG loss: 0.2681013752977985\n","Epoch: test     test index of 12 minibatch: 20      time used: 2.3972175121307373\n","minibatch AVG loss: 0.37291597273845883\n","Epoch: test     test index of 12 minibatch: 21      time used: 2.406644105911255\n","minibatch AVG loss: 0.1129401049305064\n","\n","Epoch:  test \n","Loss: 0.2456  Acc: 91.2402\n","Negative precision: 91.1047  recall: 95.9215\n","Negative sensitivity: 95.9215  specificity: 82.4859\n","Negative FPR: 17.5141  NPV: 91.5361\n","Negative TP: 635.0\n","Negative TN: 292.0\n","Negative FP: 62.0\n","Negative FN: 27.0\n","Positive precision: 91.5361  recall: 82.4859\n","Positive sensitivity: 82.4859  specificity: 95.9215\n","Positive FPR: 4.0785  NPV: 91.1047\n","Positive TP: 292.0\n","Positive TN: 635.0\n","Positive FP: 27.0\n","Positive FN: 62.0\n","\n","\n","Testing complete in 3m 46s\n"]}],"source":["!python CellMix_test.py --model_idx ViT_384_401_PT_lf25_b8_ROSE_CLS --gpu_idx 0 --enable_visualize_check --edge_size 384 --data_augmentation_mode 0 --augmentation_name CellMix-Group --fix_position_ratio 0.5 --puzzle_patch_size 96 --batch_size 4 --enable_attention_check --shuffle_dataloader --dataroot /data/Pathology_Experiment/dataset/ROSE_CLS --model_path /home/Pathology_Experiment/saved_models --draw_root /home/Pathology_Experiment/imaging_results"]},{"cell_type":"markdown","source":["--fix_position_ratio 0.5 --puzzle_patch_size 128 --batch_size 4 --enable_attention_check --shuffle_dataloader"],"metadata":{"id":"Bd4ucV3488yL"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ZbPKb4ZuY8ii","outputId":"f6a610c7-e0ce-47cb-e462-b691cab6870c"},"outputs":[{"name":"stdout","output_type":"stream","text":["class_names: ['Negative', 'Positive']\n","['convit_base',\n"," 'convit_small',\n"," 'convit_tiny',\n"," 'crossvit_9_240',\n"," 'crossvit_9_dagger_240',\n"," 'crossvit_15_240',\n"," 'crossvit_15_dagger_240',\n"," 'crossvit_15_dagger_408',\n"," 'crossvit_18_240',\n"," 'crossvit_18_dagger_240',\n"," 'crossvit_18_dagger_408',\n"," 'crossvit_base_240',\n"," 'crossvit_small_240',\n"," 'crossvit_tiny_240',\n"," 'gcvit_base',\n"," 'gcvit_small',\n"," 'gcvit_tiny',\n"," 'gcvit_xtiny',\n"," 'gcvit_xxtiny',\n"," 'levit_128',\n"," 'levit_128s',\n"," 'levit_192',\n"," 'levit_256',\n"," 'levit_256d',\n"," 'levit_384',\n"," 'maxvit_base_224',\n"," 'maxvit_large_224',\n"," 'maxvit_nano_rw_256',\n"," 'maxvit_pico_rw_256',\n"," 'maxvit_rmlp_nano_rw_256',\n"," 'maxvit_rmlp_pico_rw_256',\n"," 'maxvit_rmlp_small_rw_224',\n"," 'maxvit_rmlp_small_rw_256',\n"," 'maxvit_rmlp_tiny_rw_256',\n"," 'maxvit_small_224',\n"," 'maxvit_tiny_224',\n"," 'maxvit_tiny_pm_256',\n"," 'maxvit_tiny_rw_224',\n"," 'maxvit_tiny_rw_256',\n"," 'maxvit_xlarge_224',\n"," 'maxxvit_rmlp_nano_rw_256',\n"," 'maxxvit_rmlp_small_rw_256',\n"," 'maxxvit_rmlp_tiny_rw_256',\n"," 'mobilevit_s',\n"," 'mobilevit_xs',\n"," 'mobilevit_xxs',\n"," 'mobilevitv2_050',\n"," 'mobilevitv2_075',\n"," 'mobilevitv2_100',\n"," 'mobilevitv2_125',\n"," 'mobilevitv2_150',\n"," 'mobilevitv2_150_384_in22ft1k',\n"," 'mobilevitv2_150_in22ft1k',\n"," 'mobilevitv2_175',\n"," 'mobilevitv2_175_384_in22ft1k',\n"," 'mobilevitv2_175_in22ft1k',\n"," 'mobilevitv2_200',\n"," 'mobilevitv2_200_384_in22ft1k',\n"," 'mobilevitv2_200_in22ft1k',\n"," 'mvitv2_base',\n"," 'mvitv2_large',\n"," 'mvitv2_small',\n"," 'mvitv2_small_cls',\n"," 'mvitv2_tiny',\n"," 'semobilevit_s',\n"," 'vit_base_patch8_224',\n"," 'vit_base_patch8_224_dino',\n"," 'vit_base_patch8_224_in21k',\n"," 'vit_base_patch16_18x2_224',\n"," 'vit_base_patch16_224',\n"," 'vit_base_patch16_224_dino',\n"," 'vit_base_patch16_224_in21k',\n"," 'vit_base_patch16_224_miil',\n"," 'vit_base_patch16_224_miil_in21k',\n"," 'vit_base_patch16_224_sam',\n"," 'vit_base_patch16_384',\n"," 'vit_base_patch16_plus_240',\n"," 'vit_base_patch16_rpn_224',\n"," 'vit_base_patch32_224',\n"," 'vit_base_patch32_224_clip_laion2b',\n"," 'vit_base_patch32_224_in21k',\n"," 'vit_base_patch32_224_sam',\n"," 'vit_base_patch32_384',\n"," 'vit_base_patch32_plus_256',\n"," 'vit_base_r26_s32_224',\n"," 'vit_base_r50_s16_224',\n"," 'vit_base_r50_s16_224_in21k',\n"," 'vit_base_r50_s16_384',\n"," 'vit_base_resnet26d_224',\n"," 'vit_base_resnet50_224_in21k',\n"," 'vit_base_resnet50_384',\n"," 'vit_base_resnet50d_224',\n"," 'vit_giant_patch14_224',\n"," 'vit_giant_patch14_224_clip_laion2b',\n"," 'vit_gigantic_patch14_224',\n"," 'vit_huge_patch14_224',\n"," 'vit_huge_patch14_224_clip_laion2b',\n"," 'vit_huge_patch14_224_in21k',\n"," 'vit_large_patch14_224',\n"," 'vit_large_patch14_224_clip_laion2b',\n"," 'vit_large_patch16_224',\n"," 'vit_large_patch16_224_in21k',\n"," 'vit_large_patch16_384',\n"," 'vit_large_patch32_224',\n"," 'vit_large_patch32_224_in21k',\n"," 'vit_large_patch32_384',\n"," 'vit_large_r50_s32_224',\n"," 'vit_large_r50_s32_224_in21k',\n"," 'vit_large_r50_s32_384',\n"," 'vit_relpos_base_patch16_224',\n"," 'vit_relpos_base_patch16_cls_224',\n"," 'vit_relpos_base_patch16_clsgap_224',\n"," 'vit_relpos_base_patch16_plus_240',\n"," 'vit_relpos_base_patch16_rpn_224',\n"," 'vit_relpos_base_patch32_plus_rpn_256',\n"," 'vit_relpos_medium_patch16_224',\n"," 'vit_relpos_medium_patch16_cls_224',\n"," 'vit_relpos_medium_patch16_rpn_224',\n"," 'vit_relpos_small_patch16_224',\n"," 'vit_relpos_small_patch16_rpn_224',\n"," 'vit_small_patch8_224_dino',\n"," 'vit_small_patch16_18x2_224',\n"," 'vit_small_patch16_36x1_224',\n"," 'vit_small_patch16_224',\n"," 'vit_small_patch16_224_dino',\n"," 'vit_small_patch16_224_in21k',\n"," 'vit_small_patch16_384',\n"," 'vit_small_patch32_224',\n"," 'vit_small_patch32_224_in21k',\n"," 'vit_small_patch32_384',\n"," 'vit_small_r26_s32_224',\n"," 'vit_small_r26_s32_224_in21k',\n"," 'vit_small_r26_s32_384',\n"," 'vit_small_resnet26d_224',\n"," 'vit_small_resnet50d_s16_224',\n"," 'vit_srelpos_medium_patch16_224',\n"," 'vit_srelpos_small_patch16_224',\n"," 'vit_tiny_patch16_224',\n"," 'vit_tiny_patch16_224_in21k',\n"," 'vit_tiny_patch16_384',\n"," 'vit_tiny_r_s16_p8_224',\n"," 'vit_tiny_r_s16_p8_224_in21k',\n"," 'vit_tiny_r_s16_p8_384']\n","test model output： tensor([[ 0.5841, -0.1408]], grad_fn=<AddmmBackward0>)\n","model is ready now!\n","model loaded\n","model : ViT_384_401_PT_lf25_b8_ROSE_CLS\n","*********************************setting*************************************\n","Namespace(Pre_Trained_model_path=None, PromptTuning=None, PromptUnFreeze=False, Prompt_Token_num=10, att_module='SimAM', attn_drop_rate=0.0, augmentation_name='CellMix-Group', batch_size=4, check_minibatch=None, cls_token_off=False, data_augmentation_mode=0, dataroot='/data/Pathology_Experiment/dataset/ROSE_CLS', draw_root='/home/Pathology_Experiment/imaging_results', drop_path_rate=0.0, drop_rate=0.0, edge_size=384, enable_attention_check=True, enable_notify=False, enable_tensorboard=False, enable_visualize_check=True, fix_position_ratio=0.5, gpu_idx=0, model_idx='ViT_384_401_PT_lf25_b8_ROSE_CLS', model_path='/home/Pathology_Experiment/saved_models', model_path_by_hand=None, num_classes=0, paint=True, pos_embedding_off=False, puzzle_patch_size=128, shuffle_dataloader=True)\n","Epoch: Test\n","\n","useing  CellMix-Group \n","\n","----------\n","Epoch: test     test index of 12 minibatch: 1      time used: 2.6025521755218506\n","minibatch AVG loss: 0.10536830551670089\n","/home/Pathology_Experiment/code/utils/visual_usage.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  return sof(x)\n","Epoch: test     test index of 12 minibatch: 2      time used: 2.369764804840088\n","minibatch AVG loss: 0.3500146583343546\n","Epoch: test     test index of 12 minibatch: 3      time used: 2.445359468460083\n","minibatch AVG loss: 0.2560141694072324\n","Epoch: test     test index of 12 minibatch: 4      time used: 2.460838794708252\n","minibatch AVG loss: 0.36438849786645733\n","Epoch: test     test index of 12 minibatch: 5      time used: 2.4101970195770264\n","minibatch AVG loss: 0.2419606231784807\n","Epoch: test     test index of 12 minibatch: 6      time used: 2.3657925128936768\n","minibatch AVG loss: 0.17919500765856355\n","Epoch: test     test index of 12 minibatch: 7      time used: 2.403071403503418\n","minibatch AVG loss: 0.20485215715598315\n","Epoch: test     test index of 12 minibatch: 8      time used: 2.360386848449707\n","minibatch AVG loss: 0.15893071546937185\n","Epoch: test     test index of 12 minibatch: 9      time used: 2.3936285972595215\n","minibatch AVG loss: 0.21627691448763167\n","Epoch: test     test index of 12 minibatch: 10      time used: 2.423515558242798\n","minibatch AVG loss: 0.07541034081562732\n","Epoch: test     test index of 12 minibatch: 11      time used: 2.416491985321045\n","minibatch AVG loss: 0.1786380932026077\n","Epoch: test     test index of 12 minibatch: 12      time used: 2.413522243499756\n","minibatch AVG loss: 0.29367171390913427\n","Epoch: test     test index of 12 minibatch: 13      time used: 2.368386745452881\n","minibatch AVG loss: 0.23835404279331365\n","Epoch: test     test index of 12 minibatch: 14      time used: 2.380582094192505\n","minibatch AVG loss: 0.20407856076053577\n","Epoch: test     test index of 12 minibatch: 15      time used: 2.395411252975464\n","minibatch AVG loss: 0.28250806375096243\n","Epoch: test     test index of 12 minibatch: 16      time used: 2.4269332885742188\n","minibatch AVG loss: 0.0718928460458604\n","Epoch: test     test index of 12 minibatch: 17      time used: 2.3933465480804443\n","minibatch AVG loss: 0.5705558514067283\n","Epoch: test     test index of 12 minibatch: 18      time used: 2.4084410667419434\n","minibatch AVG loss: 0.3858813595143147\n","Epoch: test     test index of 12 minibatch: 19      time used: 2.3557958602905273\n","minibatch AVG loss: 0.1584530118840727\n","Epoch: test     test index of 12 minibatch: 20      time used: 2.3782739639282227\n","minibatch AVG loss: 0.28637338026116294\n","Epoch: test     test index of 12 minibatch: 21      time used: 2.393773078918457\n","minibatch AVG loss: 0.25459697472979315\n","\n","Epoch:  test \n","Loss: 0.2456  Acc: 91.2402\n","Negative precision: 91.1047  recall: 95.9215\n","Negative sensitivity: 95.9215  specificity: 82.4859\n","Negative FPR: 17.5141  NPV: 91.5361\n","Negative TP: 635.0\n","Negative TN: 292.0\n","Negative FP: 62.0\n","Negative FN: 27.0\n","Positive precision: 91.5361  recall: 82.4859\n","Positive sensitivity: 82.4859  specificity: 95.9215\n","Positive FPR: 4.0785  NPV: 91.1047\n","Positive TP: 292.0\n","Positive TN: 635.0\n","Positive FP: 27.0\n","Positive FN: 62.0\n","\n","\n","Testing complete in 3m 46s\n"]}],"source":["!python CellMix_test.py --model_idx ViT_384_401_PT_lf25_b8_ROSE_CLS --gpu_idx 0 --enable_visualize_check --edge_size 384 --data_augmentation_mode 0 --augmentation_name CellMix-Group --fix_position_ratio 0.5 --puzzle_patch_size 128 --batch_size 4 --enable_attention_check --shuffle_dataloader --dataroot /data/Pathology_Experiment/dataset/ROSE_CLS --model_path /home/Pathology_Experiment/saved_models --draw_root /home/Pathology_Experiment/imaging_results"]},{"cell_type":"markdown","source":["--fix_position_ratio 0.5 --puzzle_patch_size 192 --batch_size 4 --enable_attention_check --shuffle_dataloader"],"metadata":{"id":"ZHxg9jXa8_9e"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"nE717jo1Y-bq","outputId":"18077882-d5f8-48c7-e68d-244ac3268afa"},"outputs":[{"name":"stdout","output_type":"stream","text":["class_names: ['Negative', 'Positive']\n","['convit_base',\n"," 'convit_small',\n"," 'convit_tiny',\n"," 'crossvit_9_240',\n"," 'crossvit_9_dagger_240',\n"," 'crossvit_15_240',\n"," 'crossvit_15_dagger_240',\n"," 'crossvit_15_dagger_408',\n"," 'crossvit_18_240',\n"," 'crossvit_18_dagger_240',\n"," 'crossvit_18_dagger_408',\n"," 'crossvit_base_240',\n"," 'crossvit_small_240',\n"," 'crossvit_tiny_240',\n"," 'gcvit_base',\n"," 'gcvit_small',\n"," 'gcvit_tiny',\n"," 'gcvit_xtiny',\n"," 'gcvit_xxtiny',\n"," 'levit_128',\n"," 'levit_128s',\n"," 'levit_192',\n"," 'levit_256',\n"," 'levit_256d',\n"," 'levit_384',\n"," 'maxvit_base_224',\n"," 'maxvit_large_224',\n"," 'maxvit_nano_rw_256',\n"," 'maxvit_pico_rw_256',\n"," 'maxvit_rmlp_nano_rw_256',\n"," 'maxvit_rmlp_pico_rw_256',\n"," 'maxvit_rmlp_small_rw_224',\n"," 'maxvit_rmlp_small_rw_256',\n"," 'maxvit_rmlp_tiny_rw_256',\n"," 'maxvit_small_224',\n"," 'maxvit_tiny_224',\n"," 'maxvit_tiny_pm_256',\n"," 'maxvit_tiny_rw_224',\n"," 'maxvit_tiny_rw_256',\n"," 'maxvit_xlarge_224',\n"," 'maxxvit_rmlp_nano_rw_256',\n"," 'maxxvit_rmlp_small_rw_256',\n"," 'maxxvit_rmlp_tiny_rw_256',\n"," 'mobilevit_s',\n"," 'mobilevit_xs',\n"," 'mobilevit_xxs',\n"," 'mobilevitv2_050',\n"," 'mobilevitv2_075',\n"," 'mobilevitv2_100',\n"," 'mobilevitv2_125',\n"," 'mobilevitv2_150',\n"," 'mobilevitv2_150_384_in22ft1k',\n"," 'mobilevitv2_150_in22ft1k',\n"," 'mobilevitv2_175',\n"," 'mobilevitv2_175_384_in22ft1k',\n"," 'mobilevitv2_175_in22ft1k',\n"," 'mobilevitv2_200',\n"," 'mobilevitv2_200_384_in22ft1k',\n"," 'mobilevitv2_200_in22ft1k',\n"," 'mvitv2_base',\n"," 'mvitv2_large',\n"," 'mvitv2_small',\n"," 'mvitv2_small_cls',\n"," 'mvitv2_tiny',\n"," 'semobilevit_s',\n"," 'vit_base_patch8_224',\n"," 'vit_base_patch8_224_dino',\n"," 'vit_base_patch8_224_in21k',\n"," 'vit_base_patch16_18x2_224',\n"," 'vit_base_patch16_224',\n"," 'vit_base_patch16_224_dino',\n"," 'vit_base_patch16_224_in21k',\n"," 'vit_base_patch16_224_miil',\n"," 'vit_base_patch16_224_miil_in21k',\n"," 'vit_base_patch16_224_sam',\n"," 'vit_base_patch16_384',\n"," 'vit_base_patch16_plus_240',\n"," 'vit_base_patch16_rpn_224',\n"," 'vit_base_patch32_224',\n"," 'vit_base_patch32_224_clip_laion2b',\n"," 'vit_base_patch32_224_in21k',\n"," 'vit_base_patch32_224_sam',\n"," 'vit_base_patch32_384',\n"," 'vit_base_patch32_plus_256',\n"," 'vit_base_r26_s32_224',\n"," 'vit_base_r50_s16_224',\n"," 'vit_base_r50_s16_224_in21k',\n"," 'vit_base_r50_s16_384',\n"," 'vit_base_resnet26d_224',\n"," 'vit_base_resnet50_224_in21k',\n"," 'vit_base_resnet50_384',\n"," 'vit_base_resnet50d_224',\n"," 'vit_giant_patch14_224',\n"," 'vit_giant_patch14_224_clip_laion2b',\n"," 'vit_gigantic_patch14_224',\n"," 'vit_huge_patch14_224',\n"," 'vit_huge_patch14_224_clip_laion2b',\n"," 'vit_huge_patch14_224_in21k',\n"," 'vit_large_patch14_224',\n"," 'vit_large_patch14_224_clip_laion2b',\n"," 'vit_large_patch16_224',\n"," 'vit_large_patch16_224_in21k',\n"," 'vit_large_patch16_384',\n"," 'vit_large_patch32_224',\n"," 'vit_large_patch32_224_in21k',\n"," 'vit_large_patch32_384',\n"," 'vit_large_r50_s32_224',\n"," 'vit_large_r50_s32_224_in21k',\n"," 'vit_large_r50_s32_384',\n"," 'vit_relpos_base_patch16_224',\n"," 'vit_relpos_base_patch16_cls_224',\n"," 'vit_relpos_base_patch16_clsgap_224',\n"," 'vit_relpos_base_patch16_plus_240',\n"," 'vit_relpos_base_patch16_rpn_224',\n"," 'vit_relpos_base_patch32_plus_rpn_256',\n"," 'vit_relpos_medium_patch16_224',\n"," 'vit_relpos_medium_patch16_cls_224',\n"," 'vit_relpos_medium_patch16_rpn_224',\n"," 'vit_relpos_small_patch16_224',\n"," 'vit_relpos_small_patch16_rpn_224',\n"," 'vit_small_patch8_224_dino',\n"," 'vit_small_patch16_18x2_224',\n"," 'vit_small_patch16_36x1_224',\n"," 'vit_small_patch16_224',\n"," 'vit_small_patch16_224_dino',\n"," 'vit_small_patch16_224_in21k',\n"," 'vit_small_patch16_384',\n"," 'vit_small_patch32_224',\n"," 'vit_small_patch32_224_in21k',\n"," 'vit_small_patch32_384',\n"," 'vit_small_r26_s32_224',\n"," 'vit_small_r26_s32_224_in21k',\n"," 'vit_small_r26_s32_384',\n"," 'vit_small_resnet26d_224',\n"," 'vit_small_resnet50d_s16_224',\n"," 'vit_srelpos_medium_patch16_224',\n"," 'vit_srelpos_small_patch16_224',\n"," 'vit_tiny_patch16_224',\n"," 'vit_tiny_patch16_224_in21k',\n"," 'vit_tiny_patch16_384',\n"," 'vit_tiny_r_s16_p8_224',\n"," 'vit_tiny_r_s16_p8_224_in21k',\n"," 'vit_tiny_r_s16_p8_384']\n","test model output： tensor([[-0.6989, -1.9324]], grad_fn=<AddmmBackward0>)\n","model is ready now!\n","model loaded\n","model : ViT_384_401_PT_lf25_b8_ROSE_CLS\n","*********************************setting*************************************\n","Namespace(Pre_Trained_model_path=None, PromptTuning=None, PromptUnFreeze=False, Prompt_Token_num=10, att_module='SimAM', attn_drop_rate=0.0, augmentation_name='CellMix-Group', batch_size=4, check_minibatch=None, cls_token_off=False, data_augmentation_mode=0, dataroot='/data/Pathology_Experiment/dataset/ROSE_CLS', draw_root='/home/Pathology_Experiment/imaging_results', drop_path_rate=0.0, drop_rate=0.0, edge_size=384, enable_attention_check=True, enable_notify=False, enable_tensorboard=False, enable_visualize_check=True, fix_position_ratio=0.5, gpu_idx=0, model_idx='ViT_384_401_PT_lf25_b8_ROSE_CLS', model_path='/home/Pathology_Experiment/saved_models', model_path_by_hand=None, num_classes=0, paint=True, pos_embedding_off=False, puzzle_patch_size=192, shuffle_dataloader=True)\n","Epoch: Test\n","\n","useing  CellMix-Group \n","\n","----------\n","Epoch: test     test index of 12 minibatch: 1      time used: 2.549443483352661\n","minibatch AVG loss: 0.33603193257780123\n","/home/Pathology_Experiment/code/utils/visual_usage.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  return sof(x)\n","Epoch: test     test index of 12 minibatch: 2      time used: 2.397050619125366\n","minibatch AVG loss: 0.2959729031911896\n","Epoch: test     test index of 12 minibatch: 3      time used: 2.4613003730773926\n","minibatch AVG loss: 0.21171106931069517\n","Epoch: test     test index of 12 minibatch: 4      time used: 2.417184829711914\n","minibatch AVG loss: 0.26529252573285095\n","Epoch: test     test index of 12 minibatch: 5      time used: 2.376858711242676\n","minibatch AVG loss: 0.10226839020227392\n","Epoch: test     test index of 12 minibatch: 6      time used: 2.375492572784424\n","minibatch AVG loss: 0.1876417026457299\n","Epoch: test     test index of 12 minibatch: 7      time used: 2.3895344734191895\n","minibatch AVG loss: 0.5551233201961926\n","Epoch: test     test index of 12 minibatch: 8      time used: 2.4179916381835938\n","minibatch AVG loss: 0.12141207954846323\n","Epoch: test     test index of 12 minibatch: 9      time used: 2.3839452266693115\n","minibatch AVG loss: 0.31738067177745205\n","Epoch: test     test index of 12 minibatch: 10      time used: 2.352033853530884\n","minibatch AVG loss: 0.16449537930020597\n","Epoch: test     test index of 12 minibatch: 11      time used: 2.402113914489746\n","minibatch AVG loss: 0.2904071610925409\n","Epoch: test     test index of 12 minibatch: 12      time used: 2.4359450340270996\n","minibatch AVG loss: 0.18760364510429403\n","Epoch: test     test index of 12 minibatch: 13      time used: 2.3569488525390625\n","minibatch AVG loss: 0.3117777634567271\n","Epoch: test     test index of 12 minibatch: 14      time used: 2.357370615005493\n","minibatch AVG loss: 0.1801706588982294\n","Epoch: test     test index of 12 minibatch: 15      time used: 2.398484230041504\n","minibatch AVG loss: 0.3139077202649787\n","Epoch: test     test index of 12 minibatch: 16      time used: 2.3719725608825684\n","minibatch AVG loss: 0.26063374997950933\n","Epoch: test     test index of 12 minibatch: 17      time used: 2.393430709838867\n","minibatch AVG loss: 0.15113392212272933\n","Epoch: test     test index of 12 minibatch: 18      time used: 2.410329818725586\n","minibatch AVG loss: 0.31474802278292674\n","Epoch: test     test index of 12 minibatch: 19      time used: 2.385601282119751\n","minibatch AVG loss: 0.15118094890688857\n","Epoch: test     test index of 12 minibatch: 20      time used: 2.35113525390625\n","minibatch AVG loss: 0.25862667392842315\n","Epoch: test     test index of 12 minibatch: 21      time used: 2.412602424621582\n","minibatch AVG loss: 0.20510765425569844\n","\n","Epoch:  test \n","Loss: 0.2456  Acc: 91.2402\n","Negative precision: 91.1047  recall: 95.9215\n","Negative sensitivity: 95.9215  specificity: 82.4859\n","Negative FPR: 17.5141  NPV: 91.5361\n","Negative TP: 635.0\n","Negative TN: 292.0\n","Negative FP: 62.0\n","Negative FN: 27.0\n","Positive precision: 91.5361  recall: 82.4859\n","Positive sensitivity: 82.4859  specificity: 95.9215\n","Positive FPR: 4.0785  NPV: 91.1047\n","Positive TP: 292.0\n","Positive TN: 635.0\n","Positive FP: 27.0\n","Positive FN: 62.0\n","\n","\n","Testing complete in 3m 46s\n"]}],"source":["!python CellMix_test.py --model_idx ViT_384_401_PT_lf25_b8_ROSE_CLS --gpu_idx 0 --enable_visualize_check --edge_size 384 --data_augmentation_mode 0 --augmentation_name CellMix-Group --fix_position_ratio 0.5 --puzzle_patch_size 192 --batch_size 4 --enable_attention_check --shuffle_dataloader --dataroot /data/Pathology_Experiment/dataset/ROSE_CLS --model_path /home/Pathology_Experiment/saved_models --draw_root /home/Pathology_Experiment/imaging_results"]},{"cell_type":"markdown","metadata":{"id":"reTqqd5dW7bY"},"source":["## CellMix Trained ViT"]},{"cell_type":"markdown","source":["--fix_position_ratio 0.5 --puzzle_patch_size 16 --batch_size 4 --enable_attention_check --shuffle_dataloader"],"metadata":{"id":"SNhvsXx49Mp9"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"m96LONrw3UBe","outputId":"965337ba-813b-46fb-9988-aad2dac1abd1"},"outputs":[{"name":"stdout","output_type":"stream","text":["class_names: ['Negative', 'Positive']\n","['convit_base',\n"," 'convit_small',\n"," 'convit_tiny',\n"," 'crossvit_9_240',\n"," 'crossvit_9_dagger_240',\n"," 'crossvit_15_240',\n"," 'crossvit_15_dagger_240',\n"," 'crossvit_15_dagger_408',\n"," 'crossvit_18_240',\n"," 'crossvit_18_dagger_240',\n"," 'crossvit_18_dagger_408',\n"," 'crossvit_base_240',\n"," 'crossvit_small_240',\n"," 'crossvit_tiny_240',\n"," 'gcvit_base',\n"," 'gcvit_small',\n"," 'gcvit_tiny',\n"," 'gcvit_xtiny',\n"," 'gcvit_xxtiny',\n"," 'levit_128',\n"," 'levit_128s',\n"," 'levit_192',\n"," 'levit_256',\n"," 'levit_256d',\n"," 'levit_384',\n"," 'maxvit_base_224',\n"," 'maxvit_large_224',\n"," 'maxvit_nano_rw_256',\n"," 'maxvit_pico_rw_256',\n"," 'maxvit_rmlp_nano_rw_256',\n"," 'maxvit_rmlp_pico_rw_256',\n"," 'maxvit_rmlp_small_rw_224',\n"," 'maxvit_rmlp_small_rw_256',\n"," 'maxvit_rmlp_tiny_rw_256',\n"," 'maxvit_small_224',\n"," 'maxvit_tiny_224',\n"," 'maxvit_tiny_pm_256',\n"," 'maxvit_tiny_rw_224',\n"," 'maxvit_tiny_rw_256',\n"," 'maxvit_xlarge_224',\n"," 'maxxvit_rmlp_nano_rw_256',\n"," 'maxxvit_rmlp_small_rw_256',\n"," 'maxxvit_rmlp_tiny_rw_256',\n"," 'mobilevit_s',\n"," 'mobilevit_xs',\n"," 'mobilevit_xxs',\n"," 'mobilevitv2_050',\n"," 'mobilevitv2_075',\n"," 'mobilevitv2_100',\n"," 'mobilevitv2_125',\n"," 'mobilevitv2_150',\n"," 'mobilevitv2_150_384_in22ft1k',\n"," 'mobilevitv2_150_in22ft1k',\n"," 'mobilevitv2_175',\n"," 'mobilevitv2_175_384_in22ft1k',\n"," 'mobilevitv2_175_in22ft1k',\n"," 'mobilevitv2_200',\n"," 'mobilevitv2_200_384_in22ft1k',\n"," 'mobilevitv2_200_in22ft1k',\n"," 'mvitv2_base',\n"," 'mvitv2_large',\n"," 'mvitv2_small',\n"," 'mvitv2_small_cls',\n"," 'mvitv2_tiny',\n"," 'semobilevit_s',\n"," 'vit_base_patch8_224',\n"," 'vit_base_patch8_224_dino',\n"," 'vit_base_patch8_224_in21k',\n"," 'vit_base_patch16_18x2_224',\n"," 'vit_base_patch16_224',\n"," 'vit_base_patch16_224_dino',\n"," 'vit_base_patch16_224_in21k',\n"," 'vit_base_patch16_224_miil',\n"," 'vit_base_patch16_224_miil_in21k',\n"," 'vit_base_patch16_224_sam',\n"," 'vit_base_patch16_384',\n"," 'vit_base_patch16_plus_240',\n"," 'vit_base_patch16_rpn_224',\n"," 'vit_base_patch32_224',\n"," 'vit_base_patch32_224_clip_laion2b',\n"," 'vit_base_patch32_224_in21k',\n"," 'vit_base_patch32_224_sam',\n"," 'vit_base_patch32_384',\n"," 'vit_base_patch32_plus_256',\n"," 'vit_base_r26_s32_224',\n"," 'vit_base_r50_s16_224',\n"," 'vit_base_r50_s16_224_in21k',\n"," 'vit_base_r50_s16_384',\n"," 'vit_base_resnet26d_224',\n"," 'vit_base_resnet50_224_in21k',\n"," 'vit_base_resnet50_384',\n"," 'vit_base_resnet50d_224',\n"," 'vit_giant_patch14_224',\n"," 'vit_giant_patch14_224_clip_laion2b',\n"," 'vit_gigantic_patch14_224',\n"," 'vit_huge_patch14_224',\n"," 'vit_huge_patch14_224_clip_laion2b',\n"," 'vit_huge_patch14_224_in21k',\n"," 'vit_large_patch14_224',\n"," 'vit_large_patch14_224_clip_laion2b',\n"," 'vit_large_patch16_224',\n"," 'vit_large_patch16_224_in21k',\n"," 'vit_large_patch16_384',\n"," 'vit_large_patch32_224',\n"," 'vit_large_patch32_224_in21k',\n"," 'vit_large_patch32_384',\n"," 'vit_large_r50_s32_224',\n"," 'vit_large_r50_s32_224_in21k',\n"," 'vit_large_r50_s32_384',\n"," 'vit_relpos_base_patch16_224',\n"," 'vit_relpos_base_patch16_cls_224',\n"," 'vit_relpos_base_patch16_clsgap_224',\n"," 'vit_relpos_base_patch16_plus_240',\n"," 'vit_relpos_base_patch16_rpn_224',\n"," 'vit_relpos_base_patch32_plus_rpn_256',\n"," 'vit_relpos_medium_patch16_224',\n"," 'vit_relpos_medium_patch16_cls_224',\n"," 'vit_relpos_medium_patch16_rpn_224',\n"," 'vit_relpos_small_patch16_224',\n"," 'vit_relpos_small_patch16_rpn_224',\n"," 'vit_small_patch8_224_dino',\n"," 'vit_small_patch16_18x2_224',\n"," 'vit_small_patch16_36x1_224',\n"," 'vit_small_patch16_224',\n"," 'vit_small_patch16_224_dino',\n"," 'vit_small_patch16_224_in21k',\n"," 'vit_small_patch16_384',\n"," 'vit_small_patch32_224',\n"," 'vit_small_patch32_224_in21k',\n"," 'vit_small_patch32_384',\n"," 'vit_small_r26_s32_224',\n"," 'vit_small_r26_s32_224_in21k',\n"," 'vit_small_r26_s32_384',\n"," 'vit_small_resnet26d_224',\n"," 'vit_small_resnet50d_s16_224',\n"," 'vit_srelpos_medium_patch16_224',\n"," 'vit_srelpos_small_patch16_224',\n"," 'vit_tiny_patch16_224',\n"," 'vit_tiny_patch16_224_in21k',\n"," 'vit_tiny_patch16_384',\n"," 'vit_tiny_r_s16_p8_224',\n"," 'vit_tiny_r_s16_p8_224_in21k',\n"," 'vit_tiny_r_s16_p8_384']\n","test model output： tensor([[-1.1282, -1.1510]], grad_fn=<AddmmBackward0>)\n","model is ready now!\n","model loaded\n","model : ViT_384_401_PT_lf25_b8_ROSE_CellMix_Group_CLS\n","*********************************setting*************************************\n","Namespace(Pre_Trained_model_path=None, PromptTuning=None, PromptUnFreeze=False, Prompt_Token_num=10, att_module='SimAM', attn_drop_rate=0.0, augmentation_name='CellMix-Group', batch_size=4, check_minibatch=None, cls_token_off=False, data_augmentation_mode=0, dataroot='/data/Pathology_Experiment/dataset/ROSE_CLS', draw_root='/home/Pathology_Experiment/imaging_results', drop_path_rate=0.0, drop_rate=0.0, edge_size=384, enable_attention_check=True, enable_notify=False, enable_tensorboard=False, enable_visualize_check=True, fix_position_ratio=0.5, gpu_idx=0, model_idx='ViT_384_401_PT_lf25_b8_ROSE_CellMix_Group_CLS', model_path='/home/Pathology_Experiment/saved_models', model_path_by_hand=None, num_classes=0, paint=True, pos_embedding_off=False, puzzle_patch_size=16, shuffle_dataloader=True)\n","Epoch: Test\n","\n","useing  CellMix-Group \n","\n","----------\n","Epoch: test     test index of 12 minibatch: 1      time used: 2.5588114261627197\n","minibatch AVG loss: 0.1421453274791323\n","/home/Pathology_Experiment/code/utils/visual_usage.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  return sof(x)\n","Epoch: test     test index of 12 minibatch: 2      time used: 2.3617823123931885\n","minibatch AVG loss: 0.43691974179819226\n","Epoch: test     test index of 12 minibatch: 3      time used: 2.4337735176086426\n","minibatch AVG loss: 0.22954848092172142\n","Epoch: test     test index of 12 minibatch: 4      time used: 2.4916841983795166\n","minibatch AVG loss: 0.4292554303289459\n","Epoch: test     test index of 12 minibatch: 5      time used: 2.4576587677001953\n","minibatch AVG loss: 0.07276210417330731\n","Epoch: test     test index of 12 minibatch: 6      time used: 2.3797738552093506\n","minibatch AVG loss: 0.10372756724245846\n","Epoch: test     test index of 12 minibatch: 7      time used: 2.3603663444519043\n","minibatch AVG loss: 0.11104771402218223\n","Epoch: test     test index of 12 minibatch: 8      time used: 2.3807501792907715\n","minibatch AVG loss: 0.340806543637882\n","Epoch: test     test index of 12 minibatch: 9      time used: 2.3929548263549805\n","minibatch AVG loss: 0.19497011010632073\n","Epoch: test     test index of 12 minibatch: 10      time used: 2.3875954151153564\n","minibatch AVG loss: 0.15477283464254774\n","Epoch: test     test index of 12 minibatch: 11      time used: 2.371250867843628\n","minibatch AVG loss: 0.22899050418588254\n","Epoch: test     test index of 12 minibatch: 12      time used: 2.3812005519866943\n","minibatch AVG loss: 0.10377440634996067\n","Epoch: test     test index of 12 minibatch: 13      time used: 2.4218523502349854\n","minibatch AVG loss: 0.4492661664019882\n","Epoch: test     test index of 12 minibatch: 14      time used: 2.4213321208953857\n","minibatch AVG loss: 0.053543470391256655\n","Epoch: test     test index of 12 minibatch: 15      time used: 2.4029605388641357\n","minibatch AVG loss: 0.2054786353255622\n","Epoch: test     test index of 12 minibatch: 16      time used: 2.3755877017974854\n","minibatch AVG loss: 0.22193177071865952\n","Epoch: test     test index of 12 minibatch: 17      time used: 2.3752567768096924\n","minibatch AVG loss: 0.12775703396861596\n","Epoch: test     test index of 12 minibatch: 18      time used: 2.4073681831359863\n","minibatch AVG loss: 0.09052299701003601\n","Epoch: test     test index of 12 minibatch: 19      time used: 2.415834665298462\n","minibatch AVG loss: 0.2623930416787819\n","Epoch: test     test index of 12 minibatch: 20      time used: 2.412015676498413\n","minibatch AVG loss: 0.2337525386537891\n","Epoch: test     test index of 12 minibatch: 21      time used: 2.418092966079712\n","minibatch AVG loss: 0.2735255021874157\n","\n","Epoch:  test \n","Loss: 0.2112  Acc: 93.3071\n","Negative precision: 93.5484  recall: 96.3746\n","Negative sensitivity: 96.3746  specificity: 87.5706\n","Negative FPR: 12.4294  NPV: 92.8144\n","Negative TP: 638.0\n","Negative TN: 310.0\n","Negative FP: 44.0\n","Negative FN: 24.0\n","Positive precision: 92.8144  recall: 87.5706\n","Positive sensitivity: 87.5706  specificity: 96.3746\n","Positive FPR: 3.6254  NPV: 93.5484\n","Positive TP: 310.0\n","Positive TN: 638.0\n","Positive FP: 24.0\n","Positive FN: 44.0\n","\n","\n","Testing complete in 3m 46s\n"]}],"source":["!python CellMix_test.py --model_idx ViT_384_401_PT_lf25_b8_ROSE_CellMix_Group_CLS --gpu_idx 0 --enable_visualize_check --edge_size 384 --data_augmentation_mode 0 --augmentation_name CellMix-Group --fix_position_ratio 0.5 --puzzle_patch_size 16 --batch_size 4 --enable_attention_check --shuffle_dataloader --dataroot /data/Pathology_Experiment/dataset/ROSE_CLS --model_path /home/Pathology_Experiment/saved_models --draw_root /home/Pathology_Experiment/imaging_results"]},{"cell_type":"markdown","source":["--fix_position_ratio 0.5 --puzzle_patch_size 32 --batch_size 4 --enable_attention_check --shuffle_dataloader"],"metadata":{"id":"HYJaprBG9N8_"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"AXkNS2xAZBzi","outputId":"00381c2b-3fd1-47ae-b0e4-015eead6e9aa"},"outputs":[{"name":"stdout","output_type":"stream","text":["class_names: ['Negative', 'Positive']\n","['convit_base',\n"," 'convit_small',\n"," 'convit_tiny',\n"," 'crossvit_9_240',\n"," 'crossvit_9_dagger_240',\n"," 'crossvit_15_240',\n"," 'crossvit_15_dagger_240',\n"," 'crossvit_15_dagger_408',\n"," 'crossvit_18_240',\n"," 'crossvit_18_dagger_240',\n"," 'crossvit_18_dagger_408',\n"," 'crossvit_base_240',\n"," 'crossvit_small_240',\n"," 'crossvit_tiny_240',\n"," 'gcvit_base',\n"," 'gcvit_small',\n"," 'gcvit_tiny',\n"," 'gcvit_xtiny',\n"," 'gcvit_xxtiny',\n"," 'levit_128',\n"," 'levit_128s',\n"," 'levit_192',\n"," 'levit_256',\n"," 'levit_256d',\n"," 'levit_384',\n"," 'maxvit_base_224',\n"," 'maxvit_large_224',\n"," 'maxvit_nano_rw_256',\n"," 'maxvit_pico_rw_256',\n"," 'maxvit_rmlp_nano_rw_256',\n"," 'maxvit_rmlp_pico_rw_256',\n"," 'maxvit_rmlp_small_rw_224',\n"," 'maxvit_rmlp_small_rw_256',\n"," 'maxvit_rmlp_tiny_rw_256',\n"," 'maxvit_small_224',\n"," 'maxvit_tiny_224',\n"," 'maxvit_tiny_pm_256',\n"," 'maxvit_tiny_rw_224',\n"," 'maxvit_tiny_rw_256',\n"," 'maxvit_xlarge_224',\n"," 'maxxvit_rmlp_nano_rw_256',\n"," 'maxxvit_rmlp_small_rw_256',\n"," 'maxxvit_rmlp_tiny_rw_256',\n"," 'mobilevit_s',\n"," 'mobilevit_xs',\n"," 'mobilevit_xxs',\n"," 'mobilevitv2_050',\n"," 'mobilevitv2_075',\n"," 'mobilevitv2_100',\n"," 'mobilevitv2_125',\n"," 'mobilevitv2_150',\n"," 'mobilevitv2_150_384_in22ft1k',\n"," 'mobilevitv2_150_in22ft1k',\n"," 'mobilevitv2_175',\n"," 'mobilevitv2_175_384_in22ft1k',\n"," 'mobilevitv2_175_in22ft1k',\n"," 'mobilevitv2_200',\n"," 'mobilevitv2_200_384_in22ft1k',\n"," 'mobilevitv2_200_in22ft1k',\n"," 'mvitv2_base',\n"," 'mvitv2_large',\n"," 'mvitv2_small',\n"," 'mvitv2_small_cls',\n"," 'mvitv2_tiny',\n"," 'semobilevit_s',\n"," 'vit_base_patch8_224',\n"," 'vit_base_patch8_224_dino',\n"," 'vit_base_patch8_224_in21k',\n"," 'vit_base_patch16_18x2_224',\n"," 'vit_base_patch16_224',\n"," 'vit_base_patch16_224_dino',\n"," 'vit_base_patch16_224_in21k',\n"," 'vit_base_patch16_224_miil',\n"," 'vit_base_patch16_224_miil_in21k',\n"," 'vit_base_patch16_224_sam',\n"," 'vit_base_patch16_384',\n"," 'vit_base_patch16_plus_240',\n"," 'vit_base_patch16_rpn_224',\n"," 'vit_base_patch32_224',\n"," 'vit_base_patch32_224_clip_laion2b',\n"," 'vit_base_patch32_224_in21k',\n"," 'vit_base_patch32_224_sam',\n"," 'vit_base_patch32_384',\n"," 'vit_base_patch32_plus_256',\n"," 'vit_base_r26_s32_224',\n"," 'vit_base_r50_s16_224',\n"," 'vit_base_r50_s16_224_in21k',\n"," 'vit_base_r50_s16_384',\n"," 'vit_base_resnet26d_224',\n"," 'vit_base_resnet50_224_in21k',\n"," 'vit_base_resnet50_384',\n"," 'vit_base_resnet50d_224',\n"," 'vit_giant_patch14_224',\n"," 'vit_giant_patch14_224_clip_laion2b',\n"," 'vit_gigantic_patch14_224',\n"," 'vit_huge_patch14_224',\n"," 'vit_huge_patch14_224_clip_laion2b',\n"," 'vit_huge_patch14_224_in21k',\n"," 'vit_large_patch14_224',\n"," 'vit_large_patch14_224_clip_laion2b',\n"," 'vit_large_patch16_224',\n"," 'vit_large_patch16_224_in21k',\n"," 'vit_large_patch16_384',\n"," 'vit_large_patch32_224',\n"," 'vit_large_patch32_224_in21k',\n"," 'vit_large_patch32_384',\n"," 'vit_large_r50_s32_224',\n"," 'vit_large_r50_s32_224_in21k',\n"," 'vit_large_r50_s32_384',\n"," 'vit_relpos_base_patch16_224',\n"," 'vit_relpos_base_patch16_cls_224',\n"," 'vit_relpos_base_patch16_clsgap_224',\n"," 'vit_relpos_base_patch16_plus_240',\n"," 'vit_relpos_base_patch16_rpn_224',\n"," 'vit_relpos_base_patch32_plus_rpn_256',\n"," 'vit_relpos_medium_patch16_224',\n"," 'vit_relpos_medium_patch16_cls_224',\n"," 'vit_relpos_medium_patch16_rpn_224',\n"," 'vit_relpos_small_patch16_224',\n"," 'vit_relpos_small_patch16_rpn_224',\n"," 'vit_small_patch8_224_dino',\n"," 'vit_small_patch16_18x2_224',\n"," 'vit_small_patch16_36x1_224',\n"," 'vit_small_patch16_224',\n"," 'vit_small_patch16_224_dino',\n"," 'vit_small_patch16_224_in21k',\n"," 'vit_small_patch16_384',\n"," 'vit_small_patch32_224',\n"," 'vit_small_patch32_224_in21k',\n"," 'vit_small_patch32_384',\n"," 'vit_small_r26_s32_224',\n"," 'vit_small_r26_s32_224_in21k',\n"," 'vit_small_r26_s32_384',\n"," 'vit_small_resnet26d_224',\n"," 'vit_small_resnet50d_s16_224',\n"," 'vit_srelpos_medium_patch16_224',\n"," 'vit_srelpos_small_patch16_224',\n"," 'vit_tiny_patch16_224',\n"," 'vit_tiny_patch16_224_in21k',\n"," 'vit_tiny_patch16_384',\n"," 'vit_tiny_r_s16_p8_224',\n"," 'vit_tiny_r_s16_p8_224_in21k',\n"," 'vit_tiny_r_s16_p8_384']\n","test model output： tensor([[-0.6940, -0.8271]], grad_fn=<AddmmBackward0>)\n","model is ready now!\n","model loaded\n","model : ViT_384_401_PT_lf25_b8_ROSE_CellMix_Group_CLS\n","*********************************setting*************************************\n","Namespace(Pre_Trained_model_path=None, PromptTuning=None, PromptUnFreeze=False, Prompt_Token_num=10, att_module='SimAM', attn_drop_rate=0.0, augmentation_name='CellMix-Group', batch_size=4, check_minibatch=None, cls_token_off=False, data_augmentation_mode=0, dataroot='/data/Pathology_Experiment/dataset/ROSE_CLS', draw_root='/home/Pathology_Experiment/imaging_results', drop_path_rate=0.0, drop_rate=0.0, edge_size=384, enable_attention_check=True, enable_notify=False, enable_tensorboard=False, enable_visualize_check=True, fix_position_ratio=0.5, gpu_idx=0, model_idx='ViT_384_401_PT_lf25_b8_ROSE_CellMix_Group_CLS', model_path='/home/Pathology_Experiment/saved_models', model_path_by_hand=None, num_classes=0, paint=True, pos_embedding_off=False, puzzle_patch_size=32, shuffle_dataloader=True)\n","Epoch: Test\n","\n","useing  CellMix-Group \n","\n","----------\n","Epoch: test     test index of 12 minibatch: 1      time used: 2.5595691204071045\n","minibatch AVG loss: 0.18316621620882265\n","/home/Pathology_Experiment/code/utils/visual_usage.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  return sof(x)\n","Epoch: test     test index of 12 minibatch: 2      time used: 2.375105381011963\n","minibatch AVG loss: 0.34606924214555573\n","Epoch: test     test index of 12 minibatch: 3      time used: 2.469454526901245\n","minibatch AVG loss: 0.34455158749672893\n","Epoch: test     test index of 12 minibatch: 4      time used: 2.4614222049713135\n","minibatch AVG loss: 0.1686224459360043\n","Epoch: test     test index of 12 minibatch: 5      time used: 2.427912712097168\n","minibatch AVG loss: 0.34934942517763073\n","Epoch: test     test index of 12 minibatch: 6      time used: 2.377910614013672\n","minibatch AVG loss: 0.30126633130081854\n","Epoch: test     test index of 12 minibatch: 7      time used: 2.3671679496765137\n","minibatch AVG loss: 0.38754166979924776\n","Epoch: test     test index of 12 minibatch: 8      time used: 2.4007816314697266\n","minibatch AVG loss: 0.21546259509007845\n","Epoch: test     test index of 12 minibatch: 9      time used: 2.3976023197174072\n","minibatch AVG loss: 0.1673318618106805\n","Epoch: test     test index of 12 minibatch: 10      time used: 2.413024425506592\n","minibatch AVG loss: 0.1595216733403504\n","Epoch: test     test index of 12 minibatch: 11      time used: 2.4196248054504395\n","minibatch AVG loss: 0.10905567597243741\n","Epoch: test     test index of 12 minibatch: 12      time used: 2.409435987472534\n","minibatch AVG loss: 0.08923897861192624\n","Epoch: test     test index of 12 minibatch: 13      time used: 2.390448570251465\n","minibatch AVG loss: 0.0669102495497403\n","Epoch: test     test index of 12 minibatch: 14      time used: 2.349200487136841\n","minibatch AVG loss: 0.19108661685125602\n","Epoch: test     test index of 12 minibatch: 15      time used: 2.402231216430664\n","minibatch AVG loss: 0.195276911292846\n","Epoch: test     test index of 12 minibatch: 16      time used: 2.420637607574463\n","minibatch AVG loss: 0.22192493083942585\n","Epoch: test     test index of 12 minibatch: 17      time used: 2.388019323348999\n","minibatch AVG loss: 0.10980611198222807\n","Epoch: test     test index of 12 minibatch: 18      time used: 2.3994808197021484\n","minibatch AVG loss: 0.16094234568299726\n","Epoch: test     test index of 12 minibatch: 19      time used: 2.407754898071289\n","minibatch AVG loss: 0.13790820794141231\n","Epoch: test     test index of 12 minibatch: 20      time used: 2.390753984451294\n","minibatch AVG loss: 0.24070117028895766\n","Epoch: test     test index of 12 minibatch: 21      time used: 2.3706068992614746\n","minibatch AVG loss: 0.3113800768114743\n","\n","Epoch:  test \n","Loss: 0.2112  Acc: 93.3071\n","Negative precision: 93.5484  recall: 96.3746\n","Negative sensitivity: 96.3746  specificity: 87.5706\n","Negative FPR: 12.4294  NPV: 92.8144\n","Negative TP: 638.0\n","Negative TN: 310.0\n","Negative FP: 44.0\n","Negative FN: 24.0\n","Positive precision: 92.8144  recall: 87.5706\n","Positive sensitivity: 87.5706  specificity: 96.3746\n","Positive FPR: 3.6254  NPV: 93.5484\n","Positive TP: 310.0\n","Positive TN: 638.0\n","Positive FP: 24.0\n","Positive FN: 44.0\n","\n","\n","Testing complete in 3m 46s\n"]}],"source":["!python CellMix_test.py --model_idx ViT_384_401_PT_lf25_b8_ROSE_CellMix_Group_CLS --gpu_idx 0 --enable_visualize_check --edge_size 384 --data_augmentation_mode 0 --augmentation_name CellMix-Group --fix_position_ratio 0.5 --puzzle_patch_size 32 --batch_size 4 --enable_attention_check --shuffle_dataloader --dataroot /data/Pathology_Experiment/dataset/ROSE_CLS --model_path /home/Pathology_Experiment/saved_models --draw_root /home/Pathology_Experiment/imaging_results"]},{"cell_type":"markdown","source":["--fix_position_ratio 0.5 --puzzle_patch_size 48 --batch_size 4 --enable_attention_check --shuffle_dataloader"],"metadata":{"id":"1MytndvZ9P58"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"IJr9pJ1gZG5N","outputId":"e9905545-9f83-4e5d-d038-763c9b298253"},"outputs":[{"name":"stdout","output_type":"stream","text":["class_names: ['Negative', 'Positive']\n","['convit_base',\n"," 'convit_small',\n"," 'convit_tiny',\n"," 'crossvit_9_240',\n"," 'crossvit_9_dagger_240',\n"," 'crossvit_15_240',\n"," 'crossvit_15_dagger_240',\n"," 'crossvit_15_dagger_408',\n"," 'crossvit_18_240',\n"," 'crossvit_18_dagger_240',\n"," 'crossvit_18_dagger_408',\n"," 'crossvit_base_240',\n"," 'crossvit_small_240',\n"," 'crossvit_tiny_240',\n"," 'gcvit_base',\n"," 'gcvit_small',\n"," 'gcvit_tiny',\n"," 'gcvit_xtiny',\n"," 'gcvit_xxtiny',\n"," 'levit_128',\n"," 'levit_128s',\n"," 'levit_192',\n"," 'levit_256',\n"," 'levit_256d',\n"," 'levit_384',\n"," 'maxvit_base_224',\n"," 'maxvit_large_224',\n"," 'maxvit_nano_rw_256',\n"," 'maxvit_pico_rw_256',\n"," 'maxvit_rmlp_nano_rw_256',\n"," 'maxvit_rmlp_pico_rw_256',\n"," 'maxvit_rmlp_small_rw_224',\n"," 'maxvit_rmlp_small_rw_256',\n"," 'maxvit_rmlp_tiny_rw_256',\n"," 'maxvit_small_224',\n"," 'maxvit_tiny_224',\n"," 'maxvit_tiny_pm_256',\n"," 'maxvit_tiny_rw_224',\n"," 'maxvit_tiny_rw_256',\n"," 'maxvit_xlarge_224',\n"," 'maxxvit_rmlp_nano_rw_256',\n"," 'maxxvit_rmlp_small_rw_256',\n"," 'maxxvit_rmlp_tiny_rw_256',\n"," 'mobilevit_s',\n"," 'mobilevit_xs',\n"," 'mobilevit_xxs',\n"," 'mobilevitv2_050',\n"," 'mobilevitv2_075',\n"," 'mobilevitv2_100',\n"," 'mobilevitv2_125',\n"," 'mobilevitv2_150',\n"," 'mobilevitv2_150_384_in22ft1k',\n"," 'mobilevitv2_150_in22ft1k',\n"," 'mobilevitv2_175',\n"," 'mobilevitv2_175_384_in22ft1k',\n"," 'mobilevitv2_175_in22ft1k',\n"," 'mobilevitv2_200',\n"," 'mobilevitv2_200_384_in22ft1k',\n"," 'mobilevitv2_200_in22ft1k',\n"," 'mvitv2_base',\n"," 'mvitv2_large',\n"," 'mvitv2_small',\n"," 'mvitv2_small_cls',\n"," 'mvitv2_tiny',\n"," 'semobilevit_s',\n"," 'vit_base_patch8_224',\n"," 'vit_base_patch8_224_dino',\n"," 'vit_base_patch8_224_in21k',\n"," 'vit_base_patch16_18x2_224',\n"," 'vit_base_patch16_224',\n"," 'vit_base_patch16_224_dino',\n"," 'vit_base_patch16_224_in21k',\n"," 'vit_base_patch16_224_miil',\n"," 'vit_base_patch16_224_miil_in21k',\n"," 'vit_base_patch16_224_sam',\n"," 'vit_base_patch16_384',\n"," 'vit_base_patch16_plus_240',\n"," 'vit_base_patch16_rpn_224',\n"," 'vit_base_patch32_224',\n"," 'vit_base_patch32_224_clip_laion2b',\n"," 'vit_base_patch32_224_in21k',\n"," 'vit_base_patch32_224_sam',\n"," 'vit_base_patch32_384',\n"," 'vit_base_patch32_plus_256',\n"," 'vit_base_r26_s32_224',\n"," 'vit_base_r50_s16_224',\n"," 'vit_base_r50_s16_224_in21k',\n"," 'vit_base_r50_s16_384',\n"," 'vit_base_resnet26d_224',\n"," 'vit_base_resnet50_224_in21k',\n"," 'vit_base_resnet50_384',\n"," 'vit_base_resnet50d_224',\n"," 'vit_giant_patch14_224',\n"," 'vit_giant_patch14_224_clip_laion2b',\n"," 'vit_gigantic_patch14_224',\n"," 'vit_huge_patch14_224',\n"," 'vit_huge_patch14_224_clip_laion2b',\n"," 'vit_huge_patch14_224_in21k',\n"," 'vit_large_patch14_224',\n"," 'vit_large_patch14_224_clip_laion2b',\n"," 'vit_large_patch16_224',\n"," 'vit_large_patch16_224_in21k',\n"," 'vit_large_patch16_384',\n"," 'vit_large_patch32_224',\n"," 'vit_large_patch32_224_in21k',\n"," 'vit_large_patch32_384',\n"," 'vit_large_r50_s32_224',\n"," 'vit_large_r50_s32_224_in21k',\n"," 'vit_large_r50_s32_384',\n"," 'vit_relpos_base_patch16_224',\n"," 'vit_relpos_base_patch16_cls_224',\n"," 'vit_relpos_base_patch16_clsgap_224',\n"," 'vit_relpos_base_patch16_plus_240',\n"," 'vit_relpos_base_patch16_rpn_224',\n"," 'vit_relpos_base_patch32_plus_rpn_256',\n"," 'vit_relpos_medium_patch16_224',\n"," 'vit_relpos_medium_patch16_cls_224',\n"," 'vit_relpos_medium_patch16_rpn_224',\n"," 'vit_relpos_small_patch16_224',\n"," 'vit_relpos_small_patch16_rpn_224',\n"," 'vit_small_patch8_224_dino',\n"," 'vit_small_patch16_18x2_224',\n"," 'vit_small_patch16_36x1_224',\n"," 'vit_small_patch16_224',\n"," 'vit_small_patch16_224_dino',\n"," 'vit_small_patch16_224_in21k',\n"," 'vit_small_patch16_384',\n"," 'vit_small_patch32_224',\n"," 'vit_small_patch32_224_in21k',\n"," 'vit_small_patch32_384',\n"," 'vit_small_r26_s32_224',\n"," 'vit_small_r26_s32_224_in21k',\n"," 'vit_small_r26_s32_384',\n"," 'vit_small_resnet26d_224',\n"," 'vit_small_resnet50d_s16_224',\n"," 'vit_srelpos_medium_patch16_224',\n"," 'vit_srelpos_small_patch16_224',\n"," 'vit_tiny_patch16_224',\n"," 'vit_tiny_patch16_224_in21k',\n"," 'vit_tiny_patch16_384',\n"," 'vit_tiny_r_s16_p8_224',\n"," 'vit_tiny_r_s16_p8_224_in21k',\n"," 'vit_tiny_r_s16_p8_384']\n","test model output： tensor([[0.3563, 0.1329]], grad_fn=<AddmmBackward0>)\n","model is ready now!\n","model loaded\n","model : ViT_384_401_PT_lf25_b8_ROSE_CellMix_Group_CLS\n","*********************************setting*************************************\n","Namespace(Pre_Trained_model_path=None, PromptTuning=None, PromptUnFreeze=False, Prompt_Token_num=10, att_module='SimAM', attn_drop_rate=0.0, augmentation_name='CellMix-Group', batch_size=4, check_minibatch=None, cls_token_off=False, data_augmentation_mode=0, dataroot='/data/Pathology_Experiment/dataset/ROSE_CLS', draw_root='/home/Pathology_Experiment/imaging_results', drop_path_rate=0.0, drop_rate=0.0, edge_size=384, enable_attention_check=True, enable_notify=False, enable_tensorboard=False, enable_visualize_check=True, fix_position_ratio=0.5, gpu_idx=0, model_idx='ViT_384_401_PT_lf25_b8_ROSE_CellMix_Group_CLS', model_path='/home/Pathology_Experiment/saved_models', model_path_by_hand=None, num_classes=0, paint=True, pos_embedding_off=False, puzzle_patch_size=48, shuffle_dataloader=True)\n","Epoch: Test\n","\n","useing  CellMix-Group \n","\n","----------\n","Epoch: test     test index of 12 minibatch: 1      time used: 2.5586962699890137\n","minibatch AVG loss: 0.18129095659120745\n","/home/Pathology_Experiment/code/utils/visual_usage.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  return sof(x)\n","Epoch: test     test index of 12 minibatch: 2      time used: 2.4142017364501953\n","minibatch AVG loss: 0.13190800955878026\n","Epoch: test     test index of 12 minibatch: 3      time used: 2.5101583003997803\n","minibatch AVG loss: 0.2517317527041693\n","Epoch: test     test index of 12 minibatch: 4      time used: 2.4688310623168945\n","minibatch AVG loss: 0.13497778696667714\n","Epoch: test     test index of 12 minibatch: 5      time used: 2.3764405250549316\n","minibatch AVG loss: 0.33121553719865915\n","Epoch: test     test index of 12 minibatch: 6      time used: 2.353445529937744\n","minibatch AVG loss: 0.1491274266572873\n","Epoch: test     test index of 12 minibatch: 7      time used: 2.3717236518859863\n","minibatch AVG loss: 0.2695980523931212\n","Epoch: test     test index of 12 minibatch: 8      time used: 2.3908040523529053\n","minibatch AVG loss: 0.4046019081045718\n","Epoch: test     test index of 12 minibatch: 9      time used: 2.438293933868408\n","minibatch AVG loss: 0.20845660486763032\n","Epoch: test     test index of 12 minibatch: 10      time used: 2.4138705730438232\n","minibatch AVG loss: 0.21649208161882902\n","Epoch: test     test index of 12 minibatch: 11      time used: 2.393580436706543\n","minibatch AVG loss: 0.24463129639965095\n","Epoch: test     test index of 12 minibatch: 12      time used: 2.3679451942443848\n","minibatch AVG loss: 0.3380213416882422\n","Epoch: test     test index of 12 minibatch: 13      time used: 2.3723301887512207\n","minibatch AVG loss: 0.1841458075408203\n","Epoch: test     test index of 12 minibatch: 14      time used: 2.4229114055633545\n","minibatch AVG loss: 0.3259291910611258\n","Epoch: test     test index of 12 minibatch: 15      time used: 2.420905828475952\n","minibatch AVG loss: 0.24471312613513874\n","Epoch: test     test index of 12 minibatch: 16      time used: 2.4083938598632812\n","minibatch AVG loss: 0.019703625281484467\n","Epoch: test     test index of 12 minibatch: 17      time used: 2.3653602600097656\n","minibatch AVG loss: 0.1495962882315022\n","Epoch: test     test index of 12 minibatch: 18      time used: 2.3962182998657227\n","minibatch AVG loss: 0.07568408182639057\n","Epoch: test     test index of 12 minibatch: 19      time used: 2.415253162384033\n","minibatch AVG loss: 0.2839320096148488\n","Epoch: test     test index of 12 minibatch: 20      time used: 2.3965508937835693\n","minibatch AVG loss: 0.05011665835172607\n","Epoch: test     test index of 12 minibatch: 21      time used: 2.39780330657959\n","minibatch AVG loss: 0.27315909781706676\n","\n","Epoch:  test \n","Loss: 0.2112  Acc: 93.3071\n","Negative precision: 93.5484  recall: 96.3746\n","Negative sensitivity: 96.3746  specificity: 87.5706\n","Negative FPR: 12.4294  NPV: 92.8144\n","Negative TP: 638.0\n","Negative TN: 310.0\n","Negative FP: 44.0\n","Negative FN: 24.0\n","Positive precision: 92.8144  recall: 87.5706\n","Positive sensitivity: 87.5706  specificity: 96.3746\n","Positive FPR: 3.6254  NPV: 93.5484\n","Positive TP: 310.0\n","Positive TN: 638.0\n","Positive FP: 24.0\n","Positive FN: 44.0\n","\n","\n","Testing complete in 3m 46s\n"]}],"source":["!python CellMix_test.py --model_idx ViT_384_401_PT_lf25_b8_ROSE_CellMix_Group_CLS --gpu_idx 0 --enable_visualize_check --edge_size 384 --data_augmentation_mode 0 --augmentation_name CellMix-Group --fix_position_ratio 0.5 --puzzle_patch_size 48 --batch_size 4 --enable_attention_check --shuffle_dataloader --dataroot /data/Pathology_Experiment/dataset/ROSE_CLS --model_path /home/Pathology_Experiment/saved_models --draw_root /home/Pathology_Experiment/imaging_results"]},{"cell_type":"markdown","source":["--fix_position_ratio 0.5 --puzzle_patch_size 64 --batch_size 4 --enable_attention_check --shuffle_dataloader"],"metadata":{"id":"wMDaJqMA9RxV"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"JjIRFCplZIv9","outputId":"2d8f54d7-79df-4190-b63c-58dacfe44d93"},"outputs":[{"name":"stdout","output_type":"stream","text":["class_names: ['Negative', 'Positive']\n","['convit_base',\n"," 'convit_small',\n"," 'convit_tiny',\n"," 'crossvit_9_240',\n"," 'crossvit_9_dagger_240',\n"," 'crossvit_15_240',\n"," 'crossvit_15_dagger_240',\n"," 'crossvit_15_dagger_408',\n"," 'crossvit_18_240',\n"," 'crossvit_18_dagger_240',\n"," 'crossvit_18_dagger_408',\n"," 'crossvit_base_240',\n"," 'crossvit_small_240',\n"," 'crossvit_tiny_240',\n"," 'gcvit_base',\n"," 'gcvit_small',\n"," 'gcvit_tiny',\n"," 'gcvit_xtiny',\n"," 'gcvit_xxtiny',\n"," 'levit_128',\n"," 'levit_128s',\n"," 'levit_192',\n"," 'levit_256',\n"," 'levit_256d',\n"," 'levit_384',\n"," 'maxvit_base_224',\n"," 'maxvit_large_224',\n"," 'maxvit_nano_rw_256',\n"," 'maxvit_pico_rw_256',\n"," 'maxvit_rmlp_nano_rw_256',\n"," 'maxvit_rmlp_pico_rw_256',\n"," 'maxvit_rmlp_small_rw_224',\n"," 'maxvit_rmlp_small_rw_256',\n"," 'maxvit_rmlp_tiny_rw_256',\n"," 'maxvit_small_224',\n"," 'maxvit_tiny_224',\n"," 'maxvit_tiny_pm_256',\n"," 'maxvit_tiny_rw_224',\n"," 'maxvit_tiny_rw_256',\n"," 'maxvit_xlarge_224',\n"," 'maxxvit_rmlp_nano_rw_256',\n"," 'maxxvit_rmlp_small_rw_256',\n"," 'maxxvit_rmlp_tiny_rw_256',\n"," 'mobilevit_s',\n"," 'mobilevit_xs',\n"," 'mobilevit_xxs',\n"," 'mobilevitv2_050',\n"," 'mobilevitv2_075',\n"," 'mobilevitv2_100',\n"," 'mobilevitv2_125',\n"," 'mobilevitv2_150',\n"," 'mobilevitv2_150_384_in22ft1k',\n"," 'mobilevitv2_150_in22ft1k',\n"," 'mobilevitv2_175',\n"," 'mobilevitv2_175_384_in22ft1k',\n"," 'mobilevitv2_175_in22ft1k',\n"," 'mobilevitv2_200',\n"," 'mobilevitv2_200_384_in22ft1k',\n"," 'mobilevitv2_200_in22ft1k',\n"," 'mvitv2_base',\n"," 'mvitv2_large',\n"," 'mvitv2_small',\n"," 'mvitv2_small_cls',\n"," 'mvitv2_tiny',\n"," 'semobilevit_s',\n"," 'vit_base_patch8_224',\n"," 'vit_base_patch8_224_dino',\n"," 'vit_base_patch8_224_in21k',\n"," 'vit_base_patch16_18x2_224',\n"," 'vit_base_patch16_224',\n"," 'vit_base_patch16_224_dino',\n"," 'vit_base_patch16_224_in21k',\n"," 'vit_base_patch16_224_miil',\n"," 'vit_base_patch16_224_miil_in21k',\n"," 'vit_base_patch16_224_sam',\n"," 'vit_base_patch16_384',\n"," 'vit_base_patch16_plus_240',\n"," 'vit_base_patch16_rpn_224',\n"," 'vit_base_patch32_224',\n"," 'vit_base_patch32_224_clip_laion2b',\n"," 'vit_base_patch32_224_in21k',\n"," 'vit_base_patch32_224_sam',\n"," 'vit_base_patch32_384',\n"," 'vit_base_patch32_plus_256',\n"," 'vit_base_r26_s32_224',\n"," 'vit_base_r50_s16_224',\n"," 'vit_base_r50_s16_224_in21k',\n"," 'vit_base_r50_s16_384',\n"," 'vit_base_resnet26d_224',\n"," 'vit_base_resnet50_224_in21k',\n"," 'vit_base_resnet50_384',\n"," 'vit_base_resnet50d_224',\n"," 'vit_giant_patch14_224',\n"," 'vit_giant_patch14_224_clip_laion2b',\n"," 'vit_gigantic_patch14_224',\n"," 'vit_huge_patch14_224',\n"," 'vit_huge_patch14_224_clip_laion2b',\n"," 'vit_huge_patch14_224_in21k',\n"," 'vit_large_patch14_224',\n"," 'vit_large_patch14_224_clip_laion2b',\n"," 'vit_large_patch16_224',\n"," 'vit_large_patch16_224_in21k',\n"," 'vit_large_patch16_384',\n"," 'vit_large_patch32_224',\n"," 'vit_large_patch32_224_in21k',\n"," 'vit_large_patch32_384',\n"," 'vit_large_r50_s32_224',\n"," 'vit_large_r50_s32_224_in21k',\n"," 'vit_large_r50_s32_384',\n"," 'vit_relpos_base_patch16_224',\n"," 'vit_relpos_base_patch16_cls_224',\n"," 'vit_relpos_base_patch16_clsgap_224',\n"," 'vit_relpos_base_patch16_plus_240',\n"," 'vit_relpos_base_patch16_rpn_224',\n"," 'vit_relpos_base_patch32_plus_rpn_256',\n"," 'vit_relpos_medium_patch16_224',\n"," 'vit_relpos_medium_patch16_cls_224',\n"," 'vit_relpos_medium_patch16_rpn_224',\n"," 'vit_relpos_small_patch16_224',\n"," 'vit_relpos_small_patch16_rpn_224',\n"," 'vit_small_patch8_224_dino',\n"," 'vit_small_patch16_18x2_224',\n"," 'vit_small_patch16_36x1_224',\n"," 'vit_small_patch16_224',\n"," 'vit_small_patch16_224_dino',\n"," 'vit_small_patch16_224_in21k',\n"," 'vit_small_patch16_384',\n"," 'vit_small_patch32_224',\n"," 'vit_small_patch32_224_in21k',\n"," 'vit_small_patch32_384',\n"," 'vit_small_r26_s32_224',\n"," 'vit_small_r26_s32_224_in21k',\n"," 'vit_small_r26_s32_384',\n"," 'vit_small_resnet26d_224',\n"," 'vit_small_resnet50d_s16_224',\n"," 'vit_srelpos_medium_patch16_224',\n"," 'vit_srelpos_small_patch16_224',\n"," 'vit_tiny_patch16_224',\n"," 'vit_tiny_patch16_224_in21k',\n"," 'vit_tiny_patch16_384',\n"," 'vit_tiny_r_s16_p8_224',\n"," 'vit_tiny_r_s16_p8_224_in21k',\n"," 'vit_tiny_r_s16_p8_384']\n","test model output： tensor([[ 0.0910, -0.3262]], grad_fn=<AddmmBackward0>)\n","model is ready now!\n","model loaded\n","model : ViT_384_401_PT_lf25_b8_ROSE_CellMix_Group_CLS\n","*********************************setting*************************************\n","Namespace(Pre_Trained_model_path=None, PromptTuning=None, PromptUnFreeze=False, Prompt_Token_num=10, att_module='SimAM', attn_drop_rate=0.0, augmentation_name='CellMix-Group', batch_size=4, check_minibatch=None, cls_token_off=False, data_augmentation_mode=0, dataroot='/data/Pathology_Experiment/dataset/ROSE_CLS', draw_root='/home/Pathology_Experiment/imaging_results', drop_path_rate=0.0, drop_rate=0.0, edge_size=384, enable_attention_check=True, enable_notify=False, enable_tensorboard=False, enable_visualize_check=True, fix_position_ratio=0.5, gpu_idx=0, model_idx='ViT_384_401_PT_lf25_b8_ROSE_CellMix_Group_CLS', model_path='/home/Pathology_Experiment/saved_models', model_path_by_hand=None, num_classes=0, paint=True, pos_embedding_off=False, puzzle_patch_size=64, shuffle_dataloader=True)\n","Epoch: Test\n","\n","useing  CellMix-Group \n","\n","----------\n","Epoch: test     test index of 12 minibatch: 1      time used: 2.554436206817627\n","minibatch AVG loss: 0.10302454629709246\n","/home/Pathology_Experiment/code/utils/visual_usage.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  return sof(x)\n","Epoch: test     test index of 12 minibatch: 2      time used: 2.400839328765869\n","minibatch AVG loss: 0.08304671356260467\n","Epoch: test     test index of 12 minibatch: 3      time used: 2.465644359588623\n","minibatch AVG loss: 0.28933282422561507\n","Epoch: test     test index of 12 minibatch: 4      time used: 2.5072929859161377\n","minibatch AVG loss: 0.08321073869107447\n","Epoch: test     test index of 12 minibatch: 5      time used: 2.4500467777252197\n","minibatch AVG loss: 0.1908795959170675\n","Epoch: test     test index of 12 minibatch: 6      time used: 2.393183946609497\n","minibatch AVG loss: 0.06188329901730564\n","Epoch: test     test index of 12 minibatch: 7      time used: 2.337841272354126\n","minibatch AVG loss: 0.02204072968743276\n","Epoch: test     test index of 12 minibatch: 8      time used: 2.3611013889312744\n","minibatch AVG loss: 0.26334013446830795\n","Epoch: test     test index of 12 minibatch: 9      time used: 2.3933629989624023\n","minibatch AVG loss: 0.26652141741154384\n","Epoch: test     test index of 12 minibatch: 10      time used: 2.407658100128174\n","minibatch AVG loss: 0.14202528929801397\n","Epoch: test     test index of 12 minibatch: 11      time used: 2.4381351470947266\n","minibatch AVG loss: 0.31582864000908256\n","Epoch: test     test index of 12 minibatch: 12      time used: 2.4240052700042725\n","minibatch AVG loss: 0.22269698082163814\n","Epoch: test     test index of 12 minibatch: 13      time used: 2.4048707485198975\n","minibatch AVG loss: 0.2897810437182973\n","Epoch: test     test index of 12 minibatch: 14      time used: 2.4007370471954346\n","minibatch AVG loss: 0.4438790275125939\n","Epoch: test     test index of 12 minibatch: 15      time used: 2.358912706375122\n","minibatch AVG loss: 0.27323812496615574\n","Epoch: test     test index of 12 minibatch: 16      time used: 2.4092040061950684\n","minibatch AVG loss: 0.13611103708475034\n","Epoch: test     test index of 12 minibatch: 17      time used: 2.4220385551452637\n","minibatch AVG loss: 0.45798205554244004\n","Epoch: test     test index of 12 minibatch: 18      time used: 2.403702735900879\n","minibatch AVG loss: 0.15173610482330938\n","Epoch: test     test index of 12 minibatch: 19      time used: 2.3900160789489746\n","minibatch AVG loss: 0.22768094161438057\n","Epoch: test     test index of 12 minibatch: 20      time used: 2.3800876140594482\n","minibatch AVG loss: 0.08449042238498805\n","Epoch: test     test index of 12 minibatch: 21      time used: 2.3835299015045166\n","minibatch AVG loss: 0.134179035272003\n","\n","Epoch:  test \n","Loss: 0.2112  Acc: 93.3071\n","Negative precision: 93.5484  recall: 96.3746\n","Negative sensitivity: 96.3746  specificity: 87.5706\n","Negative FPR: 12.4294  NPV: 92.8144\n","Negative TP: 638.0\n","Negative TN: 310.0\n","Negative FP: 44.0\n","Negative FN: 24.0\n","Positive precision: 92.8144  recall: 87.5706\n","Positive sensitivity: 87.5706  specificity: 96.3746\n","Positive FPR: 3.6254  NPV: 93.5484\n","Positive TP: 310.0\n","Positive TN: 638.0\n","Positive FP: 24.0\n","Positive FN: 44.0\n","\n","\n","Testing complete in 3m 46s\n"]}],"source":["!python CellMix_test.py --model_idx ViT_384_401_PT_lf25_b8_ROSE_CellMix_Group_CLS --gpu_idx 0 --enable_visualize_check --edge_size 384 --data_augmentation_mode 0 --augmentation_name CellMix-Group --fix_position_ratio 0.5 --puzzle_patch_size 64 --batch_size 4 --enable_attention_check --shuffle_dataloader --dataroot /data/Pathology_Experiment/dataset/ROSE_CLS --model_path /home/Pathology_Experiment/saved_models --draw_root /home/Pathology_Experiment/imaging_results"]},{"cell_type":"markdown","source":["--fix_position_ratio 0.5 --puzzle_patch_size 96 --batch_size 4 --enable_attention_check --shuffle_dataloader"],"metadata":{"id":"5pN4Ub9h9TkV"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"YCmDXSAWZKj4","outputId":"a0cad789-88e8-439b-8748-4567083909d3"},"outputs":[{"name":"stdout","output_type":"stream","text":["class_names: ['Negative', 'Positive']\n","['convit_base',\n"," 'convit_small',\n"," 'convit_tiny',\n"," 'crossvit_9_240',\n"," 'crossvit_9_dagger_240',\n"," 'crossvit_15_240',\n"," 'crossvit_15_dagger_240',\n"," 'crossvit_15_dagger_408',\n"," 'crossvit_18_240',\n"," 'crossvit_18_dagger_240',\n"," 'crossvit_18_dagger_408',\n"," 'crossvit_base_240',\n"," 'crossvit_small_240',\n"," 'crossvit_tiny_240',\n"," 'gcvit_base',\n"," 'gcvit_small',\n"," 'gcvit_tiny',\n"," 'gcvit_xtiny',\n"," 'gcvit_xxtiny',\n"," 'levit_128',\n"," 'levit_128s',\n"," 'levit_192',\n"," 'levit_256',\n"," 'levit_256d',\n"," 'levit_384',\n"," 'maxvit_base_224',\n"," 'maxvit_large_224',\n"," 'maxvit_nano_rw_256',\n"," 'maxvit_pico_rw_256',\n"," 'maxvit_rmlp_nano_rw_256',\n"," 'maxvit_rmlp_pico_rw_256',\n"," 'maxvit_rmlp_small_rw_224',\n"," 'maxvit_rmlp_small_rw_256',\n"," 'maxvit_rmlp_tiny_rw_256',\n"," 'maxvit_small_224',\n"," 'maxvit_tiny_224',\n"," 'maxvit_tiny_pm_256',\n"," 'maxvit_tiny_rw_224',\n"," 'maxvit_tiny_rw_256',\n"," 'maxvit_xlarge_224',\n"," 'maxxvit_rmlp_nano_rw_256',\n"," 'maxxvit_rmlp_small_rw_256',\n"," 'maxxvit_rmlp_tiny_rw_256',\n"," 'mobilevit_s',\n"," 'mobilevit_xs',\n"," 'mobilevit_xxs',\n"," 'mobilevitv2_050',\n"," 'mobilevitv2_075',\n"," 'mobilevitv2_100',\n"," 'mobilevitv2_125',\n"," 'mobilevitv2_150',\n"," 'mobilevitv2_150_384_in22ft1k',\n"," 'mobilevitv2_150_in22ft1k',\n"," 'mobilevitv2_175',\n"," 'mobilevitv2_175_384_in22ft1k',\n"," 'mobilevitv2_175_in22ft1k',\n"," 'mobilevitv2_200',\n"," 'mobilevitv2_200_384_in22ft1k',\n"," 'mobilevitv2_200_in22ft1k',\n"," 'mvitv2_base',\n"," 'mvitv2_large',\n"," 'mvitv2_small',\n"," 'mvitv2_small_cls',\n"," 'mvitv2_tiny',\n"," 'semobilevit_s',\n"," 'vit_base_patch8_224',\n"," 'vit_base_patch8_224_dino',\n"," 'vit_base_patch8_224_in21k',\n"," 'vit_base_patch16_18x2_224',\n"," 'vit_base_patch16_224',\n"," 'vit_base_patch16_224_dino',\n"," 'vit_base_patch16_224_in21k',\n"," 'vit_base_patch16_224_miil',\n"," 'vit_base_patch16_224_miil_in21k',\n"," 'vit_base_patch16_224_sam',\n"," 'vit_base_patch16_384',\n"," 'vit_base_patch16_plus_240',\n"," 'vit_base_patch16_rpn_224',\n"," 'vit_base_patch32_224',\n"," 'vit_base_patch32_224_clip_laion2b',\n"," 'vit_base_patch32_224_in21k',\n"," 'vit_base_patch32_224_sam',\n"," 'vit_base_patch32_384',\n"," 'vit_base_patch32_plus_256',\n"," 'vit_base_r26_s32_224',\n"," 'vit_base_r50_s16_224',\n"," 'vit_base_r50_s16_224_in21k',\n"," 'vit_base_r50_s16_384',\n"," 'vit_base_resnet26d_224',\n"," 'vit_base_resnet50_224_in21k',\n"," 'vit_base_resnet50_384',\n"," 'vit_base_resnet50d_224',\n"," 'vit_giant_patch14_224',\n"," 'vit_giant_patch14_224_clip_laion2b',\n"," 'vit_gigantic_patch14_224',\n"," 'vit_huge_patch14_224',\n"," 'vit_huge_patch14_224_clip_laion2b',\n"," 'vit_huge_patch14_224_in21k',\n"," 'vit_large_patch14_224',\n"," 'vit_large_patch14_224_clip_laion2b',\n"," 'vit_large_patch16_224',\n"," 'vit_large_patch16_224_in21k',\n"," 'vit_large_patch16_384',\n"," 'vit_large_patch32_224',\n"," 'vit_large_patch32_224_in21k',\n"," 'vit_large_patch32_384',\n"," 'vit_large_r50_s32_224',\n"," 'vit_large_r50_s32_224_in21k',\n"," 'vit_large_r50_s32_384',\n"," 'vit_relpos_base_patch16_224',\n"," 'vit_relpos_base_patch16_cls_224',\n"," 'vit_relpos_base_patch16_clsgap_224',\n"," 'vit_relpos_base_patch16_plus_240',\n"," 'vit_relpos_base_patch16_rpn_224',\n"," 'vit_relpos_base_patch32_plus_rpn_256',\n"," 'vit_relpos_medium_patch16_224',\n"," 'vit_relpos_medium_patch16_cls_224',\n"," 'vit_relpos_medium_patch16_rpn_224',\n"," 'vit_relpos_small_patch16_224',\n"," 'vit_relpos_small_patch16_rpn_224',\n"," 'vit_small_patch8_224_dino',\n"," 'vit_small_patch16_18x2_224',\n"," 'vit_small_patch16_36x1_224',\n"," 'vit_small_patch16_224',\n"," 'vit_small_patch16_224_dino',\n"," 'vit_small_patch16_224_in21k',\n"," 'vit_small_patch16_384',\n"," 'vit_small_patch32_224',\n"," 'vit_small_patch32_224_in21k',\n"," 'vit_small_patch32_384',\n"," 'vit_small_r26_s32_224',\n"," 'vit_small_r26_s32_224_in21k',\n"," 'vit_small_r26_s32_384',\n"," 'vit_small_resnet26d_224',\n"," 'vit_small_resnet50d_s16_224',\n"," 'vit_srelpos_medium_patch16_224',\n"," 'vit_srelpos_small_patch16_224',\n"," 'vit_tiny_patch16_224',\n"," 'vit_tiny_patch16_224_in21k',\n"," 'vit_tiny_patch16_384',\n"," 'vit_tiny_r_s16_p8_224',\n"," 'vit_tiny_r_s16_p8_224_in21k',\n"," 'vit_tiny_r_s16_p8_384']\n","test model output： tensor([[0.0108, 0.0171]], grad_fn=<AddmmBackward0>)\n","model is ready now!\n","model loaded\n","model : ViT_384_401_PT_lf25_b8_ROSE_CellMix_Group_CLS\n","*********************************setting*************************************\n","Namespace(Pre_Trained_model_path=None, PromptTuning=None, PromptUnFreeze=False, Prompt_Token_num=10, att_module='SimAM', attn_drop_rate=0.0, augmentation_name='CellMix-Group', batch_size=4, check_minibatch=None, cls_token_off=False, data_augmentation_mode=0, dataroot='/data/Pathology_Experiment/dataset/ROSE_CLS', draw_root='/home/Pathology_Experiment/imaging_results', drop_path_rate=0.0, drop_rate=0.0, edge_size=384, enable_attention_check=True, enable_notify=False, enable_tensorboard=False, enable_visualize_check=True, fix_position_ratio=0.5, gpu_idx=0, model_idx='ViT_384_401_PT_lf25_b8_ROSE_CellMix_Group_CLS', model_path='/home/Pathology_Experiment/saved_models', model_path_by_hand=None, num_classes=0, paint=True, pos_embedding_off=False, puzzle_patch_size=96, shuffle_dataloader=True)\n","Epoch: Test\n","\n","useing  CellMix-Group \n","\n","----------\n","Epoch: test     test index of 12 minibatch: 1      time used: 2.573075771331787\n","minibatch AVG loss: 0.4903892160897764\n","/home/Pathology_Experiment/code/utils/visual_usage.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  return sof(x)\n","Epoch: test     test index of 12 minibatch: 2      time used: 2.3840179443359375\n","minibatch AVG loss: 0.09617588473095869\n","Epoch: test     test index of 12 minibatch: 3      time used: 2.4462344646453857\n","minibatch AVG loss: 0.04335293717789076\n","Epoch: test     test index of 12 minibatch: 4      time used: 2.4615142345428467\n","minibatch AVG loss: 0.15876846179283652\n","Epoch: test     test index of 12 minibatch: 5      time used: 2.394376277923584\n","minibatch AVG loss: 0.06473166336945724\n","Epoch: test     test index of 12 minibatch: 6      time used: 2.4229342937469482\n","minibatch AVG loss: 0.05254092922162575\n","Epoch: test     test index of 12 minibatch: 7      time used: 2.3526101112365723\n","minibatch AVG loss: 0.26887808246101486\n","Epoch: test     test index of 12 minibatch: 8      time used: 2.362154245376587\n","minibatch AVG loss: 0.17135358477996002\n","Epoch: test     test index of 12 minibatch: 9      time used: 2.3890905380249023\n","minibatch AVG loss: 0.24536487435155627\n","Epoch: test     test index of 12 minibatch: 10      time used: 2.4328787326812744\n","minibatch AVG loss: 0.21378642889127755\n","Epoch: test     test index of 12 minibatch: 11      time used: 2.4340622425079346\n","minibatch AVG loss: 0.06791463355208786\n","Epoch: test     test index of 12 minibatch: 12      time used: 2.401064872741699\n","minibatch AVG loss: 0.14001519611216887\n","Epoch: test     test index of 12 minibatch: 13      time used: 2.396395444869995\n","minibatch AVG loss: 0.3515264833549736\n","Epoch: test     test index of 12 minibatch: 14      time used: 2.3839221000671387\n","minibatch AVG loss: 0.3848205323471727\n","Epoch: test     test index of 12 minibatch: 15      time used: 2.386072874069214\n","minibatch AVG loss: 0.2665113259499776\n","Epoch: test     test index of 12 minibatch: 16      time used: 2.4255523681640625\n","minibatch AVG loss: 0.12428311870644393\n","Epoch: test     test index of 12 minibatch: 17      time used: 2.421494245529175\n","minibatch AVG loss: 0.2829538306395989\n","Epoch: test     test index of 12 minibatch: 18      time used: 2.401352643966675\n","minibatch AVG loss: 0.1570290197887516\n","Epoch: test     test index of 12 minibatch: 19      time used: 2.408449411392212\n","minibatch AVG loss: 0.20829314640529142\n","Epoch: test     test index of 12 minibatch: 20      time used: 2.3536510467529297\n","minibatch AVG loss: 0.3075869290854219\n","Epoch: test     test index of 12 minibatch: 21      time used: 2.3485872745513916\n","minibatch AVG loss: 0.3013553294100954\n","\n","Epoch:  test \n","Loss: 0.2112  Acc: 93.3071\n","Negative precision: 93.5484  recall: 96.3746\n","Negative sensitivity: 96.3746  specificity: 87.5706\n","Negative FPR: 12.4294  NPV: 92.8144\n","Negative TP: 638.0\n","Negative TN: 310.0\n","Negative FP: 44.0\n","Negative FN: 24.0\n","Positive precision: 92.8144  recall: 87.5706\n","Positive sensitivity: 87.5706  specificity: 96.3746\n","Positive FPR: 3.6254  NPV: 93.5484\n","Positive TP: 310.0\n","Positive TN: 638.0\n","Positive FP: 24.0\n","Positive FN: 44.0\n","\n","\n","Testing complete in 3m 47s\n"]}],"source":["!python CellMix_test.py --model_idx ViT_384_401_PT_lf25_b8_ROSE_CellMix_Group_CLS --gpu_idx 0 --enable_visualize_check --edge_size 384 --data_augmentation_mode 0 --augmentation_name CellMix-Group --fix_position_ratio 0.5 --puzzle_patch_size 96 --batch_size 4 --enable_attention_check --shuffle_dataloader --dataroot /data/Pathology_Experiment/dataset/ROSE_CLS --model_path /home/Pathology_Experiment/saved_models --draw_root /home/Pathology_Experiment/imaging_results"]},{"cell_type":"markdown","source":["--fix_position_ratio 0.5 --puzzle_patch_size 128 --batch_size 4 --enable_attention_check --shuffle_dataloader"],"metadata":{"id":"5OWkBWYR9Vri"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"G0y0e9IJZP-3","outputId":"254b2d8b-6842-4ded-bf66-74fef7f5f876"},"outputs":[{"name":"stdout","output_type":"stream","text":["class_names: ['Negative', 'Positive']\n","['convit_base',\n"," 'convit_small',\n"," 'convit_tiny',\n"," 'crossvit_9_240',\n"," 'crossvit_9_dagger_240',\n"," 'crossvit_15_240',\n"," 'crossvit_15_dagger_240',\n"," 'crossvit_15_dagger_408',\n"," 'crossvit_18_240',\n"," 'crossvit_18_dagger_240',\n"," 'crossvit_18_dagger_408',\n"," 'crossvit_base_240',\n"," 'crossvit_small_240',\n"," 'crossvit_tiny_240',\n"," 'gcvit_base',\n"," 'gcvit_small',\n"," 'gcvit_tiny',\n"," 'gcvit_xtiny',\n"," 'gcvit_xxtiny',\n"," 'levit_128',\n"," 'levit_128s',\n"," 'levit_192',\n"," 'levit_256',\n"," 'levit_256d',\n"," 'levit_384',\n"," 'maxvit_base_224',\n"," 'maxvit_large_224',\n"," 'maxvit_nano_rw_256',\n"," 'maxvit_pico_rw_256',\n"," 'maxvit_rmlp_nano_rw_256',\n"," 'maxvit_rmlp_pico_rw_256',\n"," 'maxvit_rmlp_small_rw_224',\n"," 'maxvit_rmlp_small_rw_256',\n"," 'maxvit_rmlp_tiny_rw_256',\n"," 'maxvit_small_224',\n"," 'maxvit_tiny_224',\n"," 'maxvit_tiny_pm_256',\n"," 'maxvit_tiny_rw_224',\n"," 'maxvit_tiny_rw_256',\n"," 'maxvit_xlarge_224',\n"," 'maxxvit_rmlp_nano_rw_256',\n"," 'maxxvit_rmlp_small_rw_256',\n"," 'maxxvit_rmlp_tiny_rw_256',\n"," 'mobilevit_s',\n"," 'mobilevit_xs',\n"," 'mobilevit_xxs',\n"," 'mobilevitv2_050',\n"," 'mobilevitv2_075',\n"," 'mobilevitv2_100',\n"," 'mobilevitv2_125',\n"," 'mobilevitv2_150',\n"," 'mobilevitv2_150_384_in22ft1k',\n"," 'mobilevitv2_150_in22ft1k',\n"," 'mobilevitv2_175',\n"," 'mobilevitv2_175_384_in22ft1k',\n"," 'mobilevitv2_175_in22ft1k',\n"," 'mobilevitv2_200',\n"," 'mobilevitv2_200_384_in22ft1k',\n"," 'mobilevitv2_200_in22ft1k',\n"," 'mvitv2_base',\n"," 'mvitv2_large',\n"," 'mvitv2_small',\n"," 'mvitv2_small_cls',\n"," 'mvitv2_tiny',\n"," 'semobilevit_s',\n"," 'vit_base_patch8_224',\n"," 'vit_base_patch8_224_dino',\n"," 'vit_base_patch8_224_in21k',\n"," 'vit_base_patch16_18x2_224',\n"," 'vit_base_patch16_224',\n"," 'vit_base_patch16_224_dino',\n"," 'vit_base_patch16_224_in21k',\n"," 'vit_base_patch16_224_miil',\n"," 'vit_base_patch16_224_miil_in21k',\n"," 'vit_base_patch16_224_sam',\n"," 'vit_base_patch16_384',\n"," 'vit_base_patch16_plus_240',\n"," 'vit_base_patch16_rpn_224',\n"," 'vit_base_patch32_224',\n"," 'vit_base_patch32_224_clip_laion2b',\n"," 'vit_base_patch32_224_in21k',\n"," 'vit_base_patch32_224_sam',\n"," 'vit_base_patch32_384',\n"," 'vit_base_patch32_plus_256',\n"," 'vit_base_r26_s32_224',\n"," 'vit_base_r50_s16_224',\n"," 'vit_base_r50_s16_224_in21k',\n"," 'vit_base_r50_s16_384',\n"," 'vit_base_resnet26d_224',\n"," 'vit_base_resnet50_224_in21k',\n"," 'vit_base_resnet50_384',\n"," 'vit_base_resnet50d_224',\n"," 'vit_giant_patch14_224',\n"," 'vit_giant_patch14_224_clip_laion2b',\n"," 'vit_gigantic_patch14_224',\n"," 'vit_huge_patch14_224',\n"," 'vit_huge_patch14_224_clip_laion2b',\n"," 'vit_huge_patch14_224_in21k',\n"," 'vit_large_patch14_224',\n"," 'vit_large_patch14_224_clip_laion2b',\n"," 'vit_large_patch16_224',\n"," 'vit_large_patch16_224_in21k',\n"," 'vit_large_patch16_384',\n"," 'vit_large_patch32_224',\n"," 'vit_large_patch32_224_in21k',\n"," 'vit_large_patch32_384',\n"," 'vit_large_r50_s32_224',\n"," 'vit_large_r50_s32_224_in21k',\n"," 'vit_large_r50_s32_384',\n"," 'vit_relpos_base_patch16_224',\n"," 'vit_relpos_base_patch16_cls_224',\n"," 'vit_relpos_base_patch16_clsgap_224',\n"," 'vit_relpos_base_patch16_plus_240',\n"," 'vit_relpos_base_patch16_rpn_224',\n"," 'vit_relpos_base_patch32_plus_rpn_256',\n"," 'vit_relpos_medium_patch16_224',\n"," 'vit_relpos_medium_patch16_cls_224',\n"," 'vit_relpos_medium_patch16_rpn_224',\n"," 'vit_relpos_small_patch16_224',\n"," 'vit_relpos_small_patch16_rpn_224',\n"," 'vit_small_patch8_224_dino',\n"," 'vit_small_patch16_18x2_224',\n"," 'vit_small_patch16_36x1_224',\n"," 'vit_small_patch16_224',\n"," 'vit_small_patch16_224_dino',\n"," 'vit_small_patch16_224_in21k',\n"," 'vit_small_patch16_384',\n"," 'vit_small_patch32_224',\n"," 'vit_small_patch32_224_in21k',\n"," 'vit_small_patch32_384',\n"," 'vit_small_r26_s32_224',\n"," 'vit_small_r26_s32_224_in21k',\n"," 'vit_small_r26_s32_384',\n"," 'vit_small_resnet26d_224',\n"," 'vit_small_resnet50d_s16_224',\n"," 'vit_srelpos_medium_patch16_224',\n"," 'vit_srelpos_small_patch16_224',\n"," 'vit_tiny_patch16_224',\n"," 'vit_tiny_patch16_224_in21k',\n"," 'vit_tiny_patch16_384',\n"," 'vit_tiny_r_s16_p8_224',\n"," 'vit_tiny_r_s16_p8_224_in21k',\n"," 'vit_tiny_r_s16_p8_384']\n","test model output： tensor([[-1.1355, -0.1356]], grad_fn=<AddmmBackward0>)\n","model is ready now!\n","model loaded\n","model : ViT_384_401_PT_lf25_b8_ROSE_CellMix_Group_CLS\n","*********************************setting*************************************\n","Namespace(Pre_Trained_model_path=None, PromptTuning=None, PromptUnFreeze=False, Prompt_Token_num=10, att_module='SimAM', attn_drop_rate=0.0, augmentation_name='CellMix-Group', batch_size=4, check_minibatch=None, cls_token_off=False, data_augmentation_mode=0, dataroot='/data/Pathology_Experiment/dataset/ROSE_CLS', draw_root='/home/Pathology_Experiment/imaging_results', drop_path_rate=0.0, drop_rate=0.0, edge_size=384, enable_attention_check=True, enable_notify=False, enable_tensorboard=False, enable_visualize_check=True, fix_position_ratio=0.5, gpu_idx=0, model_idx='ViT_384_401_PT_lf25_b8_ROSE_CellMix_Group_CLS', model_path='/home/Pathology_Experiment/saved_models', model_path_by_hand=None, num_classes=0, paint=True, pos_embedding_off=False, puzzle_patch_size=128, shuffle_dataloader=True)\n","Epoch: Test\n","\n","useing  CellMix-Group \n","\n","----------\n","Epoch: test     test index of 12 minibatch: 1      time used: 2.600245237350464\n","minibatch AVG loss: 0.28320393939308514\n","/home/Pathology_Experiment/code/utils/visual_usage.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  return sof(x)\n","Epoch: test     test index of 12 minibatch: 2      time used: 2.4239444732666016\n","minibatch AVG loss: 0.2869047341227997\n","Epoch: test     test index of 12 minibatch: 3      time used: 2.4918439388275146\n","minibatch AVG loss: 0.07625303151629244\n","Epoch: test     test index of 12 minibatch: 4      time used: 2.4138083457946777\n","minibatch AVG loss: 0.13425297024271762\n","Epoch: test     test index of 12 minibatch: 5      time used: 2.3854317665100098\n","minibatch AVG loss: 0.17941349199827528\n","Epoch: test     test index of 12 minibatch: 6      time used: 2.394505500793457\n","minibatch AVG loss: 0.2533735476899892\n","Epoch: test     test index of 12 minibatch: 7      time used: 2.3865668773651123\n","minibatch AVG loss: 0.5809441557406293\n","Epoch: test     test index of 12 minibatch: 8      time used: 2.387505531311035\n","minibatch AVG loss: 0.2021493446882232\n","Epoch: test     test index of 12 minibatch: 9      time used: 2.3792991638183594\n","minibatch AVG loss: 0.23626216483535245\n","Epoch: test     test index of 12 minibatch: 10      time used: 2.385504722595215\n","minibatch AVG loss: 0.16696358817292398\n","Epoch: test     test index of 12 minibatch: 11      time used: 2.4180688858032227\n","minibatch AVG loss: 0.15131385180166035\n","Epoch: test     test index of 12 minibatch: 12      time used: 2.3919050693511963\n","minibatch AVG loss: 0.19494111915264511\n","Epoch: test     test index of 12 minibatch: 13      time used: 2.4228341579437256\n","minibatch AVG loss: 0.07443535311783005\n","Epoch: test     test index of 12 minibatch: 14      time used: 2.391023874282837\n","minibatch AVG loss: 0.14023094718140783\n","Epoch: test     test index of 12 minibatch: 15      time used: 2.3823800086975098\n","minibatch AVG loss: 0.03533951670760871\n","Epoch: test     test index of 12 minibatch: 16      time used: 2.3990933895111084\n","minibatch AVG loss: 0.22106150801603994\n","Epoch: test     test index of 12 minibatch: 17      time used: 2.362578868865967\n","minibatch AVG loss: 0.08314873117099826\n","Epoch: test     test index of 12 minibatch: 18      time used: 2.379215955734253\n","minibatch AVG loss: 0.12547050631352855\n","Epoch: test     test index of 12 minibatch: 19      time used: 2.3841986656188965\n","minibatch AVG loss: 0.28192388284999953\n","Epoch: test     test index of 12 minibatch: 20      time used: 2.4124131202697754\n","minibatch AVG loss: 0.36505839521608624\n","Epoch: test     test index of 12 minibatch: 21      time used: 2.428325653076172\n","minibatch AVG loss: 0.38694289572716417\n","\n","Epoch:  test \n","Loss: 0.2112  Acc: 93.3071\n","Negative precision: 93.5484  recall: 96.3746\n","Negative sensitivity: 96.3746  specificity: 87.5706\n","Negative FPR: 12.4294  NPV: 92.8144\n","Negative TP: 638.0\n","Negative TN: 310.0\n","Negative FP: 44.0\n","Negative FN: 24.0\n","Positive precision: 92.8144  recall: 87.5706\n","Positive sensitivity: 87.5706  specificity: 96.3746\n","Positive FPR: 3.6254  NPV: 93.5484\n","Positive TP: 310.0\n","Positive TN: 638.0\n","Positive FP: 24.0\n","Positive FN: 44.0\n","\n","\n","Testing complete in 3m 49s\n"]}],"source":["!python CellMix_test.py --model_idx ViT_384_401_PT_lf25_b8_ROSE_CellMix_Group_CLS --gpu_idx 0 --enable_visualize_check --edge_size 384 --data_augmentation_mode 0 --augmentation_name CellMix-Group --fix_position_ratio 0.5 --puzzle_patch_size 128 --batch_size 4 --enable_attention_check --shuffle_dataloader --dataroot /data/Pathology_Experiment/dataset/ROSE_CLS --model_path /home/Pathology_Experiment/saved_models --draw_root /home/Pathology_Experiment/imaging_results"]},{"cell_type":"markdown","source":["--fix_position_ratio 0.5 --puzzle_patch_size 192 --batch_size 4 --enable_attention_check --shuffle_dataloader"],"metadata":{"id":"eEfWuLAH9Y_4"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ZijdrhOMZSPl","outputId":"64185b04-5046-4a46-934f-41a81dd4d8a9"},"outputs":[{"name":"stdout","output_type":"stream","text":["class_names: ['Negative', 'Positive']\n","['convit_base',\n"," 'convit_small',\n"," 'convit_tiny',\n"," 'crossvit_9_240',\n"," 'crossvit_9_dagger_240',\n"," 'crossvit_15_240',\n"," 'crossvit_15_dagger_240',\n"," 'crossvit_15_dagger_408',\n"," 'crossvit_18_240',\n"," 'crossvit_18_dagger_240',\n"," 'crossvit_18_dagger_408',\n"," 'crossvit_base_240',\n"," 'crossvit_small_240',\n"," 'crossvit_tiny_240',\n"," 'gcvit_base',\n"," 'gcvit_small',\n"," 'gcvit_tiny',\n"," 'gcvit_xtiny',\n"," 'gcvit_xxtiny',\n"," 'levit_128',\n"," 'levit_128s',\n"," 'levit_192',\n"," 'levit_256',\n"," 'levit_256d',\n"," 'levit_384',\n"," 'maxvit_base_224',\n"," 'maxvit_large_224',\n"," 'maxvit_nano_rw_256',\n"," 'maxvit_pico_rw_256',\n"," 'maxvit_rmlp_nano_rw_256',\n"," 'maxvit_rmlp_pico_rw_256',\n"," 'maxvit_rmlp_small_rw_224',\n"," 'maxvit_rmlp_small_rw_256',\n"," 'maxvit_rmlp_tiny_rw_256',\n"," 'maxvit_small_224',\n"," 'maxvit_tiny_224',\n"," 'maxvit_tiny_pm_256',\n"," 'maxvit_tiny_rw_224',\n"," 'maxvit_tiny_rw_256',\n"," 'maxvit_xlarge_224',\n"," 'maxxvit_rmlp_nano_rw_256',\n"," 'maxxvit_rmlp_small_rw_256',\n"," 'maxxvit_rmlp_tiny_rw_256',\n"," 'mobilevit_s',\n"," 'mobilevit_xs',\n"," 'mobilevit_xxs',\n"," 'mobilevitv2_050',\n"," 'mobilevitv2_075',\n"," 'mobilevitv2_100',\n"," 'mobilevitv2_125',\n"," 'mobilevitv2_150',\n"," 'mobilevitv2_150_384_in22ft1k',\n"," 'mobilevitv2_150_in22ft1k',\n"," 'mobilevitv2_175',\n"," 'mobilevitv2_175_384_in22ft1k',\n"," 'mobilevitv2_175_in22ft1k',\n"," 'mobilevitv2_200',\n"," 'mobilevitv2_200_384_in22ft1k',\n"," 'mobilevitv2_200_in22ft1k',\n"," 'mvitv2_base',\n"," 'mvitv2_large',\n"," 'mvitv2_small',\n"," 'mvitv2_small_cls',\n"," 'mvitv2_tiny',\n"," 'semobilevit_s',\n"," 'vit_base_patch8_224',\n"," 'vit_base_patch8_224_dino',\n"," 'vit_base_patch8_224_in21k',\n"," 'vit_base_patch16_18x2_224',\n"," 'vit_base_patch16_224',\n"," 'vit_base_patch16_224_dino',\n"," 'vit_base_patch16_224_in21k',\n"," 'vit_base_patch16_224_miil',\n"," 'vit_base_patch16_224_miil_in21k',\n"," 'vit_base_patch16_224_sam',\n"," 'vit_base_patch16_384',\n"," 'vit_base_patch16_plus_240',\n"," 'vit_base_patch16_rpn_224',\n"," 'vit_base_patch32_224',\n"," 'vit_base_patch32_224_clip_laion2b',\n"," 'vit_base_patch32_224_in21k',\n"," 'vit_base_patch32_224_sam',\n"," 'vit_base_patch32_384',\n"," 'vit_base_patch32_plus_256',\n"," 'vit_base_r26_s32_224',\n"," 'vit_base_r50_s16_224',\n"," 'vit_base_r50_s16_224_in21k',\n"," 'vit_base_r50_s16_384',\n"," 'vit_base_resnet26d_224',\n"," 'vit_base_resnet50_224_in21k',\n"," 'vit_base_resnet50_384',\n"," 'vit_base_resnet50d_224',\n"," 'vit_giant_patch14_224',\n"," 'vit_giant_patch14_224_clip_laion2b',\n"," 'vit_gigantic_patch14_224',\n"," 'vit_huge_patch14_224',\n"," 'vit_huge_patch14_224_clip_laion2b',\n"," 'vit_huge_patch14_224_in21k',\n"," 'vit_large_patch14_224',\n"," 'vit_large_patch14_224_clip_laion2b',\n"," 'vit_large_patch16_224',\n"," 'vit_large_patch16_224_in21k',\n"," 'vit_large_patch16_384',\n"," 'vit_large_patch32_224',\n"," 'vit_large_patch32_224_in21k',\n"," 'vit_large_patch32_384',\n"," 'vit_large_r50_s32_224',\n"," 'vit_large_r50_s32_224_in21k',\n"," 'vit_large_r50_s32_384',\n"," 'vit_relpos_base_patch16_224',\n"," 'vit_relpos_base_patch16_cls_224',\n"," 'vit_relpos_base_patch16_clsgap_224',\n"," 'vit_relpos_base_patch16_plus_240',\n"," 'vit_relpos_base_patch16_rpn_224',\n"," 'vit_relpos_base_patch32_plus_rpn_256',\n"," 'vit_relpos_medium_patch16_224',\n"," 'vit_relpos_medium_patch16_cls_224',\n"," 'vit_relpos_medium_patch16_rpn_224',\n"," 'vit_relpos_small_patch16_224',\n"," 'vit_relpos_small_patch16_rpn_224',\n"," 'vit_small_patch8_224_dino',\n"," 'vit_small_patch16_18x2_224',\n"," 'vit_small_patch16_36x1_224',\n"," 'vit_small_patch16_224',\n"," 'vit_small_patch16_224_dino',\n"," 'vit_small_patch16_224_in21k',\n"," 'vit_small_patch16_384',\n"," 'vit_small_patch32_224',\n"," 'vit_small_patch32_224_in21k',\n"," 'vit_small_patch32_384',\n"," 'vit_small_r26_s32_224',\n"," 'vit_small_r26_s32_224_in21k',\n"," 'vit_small_r26_s32_384',\n"," 'vit_small_resnet26d_224',\n"," 'vit_small_resnet50d_s16_224',\n"," 'vit_srelpos_medium_patch16_224',\n"," 'vit_srelpos_small_patch16_224',\n"," 'vit_tiny_patch16_224',\n"," 'vit_tiny_patch16_224_in21k',\n"," 'vit_tiny_patch16_384',\n"," 'vit_tiny_r_s16_p8_224',\n"," 'vit_tiny_r_s16_p8_224_in21k',\n"," 'vit_tiny_r_s16_p8_384']\n","test model output： tensor([[ 0.7384, -0.0616]], grad_fn=<AddmmBackward0>)\n","model is ready now!\n","model loaded\n","model : ViT_384_401_PT_lf25_b8_ROSE_CellMix_Group_CLS\n","*********************************setting*************************************\n","Namespace(Pre_Trained_model_path=None, PromptTuning=None, PromptUnFreeze=False, Prompt_Token_num=10, att_module='SimAM', attn_drop_rate=0.0, augmentation_name='CellMix-Group', batch_size=4, check_minibatch=None, cls_token_off=False, data_augmentation_mode=0, dataroot='/data/Pathology_Experiment/dataset/ROSE_CLS', draw_root='/home/Pathology_Experiment/imaging_results', drop_path_rate=0.0, drop_rate=0.0, edge_size=384, enable_attention_check=True, enable_notify=False, enable_tensorboard=False, enable_visualize_check=True, fix_position_ratio=0.5, gpu_idx=0, model_idx='ViT_384_401_PT_lf25_b8_ROSE_CellMix_Group_CLS', model_path='/home/Pathology_Experiment/saved_models', model_path_by_hand=None, num_classes=0, paint=True, pos_embedding_off=False, puzzle_patch_size=192, shuffle_dataloader=True)\n","Epoch: Test\n","\n","useing  CellMix-Group \n","\n","----------\n","Epoch: test     test index of 12 minibatch: 1      time used: 2.5434887409210205\n","minibatch AVG loss: 0.28245959696747985\n","/home/Pathology_Experiment/code/utils/visual_usage.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  return sof(x)\n","Epoch: test     test index of 12 minibatch: 2      time used: 2.3897855281829834\n","minibatch AVG loss: 0.30165142857003957\n","Epoch: test     test index of 12 minibatch: 3      time used: 2.479891538619995\n","minibatch AVG loss: 0.15967811428708956\n","Epoch: test     test index of 12 minibatch: 4      time used: 2.5113461017608643\n","minibatch AVG loss: 0.07387573829813239\n","Epoch: test     test index of 12 minibatch: 5      time used: 2.4461755752563477\n","minibatch AVG loss: 0.22435019108525012\n","Epoch: test     test index of 12 minibatch: 6      time used: 2.3915188312530518\n","minibatch AVG loss: 0.10612102105854622\n","Epoch: test     test index of 12 minibatch: 7      time used: 2.375636339187622\n","minibatch AVG loss: 0.12915308165126285\n","Epoch: test     test index of 12 minibatch: 8      time used: 2.3691246509552\n","minibatch AVG loss: 0.15217166731599718\n","Epoch: test     test index of 12 minibatch: 9      time used: 2.383817672729492\n","minibatch AVG loss: 0.13209248820824845\n","Epoch: test     test index of 12 minibatch: 10      time used: 2.428595542907715\n","minibatch AVG loss: 0.39791011851411895\n","Epoch: test     test index of 12 minibatch: 11      time used: 2.3900063037872314\n","minibatch AVG loss: 0.28298034541618716\n","Epoch: test     test index of 12 minibatch: 12      time used: 2.3947160243988037\n","minibatch AVG loss: 0.32566089677372173\n","Epoch: test     test index of 12 minibatch: 13      time used: 2.365992546081543\n","minibatch AVG loss: 0.27489561813611846\n","Epoch: test     test index of 12 minibatch: 14      time used: 2.364203929901123\n","minibatch AVG loss: 0.03899057216676738\n","Epoch: test     test index of 12 minibatch: 15      time used: 2.392430067062378\n","minibatch AVG loss: 0.5453356187827012\n","Epoch: test     test index of 12 minibatch: 16      time used: 2.4307780265808105\n","minibatch AVG loss: 0.2010104673584768\n","Epoch: test     test index of 12 minibatch: 17      time used: 2.4234187602996826\n","minibatch AVG loss: 0.06882968222150036\n","Epoch: test     test index of 12 minibatch: 18      time used: 2.401561975479126\n","minibatch AVG loss: 0.07864604687529209\n","Epoch: test     test index of 12 minibatch: 19      time used: 2.3700790405273438\n","minibatch AVG loss: 0.15130739631907394\n","Epoch: test     test index of 12 minibatch: 20      time used: 2.383568048477173\n","minibatch AVG loss: 0.3276132808435553\n","Epoch: test     test index of 12 minibatch: 21      time used: 2.4000964164733887\n","minibatch AVG loss: 0.21230070915953547\n","\n","Epoch:  test \n","Loss: 0.2112  Acc: 93.3071\n","Negative precision: 93.5484  recall: 96.3746\n","Negative sensitivity: 96.3746  specificity: 87.5706\n","Negative FPR: 12.4294  NPV: 92.8144\n","Negative TP: 638.0\n","Negative TN: 310.0\n","Negative FP: 44.0\n","Negative FN: 24.0\n","Positive precision: 92.8144  recall: 87.5706\n","Positive sensitivity: 87.5706  specificity: 96.3746\n","Positive FPR: 3.6254  NPV: 93.5484\n","Positive TP: 310.0\n","Positive TN: 638.0\n","Positive FP: 24.0\n","Positive FN: 44.0\n","\n","\n","Testing complete in 3m 47s\n"]}],"source":["!python CellMix_test.py --model_idx ViT_384_401_PT_lf25_b8_ROSE_CellMix_Group_CLS --gpu_idx 0 --enable_visualize_check --edge_size 384 --data_augmentation_mode 0 --augmentation_name CellMix-Group --fix_position_ratio 0.5 --puzzle_patch_size 192 --batch_size 4 --enable_attention_check --shuffle_dataloader --dataroot /data/Pathology_Experiment/dataset/ROSE_CLS --model_path /home/Pathology_Experiment/saved_models --draw_root /home/Pathology_Experiment/imaging_results"]},{"cell_type":"markdown","metadata":{"id":"7-XjT0rB2rXU"},"source":["# Tensorboard"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"r_qgPKCF2qmp","outputId":"6d16964f-358c-4d7a-cfca-e3ffac18286a"},"outputs":[{"data":{"application/javascript":["\n","        (async () => {\n","            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n","            url.searchParams.set('tensorboardColab', 'true');\n","            const iframe = document.createElement('iframe');\n","            iframe.src = url;\n","            iframe.setAttribute('width', '100%');\n","            iframe.setAttribute('height', '800');\n","            iframe.setAttribute('frameborder', 0);\n","            document.body.appendChild(iframe);\n","        })();\n","    "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"}],"source":["%load_ext tensorboard\n","%tensorboard --logdir '/home/Pathology_Experiment/runs'"]},{"cell_type":"markdown","metadata":{"id":"32lV43PnKVJx"},"source":["# Synchronize files"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"_Wx0ymiiEuyS","outputId":"1cc7c8b4-36e4-46f8-d718-3d8fcdb4645c"},"outputs":[{"name":"stdout","output_type":"stream","text":["runs copy completed!\n","models copy completed!\n","imaging_results copy completed!\n"]}],"source":["# # copy tensorboard runs\n","!/bin/cp -rf /home/Pathology_Experiment/runs/*  /content/drive/MyDrive/Pathology_Experiment/runs/\n","print('runs copy completed!')\n","# copy the traind models\n","!/bin/cp -rf /home/Pathology_Experiment/saved_models/* /content/drive/MyDrive/Pathology_Experiment/saved_models/\n","print('models copy completed!')\n","# copy the imaging_results\n","!/bin/cp -rf /home/Pathology_Experiment/imaging_results/* /content/drive/MyDrive/Pathology_Experiment/imaging_results/\n","print('imaging_results copy completed!')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"9lzAtLIhnGe5","outputId":"55c000f5-f2a8-45e5-a3ba-0e29282e7374"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tue Dec 13 13:31:45 UTC 2022\n"]}],"source":["!date --date='+8 hour'  # CST time zone"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}